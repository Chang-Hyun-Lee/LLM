{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5984ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:51:05.580 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.580 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.605 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 페이지 설정\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF 질의응답 시스템 (LangChain)\",\n",
    "    page_icon=\"📄\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# 제목\n",
    "st.title(\"📄 PDF 질의응답 시스템\")\n",
    "st.markdown(\"LangChain을 활용한 고급 PDF 문서 분석 시스템\")\n",
    "\n",
    "# OpenAI API 키 입력\n",
    "api_key = st.text_input(\"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\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    # PDF 파일 업로드\n",
    "    uploaded_file = st.file_uploader(\"PDF 파일을 선택하세요\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # 임시 파일로 저장\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        # 벡터 저장소 생성 및 저장\n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                # PDF 로드\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # 텍스트 분할\n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                # 임베딩 생성 및 벡터 저장소 구축\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error(f\"벡터 저장소 생성 중 오류: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        # 벡터 저장소 생성\n",
    "        with st.spinner(\"PDF를 분석하고 벡터 저장소를 생성하는 중...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF 분석 완료!\")\n",
    "            \n",
    "            # 문서 정보 표시\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"페이지 수\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"텍스트 청크 수\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"파일 크기\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM 및 체인 설정\n",
    "            llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo\",\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # 커스텀 프롬프트 템플릿\n",
    "            prompt_template = \"\"\"\n",
    "            당신은 PDF 문서의 내용을 바탕으로 질문에 답하는 전문 어시스턴트입니다.\n",
    "            제공된 문서 내용을 바탕으로 정확하고 상세한 답변을 제공해주세요.\n",
    "            만약 문서에서 답을 찾을 수 없다면, 그렇다고 명시해주세요.\n",
    "\n",
    "            문서 내용:\n",
    "            {context}\n",
    "\n",
    "            질문: {question}\n",
    "\n",
    "            답변:\n",
    "            \"\"\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(\n",
    "                template=prompt_template, \n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "            \n",
    "            # RetrievalQA 체인 생성\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # 질문 입력\n",
    "            question = st.text_input(\"PDF 내용에 대해 질문하세요:\")\n",
    "            \n",
    "            # 예시 질문들\n",
    "            st.markdown(\"**예시 질문:**\")\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"📋 문서 요약\"):\n",
    "                    question = \"이 문서의 주요 내용을 요약해주세요.\"\n",
    "            with col2:\n",
    "                if st.button(\"🔑 핵심 키워드\"):\n",
    "                    question = \"이 문서의 핵심 키워드들을 추출해주세요.\"\n",
    "            with col3:\n",
    "                if st.button(\"❓ 주요 논점\"):\n",
    "                    question = \"이 문서에서 다루는 주요 논점들은 무엇인가요?\"\n",
    "            \n",
    "            if st.button(\"질문하기\") and question:\n",
    "                with st.spinner(\"LangChain으로 답변을 생성하는 중...\"):\n",
    "                    try:\n",
    "                        # 질의응답 실행\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        answer = result[\"result\"]\n",
    "                        source_docs = result[\"source_documents\"]\n",
    "                        \n",
    "                        # 답변 표시\n",
    "                        st.markdown(\"### 📝 답변\")\n",
    "                        st.write(answer)\n",
    "                        \n",
    "                        # 관련 문서 청크 표시\n",
    "                        with st.expander(\"📚 참조된 문서 내용\"):\n",
    "                            for i, doc in enumerate(source_docs):\n",
    "                                st.markdown(f\"**참조 {i+1}:**\")\n",
    "                                st.write(doc.page_content[:500] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                        \n",
    "                        # 신뢰도 점수 (간단한 버전)\n",
    "                        confidence = len([doc for doc in source_docs if question.lower() in doc.page_content.lower()]) / len(source_docs) * 100\n",
    "                        st.progress(confidence/100)\n",
    "                        st.caption(f\"답변 신뢰도: {confidence:.0f}%\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"오류가 발생했습니다: {str(e)}\")\n",
    "                        st.info(\"API 키와 인터넷 연결을 확인해주세요.\")\n",
    "            \n",
    "            # 유사 문서 검색 기능\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### 🔍 유사 문서 검색\")\n",
    "            search_query = st.text_input(\"검색할 키워드를 입력하세요:\")\n",
    "            \n",
    "            if st.button(\"검색\") and search_query:\n",
    "                with st.spinner(\"유사한 내용을 검색하는 중...\"):\n",
    "                    try:\n",
    "                        # 유사도 검색\n",
    "                        similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                        \n",
    "                        st.markdown(\"### 🎯 검색 결과\")\n",
    "                        for i, doc in enumerate(similar_docs):\n",
    "                            with st.expander(f\"결과 {i+1}\"):\n",
    "                                st.write(doc.page_content[:800] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"검색 중 오류: {e}\")\n",
    "        \n",
    "        else:\n",
    "            st.error(\"PDF 처리에 실패했습니다.\")\n",
    "        \n",
    "        # 임시 파일 정리\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 사이드바 - 시스템 정보\n",
    "        with st.sidebar:\n",
    "            st.markdown(\"### 🤖 LangChain 시스템\")\n",
    "            st.markdown(\"\"\"\n",
    "            **사용 중인 기술:**\n",
    "            - 🦜 LangChain Framework\n",
    "            - 📄 PyPDF Loader\n",
    "            - 🔤 OpenAI Embeddings\n",
    "            - 🗃️ FAISS Vector Store\n",
    "            - 🤖 GPT-3.5-turbo\n",
    "            - 📊 Retrieval QA Chain\n",
    "            \"\"\")\n",
    "            \n",
    "            st.markdown(\"### 📋 사용 가이드\")\n",
    "            st.markdown(\"\"\"\n",
    "            1. OpenAI API Key 입력\n",
    "            2. PDF 파일 업로드\n",
    "            3. 자동 벡터화 및 인덱싱\n",
    "            4. 질문 또는 키워드 검색\n",
    "            5. AI가 관련 내용 기반 답변\n",
    "            \n",
    "            ⚠️ **특징:**\n",
    "            - 문서를 청크 단위로 분할\n",
    "            - 벡터 임베딩으로 의미 검색\n",
    "            - 관련 문서만 참조하여 답변\n",
    "            - 참조 출처 제공\n",
    "            \"\"\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Key를 입력해주세요.\")\n",
    "    st.info(\"API Key는 https://platform.openai.com에서 발급받을 수 있습니다.\")\n",
    "    \n",
    "    # LangChain 소개\n",
    "    with st.expander(\"🦜 LangChain이란?\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **LangChain**은 대형 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크입니다.\n",
    "        \n",
    "        **주요 기능:**\n",
    "        - **Document Loaders**: 다양한 형식의 문서 로드\n",
    "        - **Text Splitters**: 텍스트를 적절한 크기로 분할\n",
    "        - **Embeddings**: 텍스트를 벡터로 변환\n",
    "        - **Vector Stores**: 벡터 데이터베이스 관리\n",
    "        - **Chains**: 복잡한 워크플로우 구성\n",
    "        - **Retrievers**: 관련 정보 검색\n",
    "        \n",
    "        이 시스템에서는 **RAG (Retrieval Augmented Generation)** 패턴을 사용하여\n",
    "        PDF 문서에서 관련 내용을 찾아 정확한 답변을 생성합니다.\n",
    "        \"\"\")\n",
    "\n",
    "# 독립 실행 파일 생성\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### 💾 독립 실행 파일 생성\")\n",
    "\n",
    "if st.button(\"langchain_pdf_app.py 파일 생성\"):\n",
    "    langchain_app_code = '''import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF 질의응답 시스템 (LangChain)\",\n",
    "    page_icon=\"📄\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"📄 PDF 질의응답 시스템\")\n",
    "st.markdown(\"LangChain을 활용한 고급 PDF 문서 분석 시스템\")\n",
    "\n",
    "api_key = st.text_input(\"OpenAI API Key를 입력하세요:\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"PDF 파일을 선택하세요\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            except Exception as e:\n",
    "                st.error(f\"오류: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        with st.spinner(\"PDF 분석 중...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF 분석 완료!\")\n",
    "            \n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"페이지 수\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"청크 수\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"파일 크기\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "            \n",
    "            prompt_template = \\\"\\\"\\\"\n",
    "            PDF 문서 내용을 바탕으로 질문에 답해주세요.\n",
    "            \n",
    "            문서 내용: {context}\n",
    "            질문: {question}\n",
    "            답변:\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "            \n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            question = st.text_input(\"질문을 입력하세요:\")\n",
    "            \n",
    "            if st.button(\"질문하기\") and question:\n",
    "                with st.spinner(\"답변 생성 중...\"):\n",
    "                    try:\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        \n",
    "                        st.markdown(\"### 📝 답변\")\n",
    "                        st.write(result[\"result\"])\n",
    "                        \n",
    "                        with st.expander(\"참조 문서\"):\n",
    "                            for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                                st.markdown(f\"**참조 {i+1}:**\")\n",
    "                                st.write(doc.page_content[:300] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"오류: {e}\")\n",
    "        \n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Key를 입력해주세요.\")\n",
    "'''\n",
    "    \n",
    "    try:\n",
    "        with open('langchain_pdf_app.py', 'w', encoding='utf-8') as f:\n",
    "            f.write(langchain_app_code)\n",
    "        st.success(\"✅ langchain_pdf_app.py 파일이 생성되었습니다!\")\n",
    "        st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"파일 생성 오류: {e}\")\n",
    "\n",
    "# 설치 가이드\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### 🔧 패키지 설치 및 실행\")\n",
    "\n",
    "st.markdown(\"**필수 패키지 설치:**\")\n",
    "st.code(\"\"\"\n",
    "pip install streamlit\n",
    "pip install langchain\n",
    "pip install langchain-openai\n",
    "pip install langchain-community\n",
    "pip install pypdf\n",
    "pip install faiss-cpu\n",
    "\"\"\", language=\"bash\")\n",
    "\n",
    "st.markdown(\"**실행:**\")\n",
    "st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42054551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.97.0)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/.local/lib/python3.10/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /root/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /root/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.8-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/.local/lib/python3.10/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging>=23.2 in /root/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /root/.local/lib/python3.10/site-packages (from langchain-community) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.70-py3-none-any.whl (442 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.2/582.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, regex, python-dotenv, propcache, mypy-extensions, multidict, marshmallow, jsonpatch, httpx-sse, greenlet, frozenlist, async-timeout, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
      "\u001b[2K  Attempting uninstall: jsonpatch0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K    Found existing installation: jsonpatch 1.32━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K    Uninstalling jsonpatch-1.32:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K      Successfully uninstalled jsonpatch-1.32━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/28\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.7.0 greenlet-3.2.3 httpx-sse-0.4.1 jsonpatch-1.33 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.70 langchain-openai-0.3.28 langchain-text-splitters-0.3.8 langsmith-0.4.8 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 regex-2024.11.6 requests-toolbelt-1.0.0 tiktoken-0.9.0 typing-inspect-0.9.0 yarl-1.20.1 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U openai langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44fe1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /root/.local/lib/python3.10/site-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (2025.7.14)\n",
      "Building wheels for collected packages: google-search-results\n",
      "\u001b[33m  DEPRECATION: Building 'google-search-results' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-search-results'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32016 sha256=7c7c0c58c1a87659b256e1e8336b86bca74bcbf8f7bbabbb3121850983507597\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /root/.local/lib/python3.10/site-packages (from wikipedia) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /root/.local/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (4.14.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "\u001b[33m  DEPRECATION: Building 'wikipedia' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=4795e6233a72a76411baaecaa79da315bac5db46d70e504336c3421ef8292df9\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /root/.local/lib/python3.10/site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in /root/.local/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /root/.local/lib/python3.10/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /root/.local/lib/python3.10/site-packages (from sentence_transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.5)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /root/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch>=1.11.0->sentence_transformers) (59.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.7.14)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, threadpoolctl, sympy, scipy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, joblib, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence_transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [sentence_transformers]ence_transformers]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 safetensors-0.5.3 scikit-learn-1.7.1 scipy-1.15.3 sentence_transformers-5.0.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.2 torch-2.7.1 transformers-4.53.3 triton-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /root/.local/lib/python3.10/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results\n",
    "!pip install wikipedia\n",
    "!pip install faiss-cpu \n",
    "!pip install sentence_transformers \n",
    "!pip install tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e37680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:51:52.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.079 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.081 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 페이지 설정\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF 질의응답 시스템 (LangChain)\",\n",
    "    page_icon=\"📄\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# 제목\n",
    "st.title(\"📄 PDF 질의응답 시스템\")\n",
    "st.markdown(\"LangChain을 활용한 고급 PDF 문서 분석 시스템\")\n",
    "\n",
    "# OpenAI API 키 입력\n",
    "api_key = st.text_input(\"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\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    # PDF 파일 업로드\n",
    "    uploaded_file = st.file_uploader(\"PDF 파일을 선택하세요\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # 임시 파일로 저장\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        # 벡터 저장소 생성 및 저장\n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                # PDF 로드\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # 텍스트 분할\n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                # 임베딩 생성 및 벡터 저장소 구축\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error(f\"벡터 저장소 생성 중 오류: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        # 벡터 저장소 생성\n",
    "        with st.spinner(\"PDF를 분석하고 벡터 저장소를 생성하는 중...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF 분석 완료!\")\n",
    "            \n",
    "            # 문서 정보 표시\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"페이지 수\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"텍스트 청크 수\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"파일 크기\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM 및 체인 설정\n",
    "            llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo\",\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # 커스텀 프롬프트 템플릿\n",
    "            prompt_template = \"\"\"\n",
    "            당신은 PDF 문서의 내용을 바탕으로 질문에 답하는 전문 어시스턴트입니다.\n",
    "            제공된 문서 내용을 바탕으로 정확하고 상세한 답변을 제공해주세요.\n",
    "            만약 문서에서 답을 찾을 수 없다면, 그렇다고 명시해주세요.\n",
    "\n",
    "            문서 내용:\n",
    "            {context}\n",
    "\n",
    "            질문: {question}\n",
    "\n",
    "            답변:\n",
    "            \"\"\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(\n",
    "                template=prompt_template, \n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "            \n",
    "            # RetrievalQA 체인 생성\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # 질문 입력\n",
    "            question = st.text_input(\"PDF 내용에 대해 질문하세요:\")\n",
    "            \n",
    "            # 예시 질문들\n",
    "            st.markdown(\"**예시 질문:**\")\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"📋 문서 요약\"):\n",
    "                    question = \"이 문서의 주요 내용을 요약해주세요.\"\n",
    "            with col2:\n",
    "                if st.button(\"🔑 핵심 키워드\"):\n",
    "                    question = \"이 문서의 핵심 키워드들을 추출해주세요.\"\n",
    "            with col3:\n",
    "                if st.button(\"❓ 주요 논점\"):\n",
    "                    question = \"이 문서에서 다루는 주요 논점들은 무엇인가요?\"\n",
    "            \n",
    "            if st.button(\"질문하기\") and question:\n",
    "                with st.spinner(\"LangChain으로 답변을 생성하는 중...\"):\n",
    "                    try:\n",
    "                        # 질의응답 실행\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        answer = result[\"result\"]\n",
    "                        source_docs = result[\"source_documents\"]\n",
    "                        \n",
    "                        # 답변 표시\n",
    "                        st.markdown(\"### 📝 답변\")\n",
    "                        st.write(answer)\n",
    "                        \n",
    "                        # 관련 문서 청크 표시\n",
    "                        with st.expander(\"📚 참조된 문서 내용\"):\n",
    "                            for i, doc in enumerate(source_docs):\n",
    "                                st.markdown(f\"**참조 {i+1}:**\")\n",
    "                                st.write(doc.page_content[:500] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                        \n",
    "                        # 신뢰도 점수 (간단한 버전)\n",
    "                        confidence = len([doc for doc in source_docs if question.lower() in doc.page_content.lower()]) / len(source_docs) * 100\n",
    "                        st.progress(confidence/100)\n",
    "                        st.caption(f\"답변 신뢰도: {confidence:.0f}%\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"오류가 발생했습니다: {str(e)}\")\n",
    "                        st.info(\"API 키와 인터넷 연결을 확인해주세요.\")\n",
    "            \n",
    "            # 유사 문서 검색 기능\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### 🔍 유사 문서 검색\")\n",
    "            search_query = st.text_input(\"검색할 키워드를 입력하세요:\")\n",
    "            \n",
    "            if st.button(\"검색\") and search_query:\n",
    "                with st.spinner(\"유사한 내용을 검색하는 중...\"):\n",
    "                    try:\n",
    "                        # 유사도 검색\n",
    "                        similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                        \n",
    "                        st.markdown(\"### 🎯 검색 결과\")\n",
    "                        for i, doc in enumerate(similar_docs):\n",
    "                            with st.expander(f\"결과 {i+1}\"):\n",
    "                                st.write(doc.page_content[:800] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"검색 중 오류: {e}\")\n",
    "        \n",
    "        else:\n",
    "            st.error(\"PDF 처리에 실패했습니다.\")\n",
    "        \n",
    "        # 임시 파일 정리\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 사이드바 - 시스템 정보\n",
    "        with st.sidebar:\n",
    "            st.markdown(\"### 🤖 LangChain 시스템\")\n",
    "            st.markdown(\"\"\"\n",
    "            **사용 중인 기술:**\n",
    "            - 🦜 LangChain Framework\n",
    "            - 📄 PyPDF Loader\n",
    "            - 🔤 OpenAI Embeddings\n",
    "            - 🗃️ FAISS Vector Store\n",
    "            - 🤖 GPT-3.5-turbo\n",
    "            - 📊 Retrieval QA Chain\n",
    "            \"\"\")\n",
    "            \n",
    "            st.markdown(\"### 📋 사용 가이드\")\n",
    "            st.markdown(\"\"\"\n",
    "            1. OpenAI API Key 입력\n",
    "            2. PDF 파일 업로드\n",
    "            3. 자동 벡터화 및 인덱싱\n",
    "            4. 질문 또는 키워드 검색\n",
    "            5. AI가 관련 내용 기반 답변\n",
    "            \n",
    "            ⚠️ **특징:**\n",
    "            - 문서를 청크 단위로 분할\n",
    "            - 벡터 임베딩으로 의미 검색\n",
    "            - 관련 문서만 참조하여 답변\n",
    "            - 참조 출처 제공\n",
    "            \"\"\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Key를 입력해주세요.\")\n",
    "    st.info(\"API Key는 https://platform.openai.com에서 발급받을 수 있습니다.\")\n",
    "    \n",
    "    # LangChain 소개\n",
    "    with st.expander(\"🦜 LangChain이란?\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **LangChain**은 대형 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크입니다.\n",
    "        \n",
    "        **주요 기능:**\n",
    "        - **Document Loaders**: 다양한 형식의 문서 로드\n",
    "        - **Text Splitters**: 텍스트를 적절한 크기로 분할\n",
    "        - **Embeddings**: 텍스트를 벡터로 변환\n",
    "        - **Vector Stores**: 벡터 데이터베이스 관리\n",
    "        - **Chains**: 복잡한 워크플로우 구성\n",
    "        - **Retrievers**: 관련 정보 검색\n",
    "        \n",
    "        이 시스템에서는 **RAG (Retrieval Augmented Generation)** 패턴을 사용하여\n",
    "        PDF 문서에서 관련 내용을 찾아 정확한 답변을 생성합니다.\n",
    "        \"\"\")\n",
    "\n",
    "# 독립 실행 파일 생성\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### 💾 독립 실행 파일 생성\")\n",
    "\n",
    "if st.button(\"langchain_pdf_app.py 파일 생성\"):\n",
    "    langchain_app_code = '''import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF 질의응답 시스템 (LangChain)\",\n",
    "    page_icon=\"📄\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"📄 PDF 질의응답 시스템\")\n",
    "st.markdown(\"LangChain을 활용한 고급 PDF 문서 분석 시스템\")\n",
    "\n",
    "api_key = st.text_input(\"OpenAI API Key를 입력하세요:\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"PDF 파일을 선택하세요\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            except Exception as e:\n",
    "                st.error(f\"오류: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        with st.spinner(\"PDF 분석 중...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF 분석 완료!\")\n",
    "            \n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"페이지 수\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"청크 수\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"파일 크기\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "            \n",
    "            prompt_template = \\\"\\\"\\\"\n",
    "            PDF 문서 내용을 바탕으로 질문에 답해주세요.\n",
    "            \n",
    "            문서 내용: {context}\n",
    "            질문: {question}\n",
    "            답변:\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "            \n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            question = st.text_input(\"질문을 입력하세요:\")\n",
    "            \n",
    "            if st.button(\"질문하기\") and question:\n",
    "                with st.spinner(\"답변 생성 중...\"):\n",
    "                    try:\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        \n",
    "                        st.markdown(\"### 📝 답변\")\n",
    "                        st.write(result[\"result\"])\n",
    "                        \n",
    "                        with st.expander(\"참조 문서\"):\n",
    "                            for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                                st.markdown(f\"**참조 {i+1}:**\")\n",
    "                                st.write(doc.page_content[:300] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"오류: {e}\")\n",
    "        \n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Key를 입력해주세요.\")\n",
    "'''\n",
    "    \n",
    "    try:\n",
    "        with open('langchain_pdf_app.py', 'w', encoding='utf-8') as f:\n",
    "            f.write(langchain_app_code)\n",
    "        st.success(\"✅ langchain_pdf_app.py 파일이 생성되었습니다!\")\n",
    "        st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"파일 생성 오류: {e}\")\n",
    "\n",
    "# 설치 가이드\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### 🔧 패키지 설치 및 실행\")\n",
    "\n",
    "st.markdown(\"**필수 패키지 설치:**\")\n",
    "st.code(\"\"\"\n",
    "pip install streamlit\n",
    "pip install langchain\n",
    "pip install langchain-openai\n",
    "pip install langchain-community\n",
    "pip install pypdf\n",
    "pip install faiss-cpu\n",
    "\"\"\", language=\"bash\")\n",
    "\n",
    "st.markdown(\"**실행:**\")\n",
    "st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "539db25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /root/.local/lib/python3.10/site-packages (1.47.0)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.27)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.11.0.post1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.1.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /root/.local/lib/python3.10/site-packages (from streamlit) (2.2.6)\n",
      "Requirement already satisfied: packaging<26,>=20 in /root/.local/lib/python3.10/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (2.3.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.31.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /root/.local/lib/python3.10/site-packages (from streamlit) (2.32.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /root/.local/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (4.14.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /root/.local/lib/python3.10/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /root/.local/lib/python3.10/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in /root/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /root/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /root/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.48.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /root/.local/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /root/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.70)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.97.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.local/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /root/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /root/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /root/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:54:01.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF 질의응답 시스템 - LangChain 활용 버전\n",
    "# 필요한 패키지 설치 (Jupyter에서 실행 시)\n",
    "!pip install streamlit langchain langchain-openai langchain-community pypdf faiss-cpu\n",
    "\n",
    "# Jupyter Notebook에서 Streamlit 경고 해결\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 페이지 설정\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF 질의응답 시스템 (LangChain)\",\n",
    "    page_icon=\"📄\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# 제목\n",
    "st.title(\"📄 PDF 질의응답 시스템\")\n",
    "st.markdown(\"LangChain을 활용한 고급 PDF 문서 분석 시스템\")\n",
    "\n",
    "# OpenAI API 키 입력\n",
    "api_key = st.text_input(\"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\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    # PDF 파일 업로드\n",
    "    uploaded_file = st.file_uploader(\"PDF 파일을 선택하세요\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # 임시 파일로 저장\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        # 벡터 저장소 생성 및 저장 (캐싱으로 성능 최적화)\n",
    "        @st.cache_data(show_spinner=False)\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                # PDF 로드\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # 텍스트 분할\n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                # 임베딩 생성 및 벡터 저장소 구축\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error(f\"벡터 저장소 생성 중 오류: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        # 벡터 저장소 생성\n",
    "        with st.spinner(\"PDF를 분석하고 벡터 저장소를 생성하는 중...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF 분석 완료!\")\n",
    "            \n",
    "            # 문서 정보 표시\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"페이지 수\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"텍스트 청크 수\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"파일 크기\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM 및 체인 설정\n",
    "            llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo\",\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # 커스텀 프롬프트 템플릿\n",
    "            prompt_template = \"\"\"\n",
    "            당신은 PDF 문서의 내용을 바탕으로 질문에 답하는 전문 어시스턴트입니다.\n",
    "            제공된 문서 내용을 바탕으로 정확하고 상세한 답변을 제공해주세요.\n",
    "            만약 문서에서 답을 찾을 수 없다면, 그렇다고 명시해주세요.\n",
    "\n",
    "            문서 내용:\n",
    "            {context}\n",
    "\n",
    "            질문: {question}\n",
    "\n",
    "            답변:\n",
    "            \"\"\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(\n",
    "                template=prompt_template, \n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "            \n",
    "            # RetrievalQA 체인 생성\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # 질문 입력\n",
    "            question = st.text_input(\"PDF 내용에 대해 질문하세요:\")\n",
    "            \n",
    "            # 예시 질문들\n",
    "            st.markdown(\"**예시 질문:**\")\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"📋 문서 요약\"):\n",
    "                    question = \"이 문서의 주요 내용을 요약해주세요.\"\n",
    "            with col2:\n",
    "                if st.button(\"🔑 핵심 키워드\"):\n",
    "                    question = \"이 문서의 핵심 키워드들을 추출해주세요.\"\n",
    "            with col3:\n",
    "                if st.button(\"❓ 주요 논점\"):\n",
    "                    question = \"이 문서에서 다루는 주요 논점들은 무엇인가요?\"\n",
    "            \n",
    "            if st.button(\"질문하기\") and question:\n",
    "                with st.spinner(\"LangChain으로 답변을 생성하는 중...\"):\n",
    "                    try:\n",
    "                        # 질의응답 실행\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        answer = result[\"result\"]\n",
    "                        source_docs = result[\"source_documents\"]\n",
    "                        \n",
    "                        # 답변 표시\n",
    "                        st.markdown(\"### 📝 답변\")\n",
    "                        st.write(answer)\n",
    "                        \n",
    "                        # 관련 문서 청크 표시\n",
    "                        with st.expander(\"📚 참조된 문서 내용\"):\n",
    "                            for i, doc in enumerate(source_docs):\n",
    "                                st.markdown(f\"**참조 {i+1}:**\")\n",
    "                                st.write(doc.page_content[:500] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                        \n",
    "                        # 신뢰도 점수 (간단한 버전)\n",
    "                        confidence = len([doc for doc in source_docs if question.lower() in doc.page_content.lower()]) / len(source_docs) * 100\n",
    "                        st.progress(confidence/100)\n",
    "                        st.caption(f\"답변 신뢰도: {confidence:.0f}%\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"오류가 발생했습니다: {str(e)}\")\n",
    "                        st.info(\"API 키와 인터넷 연결을 확인해주세요.\")\n",
    "            \n",
    "            # 유사 문서 검색 기능\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### 🔍 유사 문서 검색\")\n",
    "            search_query = st.text_input(\"검색할 키워드를 입력하세요:\")\n",
    "            \n",
    "            if st.button(\"검색\") and search_query:\n",
    "                with st.spinner(\"유사한 내용을 검색하는 중...\"):\n",
    "                    try:\n",
    "                        # 유사도 검색\n",
    "                        similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                        \n",
    "                        st.markdown(\"### 🎯 검색 결과\")\n",
    "                        for i, doc in enumerate(similar_docs):\n",
    "                            with st.expander(f\"결과 {i+1}\"):\n",
    "                                st.write(doc.page_content[:800] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"검색 중 오류: {e}\")\n",
    "        \n",
    "        else:\n",
    "            st.error(\"PDF 처리에 실패했습니다.\")\n",
    "        \n",
    "        # 임시 파일 정리\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 사이드바 - 시스템 정보\n",
    "        with st.sidebar:\n",
    "            st.markdown(\"### 🤖 LangChain 시스템\")\n",
    "            st.markdown(\"\"\"\n",
    "            **사용 중인 기술:**\n",
    "            - 🦜 LangChain Framework\n",
    "            - 📄 PyPDF Loader\n",
    "            - 🔤 OpenAI Embeddings\n",
    "            - 🗃️ FAISS Vector Store\n",
    "            - 🤖 GPT-3.5-turbo\n",
    "            - 📊 Retrieval QA Chain\n",
    "            \"\"\")\n",
    "            \n",
    "            st.markdown(\"### 📋 사용 가이드\")\n",
    "            st.markdown(\"\"\"\n",
    "            1. OpenAI API Key 입력\n",
    "            2. PDF 파일 업로드\n",
    "            3. 자동 벡터화 및 인덱싱\n",
    "            4. 질문 또는 키워드 검색\n",
    "            5. AI가 관련 내용 기반 답변\n",
    "            \n",
    "            ⚠️ **특징:**\n",
    "            - 문서를 청크 단위로 분할\n",
    "            - 벡터 임베딩으로 의미 검색\n",
    "            - 관련 문서만 참조하여 답변\n",
    "            - 참조 출처 제공\n",
    "            \"\"\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Key를 입력해주세요.\")\n",
    "    st.info(\"API Key는 https://platform.openai.com에서 발급받을 수 있습니다.\")\n",
    "    \n",
    "    # LangChain 소개\n",
    "    with st.expander(\"🦜 LangChain이란?\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **LangChain**은 대형 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크입니다.\n",
    "        \n",
    "        **주요 기능:**\n",
    "        - **Document Loaders**: 다양한 형식의 문서 로드\n",
    "        - **Text Splitters**: 텍스트를 적절한 크기로 분할\n",
    "        - **Embeddings**: 텍스트를 벡터로 변환\n",
    "        - **Vector Stores**: 벡터 데이터베이스 관리\n",
    "        - **Chains**: 복잡한 워크플로우 구성\n",
    "        - **Retrievers**: 관련 정보 검색\n",
    "        \n",
    "        이 시스템에서는 **RAG (Retrieval Augmented Generation)** 패턴을 사용하여\n",
    "        PDF 문서에서 관련 내용을 찾아 정확한 답변을 생성합니다.\n",
    "        \"\"\")\n",
    "\n",
    "# 독립 실행 파일 생성\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### 💾 독립 실행 파일 생성\")\n",
    "\n",
    "if st.button(\"langchain_pdf_app.py 파일 생성\"):\n",
    "    langchain_app_code = '''# LangChain PDF 질의응답 시스템\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 페이지 설정\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF 질의응답 시스템 (LangChain)\",\n",
    "    page_icon=\"📄\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"📄 PDF 질의응답 시스템\")\n",
    "st.markdown(\"LangChain을 활용한 고급 PDF 문서 분석 시스템\")\n",
    "\n",
    "api_key = st.text_input(\"OpenAI API Key를 입력하세요:\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"PDF 파일을 선택하세요\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # 임시 파일로 저장\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        @st.cache_data(show_spinner=False)\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            except Exception as e:\n",
    "                st.error(f\"오류: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        with st.spinner(\"PDF 분석 중...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF 분석 완료!\")\n",
    "            \n",
    "            # 문서 정보\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"페이지 수\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"청크 수\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"파일 크기\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM 설정\n",
    "            llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "            \n",
    "            # 프롬프트 템플릿\n",
    "            prompt_template = \\\"\\\"\\\"PDF 문서 내용을 바탕으로 질문에 정확히 답해주세요.\n",
    "            \n",
    "            문서 내용: {context}\n",
    "            질문: {question}\n",
    "            \n",
    "            답변:\\\"\\\"\\\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "            \n",
    "            # QA 체인 생성\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # 질문 입력\n",
    "            question = st.text_input(\"질문을 입력하세요:\")\n",
    "            \n",
    "            # 예시 질문\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"📋 문서 요약\"):\n",
    "                    question = \"이 문서의 주요 내용을 요약해주세요.\"\n",
    "            with col2:\n",
    "                if st.button(\"🔑 핵심 키워드\"):\n",
    "                    question = \"이 문서의 핵심 키워드들을 추출해주세요.\"\n",
    "            with col3:\n",
    "                if st.button(\"❓ 주요 논점\"):\n",
    "                    question = \"이 문서에서 다루는 주요 논점들은 무엇인가요?\"\n",
    "            \n",
    "            if st.button(\"질문하기\") and question:\n",
    "                with st.spinner(\"답변 생성 중...\"):\n",
    "                    try:\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        \n",
    "                        # 답변 표시\n",
    "                        st.markdown(\"### 📝 답변\")\n",
    "                        st.write(result[\"result\"])\n",
    "                        \n",
    "                        # 참조 문서\n",
    "                        with st.expander(\"📚 참조 문서\"):\n",
    "                            for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                                st.markdown(f\"**참조 {i+1}:**\")\n",
    "                                st.write(doc.page_content[:400] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"오류: {e}\")\n",
    "            \n",
    "            # 유사도 검색\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### 🔍 유사 문서 검색\")\n",
    "            search_query = st.text_input(\"검색 키워드:\")\n",
    "            \n",
    "            if st.button(\"검색\") and search_query:\n",
    "                try:\n",
    "                    similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                    for i, doc in enumerate(similar_docs):\n",
    "                        with st.expander(f\"결과 {i+1}\"):\n",
    "                            st.write(doc.page_content[:600] + \"...\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"검색 오류: {e}\")\n",
    "        \n",
    "        # 임시 파일 정리\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Key를 입력해주세요.\")\n",
    "    st.info(\"API Key: https://platform.openai.com\")\n",
    "'''\n",
    "    \n",
    "    try:\n",
    "        with open('langchain_pdf_app.py', 'w', encoding='utf-8') as f:\n",
    "            f.write(langchain_app_code)\n",
    "        st.success(\"✅ langchain_pdf_app.py 파일이 생성되었습니다!\")\n",
    "        st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"파일 생성 오류: {e}\")\n",
    "\n",
    "# 설치 가이드\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### 🔧 패키지 설치 및 실행\")\n",
    "\n",
    "st.markdown(\"**필수 패키지 설치:**\")\n",
    "st.code(\"\"\"\n",
    "pip install streamlit\n",
    "pip install langchain\n",
    "pip install langchain-openai\n",
    "pip install langchain-community\n",
    "pip install pypdf\n",
    "pip install faiss-cpu\n",
    "\"\"\", language=\"bash\")\n",
    "\n",
    "st.markdown(\"**실행:**\")\n",
    "st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
