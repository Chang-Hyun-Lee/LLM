{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5984ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:51:05.580 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.580 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:05.605 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (LangChain)\",\n",
    "    page_icon=\"ğŸ“„\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# ì œëª©\n",
    "st.title(\"ğŸ“„ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "st.markdown(\"LangChainì„ í™œìš©í•œ ê³ ê¸‰ PDF ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "# OpenAI API í‚¤ ì…ë ¥\n",
    "api_key = st.text_input(\"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\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    # PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "    uploaded_file = st.file_uploader(\"PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        # ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ì €ì¥\n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                # PDF ë¡œë“œ\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # í…ìŠ¤íŠ¸ ë¶„í• \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                # ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error(f\"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        # ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "        with st.spinner(\"PDFë¥¼ ë¶„ì„í•˜ê³  ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF ë¶„ì„ ì™„ë£Œ!\")\n",
    "            \n",
    "            # ë¬¸ì„œ ì •ë³´ í‘œì‹œ\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"í˜ì´ì§€ ìˆ˜\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"íŒŒì¼ í¬ê¸°\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM ë° ì²´ì¸ ì„¤ì •\n",
    "            llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo\",\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "            prompt_template = \"\"\"\n",
    "            ë‹¹ì‹ ì€ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "            ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "            ë§Œì•½ ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ë‹¤ê³  ëª…ì‹œí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "            ë¬¸ì„œ ë‚´ìš©:\n",
    "            {context}\n",
    "\n",
    "            ì§ˆë¬¸: {question}\n",
    "\n",
    "            ë‹µë³€:\n",
    "            \"\"\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(\n",
    "                template=prompt_template, \n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "            \n",
    "            # RetrievalQA ì²´ì¸ ìƒì„±\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # ì§ˆë¬¸ ì…ë ¥\n",
    "            question = st.text_input(\"PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            # ì˜ˆì‹œ ì§ˆë¬¸ë“¤\n",
    "            st.markdown(\"**ì˜ˆì‹œ ì§ˆë¬¸:**\")\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"ğŸ“‹ ë¬¸ì„œ ìš”ì•½\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\n",
    "            with col2:\n",
    "                if st.button(\"ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ í•µì‹¬ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\"\n",
    "            with col3:\n",
    "                if st.button(\"â“ ì£¼ìš” ë…¼ì \"):\n",
    "                    question = \"ì´ ë¬¸ì„œì—ì„œ ë‹¤ë£¨ëŠ” ì£¼ìš” ë…¼ì ë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "            \n",
    "            if st.button(\"ì§ˆë¬¸í•˜ê¸°\") and question:\n",
    "                with st.spinner(\"LangChainìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
    "                    try:\n",
    "                        # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        answer = result[\"result\"]\n",
    "                        source_docs = result[\"source_documents\"]\n",
    "                        \n",
    "                        # ë‹µë³€ í‘œì‹œ\n",
    "                        st.markdown(\"### ğŸ“ ë‹µë³€\")\n",
    "                        st.write(answer)\n",
    "                        \n",
    "                        # ê´€ë ¨ ë¬¸ì„œ ì²­í¬ í‘œì‹œ\n",
    "                        with st.expander(\"ğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ë‚´ìš©\"):\n",
    "                            for i, doc in enumerate(source_docs):\n",
    "                                st.markdown(f\"**ì°¸ì¡° {i+1}:**\")\n",
    "                                st.write(doc.page_content[:500] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                        \n",
    "                        # ì‹ ë¢°ë„ ì ìˆ˜ (ê°„ë‹¨í•œ ë²„ì „)\n",
    "                        confidence = len([doc for doc in source_docs if question.lower() in doc.page_content.lower()]) / len(source_docs) * 100\n",
    "                        st.progress(confidence/100)\n",
    "                        st.caption(f\"ë‹µë³€ ì‹ ë¢°ë„: {confidence:.0f}%\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "                        st.info(\"API í‚¤ì™€ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "            \n",
    "            # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ê¸°ëŠ¥\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### ğŸ” ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\")\n",
    "            search_query = st.text_input(\"ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            if st.button(\"ê²€ìƒ‰\") and search_query:\n",
    "                with st.spinner(\"ìœ ì‚¬í•œ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘...\"):\n",
    "                    try:\n",
    "                        # ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "                        similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                        \n",
    "                        st.markdown(\"### ğŸ¯ ê²€ìƒ‰ ê²°ê³¼\")\n",
    "                        for i, doc in enumerate(similar_docs):\n",
    "                            with st.expander(f\"ê²°ê³¼ {i+1}\"):\n",
    "                                st.write(doc.page_content[:800] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        else:\n",
    "            st.error(\"PDF ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ì •ë³´\n",
    "        with st.sidebar:\n",
    "            st.markdown(\"### ğŸ¤– LangChain ì‹œìŠ¤í…œ\")\n",
    "            st.markdown(\"\"\"\n",
    "            **ì‚¬ìš© ì¤‘ì¸ ê¸°ìˆ :**\n",
    "            - ğŸ¦œ LangChain Framework\n",
    "            - ğŸ“„ PyPDF Loader\n",
    "            - ğŸ”¤ OpenAI Embeddings\n",
    "            - ğŸ—ƒï¸ FAISS Vector Store\n",
    "            - ğŸ¤– GPT-3.5-turbo\n",
    "            - ğŸ“Š Retrieval QA Chain\n",
    "            \"\"\")\n",
    "            \n",
    "            st.markdown(\"### ğŸ“‹ ì‚¬ìš© ê°€ì´ë“œ\")\n",
    "            st.markdown(\"\"\"\n",
    "            1. OpenAI API Key ì…ë ¥\n",
    "            2. PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "            3. ìë™ ë²¡í„°í™” ë° ì¸ë±ì‹±\n",
    "            4. ì§ˆë¬¸ ë˜ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "            5. AIê°€ ê´€ë ¨ ë‚´ìš© ê¸°ë°˜ ë‹µë³€\n",
    "            \n",
    "            âš ï¸ **íŠ¹ì§•:**\n",
    "            - ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "            - ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ì˜ë¯¸ ê²€ìƒ‰\n",
    "            - ê´€ë ¨ ë¬¸ì„œë§Œ ì°¸ì¡°í•˜ì—¬ ë‹µë³€\n",
    "            - ì°¸ì¡° ì¶œì²˜ ì œê³µ\n",
    "            \"\"\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "    st.info(\"API KeyëŠ” https://platform.openai.comì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # LangChain ì†Œê°œ\n",
    "    with st.expander(\"ğŸ¦œ LangChainì´ë€?\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **LangChain**ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "        \n",
    "        **ì£¼ìš” ê¸°ëŠ¥:**\n",
    "        - **Document Loaders**: ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œ ë¡œë“œ\n",
    "        - **Text Splitters**: í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• \n",
    "        - **Embeddings**: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "        - **Vector Stores**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬\n",
    "        - **Chains**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n",
    "        - **Retrievers**: ê´€ë ¨ ì •ë³´ ê²€ìƒ‰\n",
    "        \n",
    "        ì´ ì‹œìŠ¤í…œì—ì„œëŠ” **RAG (Retrieval Augmented Generation)** íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬\n",
    "        PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì•„ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        \"\"\")\n",
    "\n",
    "# ë…ë¦½ ì‹¤í–‰ íŒŒì¼ ìƒì„±\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### ğŸ’¾ ë…ë¦½ ì‹¤í–‰ íŒŒì¼ ìƒì„±\")\n",
    "\n",
    "if st.button(\"langchain_pdf_app.py íŒŒì¼ ìƒì„±\"):\n",
    "    langchain_app_code = '''import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (LangChain)\",\n",
    "    page_icon=\"ğŸ“„\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"ğŸ“„ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "st.markdown(\"LangChainì„ í™œìš©í•œ ê³ ê¸‰ PDF ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "api_key = st.text_input(\"OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            except Exception as e:\n",
    "                st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        with st.spinner(\"PDF ë¶„ì„ ì¤‘...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF ë¶„ì„ ì™„ë£Œ!\")\n",
    "            \n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"í˜ì´ì§€ ìˆ˜\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"ì²­í¬ ìˆ˜\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"íŒŒì¼ í¬ê¸°\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "            \n",
    "            prompt_template = \\\"\\\"\\\"\n",
    "            PDF ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.\n",
    "            \n",
    "            ë¬¸ì„œ ë‚´ìš©: {context}\n",
    "            ì§ˆë¬¸: {question}\n",
    "            ë‹µë³€:\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "            \n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            question = st.text_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            if st.button(\"ì§ˆë¬¸í•˜ê¸°\") and question:\n",
    "                with st.spinner(\"ë‹µë³€ ìƒì„± ì¤‘...\"):\n",
    "                    try:\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        \n",
    "                        st.markdown(\"### ğŸ“ ë‹µë³€\")\n",
    "                        st.write(result[\"result\"])\n",
    "                        \n",
    "                        with st.expander(\"ì°¸ì¡° ë¬¸ì„œ\"):\n",
    "                            for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                                st.markdown(f\"**ì°¸ì¡° {i+1}:**\")\n",
    "                                st.write(doc.page_content[:300] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "'''\n",
    "    \n",
    "    try:\n",
    "        with open('langchain_pdf_app.py', 'w', encoding='utf-8') as f:\n",
    "            f.write(langchain_app_code)\n",
    "        st.success(\"âœ… langchain_pdf_app.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì„¤ì¹˜ ê°€ì´ë“œ\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### ğŸ”§ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì‹¤í–‰\")\n",
    "\n",
    "st.markdown(\"**í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜:**\")\n",
    "st.code(\"\"\"\n",
    "pip install streamlit\n",
    "pip install langchain\n",
    "pip install langchain-openai\n",
    "pip install langchain-community\n",
    "pip install pypdf\n",
    "pip install faiss-cpu\n",
    "\"\"\", language=\"bash\")\n",
    "\n",
    "st.markdown(\"**ì‹¤í–‰:**\")\n",
    "st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42054551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.97.0)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/.local/lib/python3.10/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /root/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /root/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.8-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/.local/lib/python3.10/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging>=23.2 in /root/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /root/.local/lib/python3.10/site-packages (from langchain-community) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.70-py3-none-any.whl (442 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m582.2/582.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, regex, python-dotenv, propcache, mypy-extensions, multidict, marshmallow, jsonpatch, httpx-sse, greenlet, frozenlist, async-timeout, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
      "\u001b[2K  Attempting uninstall: jsonpatch0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K    Found existing installation: jsonpatch 1.32â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K    Uninstalling jsonpatch-1.32:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K      Successfully uninstalled jsonpatch-1.32â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/28\u001b[0m [marshmallow]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m28/28\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.7.0 greenlet-3.2.3 httpx-sse-0.4.1 jsonpatch-1.33 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.70 langchain-openai-0.3.28 langchain-text-splitters-0.3.8 langsmith-0.4.8 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 regex-2024.11.6 requests-toolbelt-1.0.0 tiktoken-0.9.0 typing-inspect-0.9.0 yarl-1.20.1 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U openai langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44fe1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /root/.local/lib/python3.10/site-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests->google-search-results) (2025.7.14)\n",
      "Building wheels for collected packages: google-search-results\n",
      "\u001b[33m  DEPRECATION: Building 'google-search-results' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-search-results'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32016 sha256=7c7c0c58c1a87659b256e1e8336b86bca74bcbf8f7bbabbb3121850983507597\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /root/.local/lib/python3.10/site-packages (from wikipedia) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /root/.local/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (4.14.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "\u001b[33m  DEPRECATION: Building 'wikipedia' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=4795e6233a72a76411baaecaa79da315bac5db46d70e504336c3421ef8292df9\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /root/.local/lib/python3.10/site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in /root/.local/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /root/.local/lib/python3.10/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /root/.local/lib/python3.10/site-packages (from sentence_transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.5)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /root/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch>=1.11.0->sentence_transformers) (59.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.7.14)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, threadpoolctl, sympy, scipy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, joblib, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence_transformers\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27/27\u001b[0m [sentence_transformers]ence_transformers]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 safetensors-0.5.3 scikit-learn-1.7.1 scipy-1.15.3 sentence_transformers-5.0.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.2 torch-2.7.1 transformers-4.53.3 triton-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /root/.local/lib/python3.10/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results\n",
    "!pip install wikipedia\n",
    "!pip install faiss-cpu \n",
    "!pip install sentence_transformers \n",
    "!pip install tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e37680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:51:52.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.078 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.079 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:51:52.081 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (LangChain)\",\n",
    "    page_icon=\"ğŸ“„\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# ì œëª©\n",
    "st.title(\"ğŸ“„ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "st.markdown(\"LangChainì„ í™œìš©í•œ ê³ ê¸‰ PDF ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "# OpenAI API í‚¤ ì…ë ¥\n",
    "api_key = st.text_input(\"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\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    # PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "    uploaded_file = st.file_uploader(\"PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        # ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ì €ì¥\n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                # PDF ë¡œë“œ\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # í…ìŠ¤íŠ¸ ë¶„í• \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                # ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error(f\"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        # ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "        with st.spinner(\"PDFë¥¼ ë¶„ì„í•˜ê³  ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF ë¶„ì„ ì™„ë£Œ!\")\n",
    "            \n",
    "            # ë¬¸ì„œ ì •ë³´ í‘œì‹œ\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"í˜ì´ì§€ ìˆ˜\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"íŒŒì¼ í¬ê¸°\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM ë° ì²´ì¸ ì„¤ì •\n",
    "            llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo\",\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "            prompt_template = \"\"\"\n",
    "            ë‹¹ì‹ ì€ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "            ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "            ë§Œì•½ ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ë‹¤ê³  ëª…ì‹œí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "            ë¬¸ì„œ ë‚´ìš©:\n",
    "            {context}\n",
    "\n",
    "            ì§ˆë¬¸: {question}\n",
    "\n",
    "            ë‹µë³€:\n",
    "            \"\"\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(\n",
    "                template=prompt_template, \n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "            \n",
    "            # RetrievalQA ì²´ì¸ ìƒì„±\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # ì§ˆë¬¸ ì…ë ¥\n",
    "            question = st.text_input(\"PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            # ì˜ˆì‹œ ì§ˆë¬¸ë“¤\n",
    "            st.markdown(\"**ì˜ˆì‹œ ì§ˆë¬¸:**\")\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"ğŸ“‹ ë¬¸ì„œ ìš”ì•½\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\n",
    "            with col2:\n",
    "                if st.button(\"ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ í•µì‹¬ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\"\n",
    "            with col3:\n",
    "                if st.button(\"â“ ì£¼ìš” ë…¼ì \"):\n",
    "                    question = \"ì´ ë¬¸ì„œì—ì„œ ë‹¤ë£¨ëŠ” ì£¼ìš” ë…¼ì ë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "            \n",
    "            if st.button(\"ì§ˆë¬¸í•˜ê¸°\") and question:\n",
    "                with st.spinner(\"LangChainìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
    "                    try:\n",
    "                        # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        answer = result[\"result\"]\n",
    "                        source_docs = result[\"source_documents\"]\n",
    "                        \n",
    "                        # ë‹µë³€ í‘œì‹œ\n",
    "                        st.markdown(\"### ğŸ“ ë‹µë³€\")\n",
    "                        st.write(answer)\n",
    "                        \n",
    "                        # ê´€ë ¨ ë¬¸ì„œ ì²­í¬ í‘œì‹œ\n",
    "                        with st.expander(\"ğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ë‚´ìš©\"):\n",
    "                            for i, doc in enumerate(source_docs):\n",
    "                                st.markdown(f\"**ì°¸ì¡° {i+1}:**\")\n",
    "                                st.write(doc.page_content[:500] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                        \n",
    "                        # ì‹ ë¢°ë„ ì ìˆ˜ (ê°„ë‹¨í•œ ë²„ì „)\n",
    "                        confidence = len([doc for doc in source_docs if question.lower() in doc.page_content.lower()]) / len(source_docs) * 100\n",
    "                        st.progress(confidence/100)\n",
    "                        st.caption(f\"ë‹µë³€ ì‹ ë¢°ë„: {confidence:.0f}%\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "                        st.info(\"API í‚¤ì™€ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "            \n",
    "            # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ê¸°ëŠ¥\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### ğŸ” ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\")\n",
    "            search_query = st.text_input(\"ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            if st.button(\"ê²€ìƒ‰\") and search_query:\n",
    "                with st.spinner(\"ìœ ì‚¬í•œ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘...\"):\n",
    "                    try:\n",
    "                        # ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "                        similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                        \n",
    "                        st.markdown(\"### ğŸ¯ ê²€ìƒ‰ ê²°ê³¼\")\n",
    "                        for i, doc in enumerate(similar_docs):\n",
    "                            with st.expander(f\"ê²°ê³¼ {i+1}\"):\n",
    "                                st.write(doc.page_content[:800] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        else:\n",
    "            st.error(\"PDF ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ì •ë³´\n",
    "        with st.sidebar:\n",
    "            st.markdown(\"### ğŸ¤– LangChain ì‹œìŠ¤í…œ\")\n",
    "            st.markdown(\"\"\"\n",
    "            **ì‚¬ìš© ì¤‘ì¸ ê¸°ìˆ :**\n",
    "            - ğŸ¦œ LangChain Framework\n",
    "            - ğŸ“„ PyPDF Loader\n",
    "            - ğŸ”¤ OpenAI Embeddings\n",
    "            - ğŸ—ƒï¸ FAISS Vector Store\n",
    "            - ğŸ¤– GPT-3.5-turbo\n",
    "            - ğŸ“Š Retrieval QA Chain\n",
    "            \"\"\")\n",
    "            \n",
    "            st.markdown(\"### ğŸ“‹ ì‚¬ìš© ê°€ì´ë“œ\")\n",
    "            st.markdown(\"\"\"\n",
    "            1. OpenAI API Key ì…ë ¥\n",
    "            2. PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "            3. ìë™ ë²¡í„°í™” ë° ì¸ë±ì‹±\n",
    "            4. ì§ˆë¬¸ ë˜ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "            5. AIê°€ ê´€ë ¨ ë‚´ìš© ê¸°ë°˜ ë‹µë³€\n",
    "            \n",
    "            âš ï¸ **íŠ¹ì§•:**\n",
    "            - ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "            - ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ì˜ë¯¸ ê²€ìƒ‰\n",
    "            - ê´€ë ¨ ë¬¸ì„œë§Œ ì°¸ì¡°í•˜ì—¬ ë‹µë³€\n",
    "            - ì°¸ì¡° ì¶œì²˜ ì œê³µ\n",
    "            \"\"\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "    st.info(\"API KeyëŠ” https://platform.openai.comì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # LangChain ì†Œê°œ\n",
    "    with st.expander(\"ğŸ¦œ LangChainì´ë€?\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **LangChain**ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "        \n",
    "        **ì£¼ìš” ê¸°ëŠ¥:**\n",
    "        - **Document Loaders**: ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œ ë¡œë“œ\n",
    "        - **Text Splitters**: í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• \n",
    "        - **Embeddings**: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "        - **Vector Stores**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬\n",
    "        - **Chains**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n",
    "        - **Retrievers**: ê´€ë ¨ ì •ë³´ ê²€ìƒ‰\n",
    "        \n",
    "        ì´ ì‹œìŠ¤í…œì—ì„œëŠ” **RAG (Retrieval Augmented Generation)** íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬\n",
    "        PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì•„ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        \"\"\")\n",
    "\n",
    "# ë…ë¦½ ì‹¤í–‰ íŒŒì¼ ìƒì„±\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### ğŸ’¾ ë…ë¦½ ì‹¤í–‰ íŒŒì¼ ìƒì„±\")\n",
    "\n",
    "if st.button(\"langchain_pdf_app.py íŒŒì¼ ìƒì„±\"):\n",
    "    langchain_app_code = '''import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (LangChain)\",\n",
    "    page_icon=\"ğŸ“„\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"ğŸ“„ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "st.markdown(\"LangChainì„ í™œìš©í•œ ê³ ê¸‰ PDF ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "api_key = st.text_input(\"OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        @st.cache_data\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            except Exception as e:\n",
    "                st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        with st.spinner(\"PDF ë¶„ì„ ì¤‘...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF ë¶„ì„ ì™„ë£Œ!\")\n",
    "            \n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"í˜ì´ì§€ ìˆ˜\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"ì²­í¬ ìˆ˜\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"íŒŒì¼ í¬ê¸°\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "            \n",
    "            prompt_template = \\\"\\\"\\\"\n",
    "            PDF ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.\n",
    "            \n",
    "            ë¬¸ì„œ ë‚´ìš©: {context}\n",
    "            ì§ˆë¬¸: {question}\n",
    "            ë‹µë³€:\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "            \n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            question = st.text_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            if st.button(\"ì§ˆë¬¸í•˜ê¸°\") and question:\n",
    "                with st.spinner(\"ë‹µë³€ ìƒì„± ì¤‘...\"):\n",
    "                    try:\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        \n",
    "                        st.markdown(\"### ğŸ“ ë‹µë³€\")\n",
    "                        st.write(result[\"result\"])\n",
    "                        \n",
    "                        with st.expander(\"ì°¸ì¡° ë¬¸ì„œ\"):\n",
    "                            for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                                st.markdown(f\"**ì°¸ì¡° {i+1}:**\")\n",
    "                                st.write(doc.page_content[:300] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "'''\n",
    "    \n",
    "    try:\n",
    "        with open('langchain_pdf_app.py', 'w', encoding='utf-8') as f:\n",
    "            f.write(langchain_app_code)\n",
    "        st.success(\"âœ… langchain_pdf_app.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì„¤ì¹˜ ê°€ì´ë“œ\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### ğŸ”§ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì‹¤í–‰\")\n",
    "\n",
    "st.markdown(\"**í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜:**\")\n",
    "st.code(\"\"\"\n",
    "pip install streamlit\n",
    "pip install langchain\n",
    "pip install langchain-openai\n",
    "pip install langchain-community\n",
    "pip install pypdf\n",
    "pip install faiss-cpu\n",
    "\"\"\", language=\"bash\")\n",
    "\n",
    "st.markdown(\"**ì‹¤í–‰:**\")\n",
    "st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "539db25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /root/.local/lib/python3.10/site-packages (1.47.0)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.27)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.11.0.post1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.1.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /root/.local/lib/python3.10/site-packages (from streamlit) (2.2.6)\n",
      "Requirement already satisfied: packaging<26,>=20 in /root/.local/lib/python3.10/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (2.3.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.31.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /root/.local/lib/python3.10/site-packages (from streamlit) (2.32.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /root/.local/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /root/.local/lib/python3.10/site-packages (from streamlit) (4.14.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /root/.local/lib/python3.10/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /root/.local/lib/python3.10/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /root/.local/lib/python3.10/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in /root/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /root/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /root/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.48.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /root/.local/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /root/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.70)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.97.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.local/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /root/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /root/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /root/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:54:01.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-22 16:54:01.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ - LangChain í™œìš© ë²„ì „\n",
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (Jupyterì—ì„œ ì‹¤í–‰ ì‹œ)\n",
    "!pip install streamlit langchain langchain-openai langchain-community pypdf faiss-cpu\n",
    "\n",
    "# Jupyter Notebookì—ì„œ Streamlit ê²½ê³  í•´ê²°\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (LangChain)\",\n",
    "    page_icon=\"ğŸ“„\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# ì œëª©\n",
    "st.title(\"ğŸ“„ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "st.markdown(\"LangChainì„ í™œìš©í•œ ê³ ê¸‰ PDF ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "# OpenAI API í‚¤ ì…ë ¥\n",
    "api_key = st.text_input(\"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\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    # PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "    uploaded_file = st.file_uploader(\"PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        # ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ì €ì¥ (ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”)\n",
    "        @st.cache_data(show_spinner=False)\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                # PDF ë¡œë“œ\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # í…ìŠ¤íŠ¸ ë¶„í• \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                # ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error(f\"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        # ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "        with st.spinner(\"PDFë¥¼ ë¶„ì„í•˜ê³  ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF ë¶„ì„ ì™„ë£Œ!\")\n",
    "            \n",
    "            # ë¬¸ì„œ ì •ë³´ í‘œì‹œ\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"í˜ì´ì§€ ìˆ˜\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"íŒŒì¼ í¬ê¸°\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM ë° ì²´ì¸ ì„¤ì •\n",
    "            llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo\",\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "            prompt_template = \"\"\"\n",
    "            ë‹¹ì‹ ì€ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "            ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "            ë§Œì•½ ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ë‹¤ê³  ëª…ì‹œí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "            ë¬¸ì„œ ë‚´ìš©:\n",
    "            {context}\n",
    "\n",
    "            ì§ˆë¬¸: {question}\n",
    "\n",
    "            ë‹µë³€:\n",
    "            \"\"\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(\n",
    "                template=prompt_template, \n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "            \n",
    "            # RetrievalQA ì²´ì¸ ìƒì„±\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # ì§ˆë¬¸ ì…ë ¥\n",
    "            question = st.text_input(\"PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            # ì˜ˆì‹œ ì§ˆë¬¸ë“¤\n",
    "            st.markdown(\"**ì˜ˆì‹œ ì§ˆë¬¸:**\")\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"ğŸ“‹ ë¬¸ì„œ ìš”ì•½\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\n",
    "            with col2:\n",
    "                if st.button(\"ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ í•µì‹¬ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\"\n",
    "            with col3:\n",
    "                if st.button(\"â“ ì£¼ìš” ë…¼ì \"):\n",
    "                    question = \"ì´ ë¬¸ì„œì—ì„œ ë‹¤ë£¨ëŠ” ì£¼ìš” ë…¼ì ë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "            \n",
    "            if st.button(\"ì§ˆë¬¸í•˜ê¸°\") and question:\n",
    "                with st.spinner(\"LangChainìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
    "                    try:\n",
    "                        # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        answer = result[\"result\"]\n",
    "                        source_docs = result[\"source_documents\"]\n",
    "                        \n",
    "                        # ë‹µë³€ í‘œì‹œ\n",
    "                        st.markdown(\"### ğŸ“ ë‹µë³€\")\n",
    "                        st.write(answer)\n",
    "                        \n",
    "                        # ê´€ë ¨ ë¬¸ì„œ ì²­í¬ í‘œì‹œ\n",
    "                        with st.expander(\"ğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ë‚´ìš©\"):\n",
    "                            for i, doc in enumerate(source_docs):\n",
    "                                st.markdown(f\"**ì°¸ì¡° {i+1}:**\")\n",
    "                                st.write(doc.page_content[:500] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                        \n",
    "                        # ì‹ ë¢°ë„ ì ìˆ˜ (ê°„ë‹¨í•œ ë²„ì „)\n",
    "                        confidence = len([doc for doc in source_docs if question.lower() in doc.page_content.lower()]) / len(source_docs) * 100\n",
    "                        st.progress(confidence/100)\n",
    "                        st.caption(f\"ë‹µë³€ ì‹ ë¢°ë„: {confidence:.0f}%\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "                        st.info(\"API í‚¤ì™€ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "            \n",
    "            # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ê¸°ëŠ¥\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### ğŸ” ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\")\n",
    "            search_query = st.text_input(\"ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            if st.button(\"ê²€ìƒ‰\") and search_query:\n",
    "                with st.spinner(\"ìœ ì‚¬í•œ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘...\"):\n",
    "                    try:\n",
    "                        # ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "                        similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                        \n",
    "                        st.markdown(\"### ğŸ¯ ê²€ìƒ‰ ê²°ê³¼\")\n",
    "                        for i, doc in enumerate(similar_docs):\n",
    "                            with st.expander(f\"ê²°ê³¼ {i+1}\"):\n",
    "                                st.write(doc.page_content[:800] + \"...\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        else:\n",
    "            st.error(\"PDF ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ì •ë³´\n",
    "        with st.sidebar:\n",
    "            st.markdown(\"### ğŸ¤– LangChain ì‹œìŠ¤í…œ\")\n",
    "            st.markdown(\"\"\"\n",
    "            **ì‚¬ìš© ì¤‘ì¸ ê¸°ìˆ :**\n",
    "            - ğŸ¦œ LangChain Framework\n",
    "            - ğŸ“„ PyPDF Loader\n",
    "            - ğŸ”¤ OpenAI Embeddings\n",
    "            - ğŸ—ƒï¸ FAISS Vector Store\n",
    "            - ğŸ¤– GPT-3.5-turbo\n",
    "            - ğŸ“Š Retrieval QA Chain\n",
    "            \"\"\")\n",
    "            \n",
    "            st.markdown(\"### ğŸ“‹ ì‚¬ìš© ê°€ì´ë“œ\")\n",
    "            st.markdown(\"\"\"\n",
    "            1. OpenAI API Key ì…ë ¥\n",
    "            2. PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "            3. ìë™ ë²¡í„°í™” ë° ì¸ë±ì‹±\n",
    "            4. ì§ˆë¬¸ ë˜ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "            5. AIê°€ ê´€ë ¨ ë‚´ìš© ê¸°ë°˜ ë‹µë³€\n",
    "            \n",
    "            âš ï¸ **íŠ¹ì§•:**\n",
    "            - ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "            - ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ì˜ë¯¸ ê²€ìƒ‰\n",
    "            - ê´€ë ¨ ë¬¸ì„œë§Œ ì°¸ì¡°í•˜ì—¬ ë‹µë³€\n",
    "            - ì°¸ì¡° ì¶œì²˜ ì œê³µ\n",
    "            \"\"\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "    st.info(\"API KeyëŠ” https://platform.openai.comì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # LangChain ì†Œê°œ\n",
    "    with st.expander(\"ğŸ¦œ LangChainì´ë€?\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **LangChain**ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "        \n",
    "        **ì£¼ìš” ê¸°ëŠ¥:**\n",
    "        - **Document Loaders**: ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œ ë¡œë“œ\n",
    "        - **Text Splitters**: í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• \n",
    "        - **Embeddings**: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "        - **Vector Stores**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬\n",
    "        - **Chains**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n",
    "        - **Retrievers**: ê´€ë ¨ ì •ë³´ ê²€ìƒ‰\n",
    "        \n",
    "        ì´ ì‹œìŠ¤í…œì—ì„œëŠ” **RAG (Retrieval Augmented Generation)** íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬\n",
    "        PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì•„ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        \"\"\")\n",
    "\n",
    "# ë…ë¦½ ì‹¤í–‰ íŒŒì¼ ìƒì„±\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### ğŸ’¾ ë…ë¦½ ì‹¤í–‰ íŒŒì¼ ìƒì„±\")\n",
    "\n",
    "if st.button(\"langchain_pdf_app.py íŒŒì¼ ìƒì„±\"):\n",
    "    langchain_app_code = '''# LangChain PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (LangChain)\",\n",
    "    page_icon=\"ğŸ“„\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"ğŸ“„ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "st.markdown(\"LangChainì„ í™œìš©í•œ ê³ ê¸‰ PDF ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "api_key = st.text_input(\"OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getbuffer())\n",
    "            tmp_file_path = tmp_file.name\n",
    "        \n",
    "        @st.cache_data(show_spinner=False)\n",
    "        def create_vectorstore(_file_path):\n",
    "            try:\n",
    "                loader = PyPDFLoader(_file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200\n",
    "                )\n",
    "                texts = text_splitter.split_documents(documents)\n",
    "                \n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "                \n",
    "                return vectorstore, len(texts), len(documents)\n",
    "            except Exception as e:\n",
    "                st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "                return None, 0, 0\n",
    "        \n",
    "        with st.spinner(\"PDF ë¶„ì„ ì¤‘...\"):\n",
    "            vectorstore, num_chunks, num_pages = create_vectorstore(tmp_file_path)\n",
    "        \n",
    "        if vectorstore:\n",
    "            st.success(\"PDF ë¶„ì„ ì™„ë£Œ!\")\n",
    "            \n",
    "            # ë¬¸ì„œ ì •ë³´\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"í˜ì´ì§€ ìˆ˜\", num_pages)\n",
    "            with col2:\n",
    "                st.metric(\"ì²­í¬ ìˆ˜\", num_chunks)\n",
    "            with col3:\n",
    "                st.metric(\"íŒŒì¼ í¬ê¸°\", f\"{uploaded_file.size/1024:.1f} KB\")\n",
    "            \n",
    "            # LLM ì„¤ì •\n",
    "            llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "            \n",
    "            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "            prompt_template = \\\"\\\"\\\"PDF ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•´ì£¼ì„¸ìš”.\n",
    "            \n",
    "            ë¬¸ì„œ ë‚´ìš©: {context}\n",
    "            ì§ˆë¬¸: {question}\n",
    "            \n",
    "            ë‹µë³€:\\\"\\\"\\\"\n",
    "            \n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "            \n",
    "            # QA ì²´ì¸ ìƒì„±\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "            # ì§ˆë¬¸ ì…ë ¥\n",
    "            question = st.text_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:\")\n",
    "            \n",
    "            # ì˜ˆì‹œ ì§ˆë¬¸\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                if st.button(\"ğŸ“‹ ë¬¸ì„œ ìš”ì•½\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\n",
    "            with col2:\n",
    "                if st.button(\"ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ\"):\n",
    "                    question = \"ì´ ë¬¸ì„œì˜ í•µì‹¬ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\"\n",
    "            with col3:\n",
    "                if st.button(\"â“ ì£¼ìš” ë…¼ì \"):\n",
    "                    question = \"ì´ ë¬¸ì„œì—ì„œ ë‹¤ë£¨ëŠ” ì£¼ìš” ë…¼ì ë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "            \n",
    "            if st.button(\"ì§ˆë¬¸í•˜ê¸°\") and question:\n",
    "                with st.spinner(\"ë‹µë³€ ìƒì„± ì¤‘...\"):\n",
    "                    try:\n",
    "                        result = qa_chain({\"query\": question})\n",
    "                        \n",
    "                        # ë‹µë³€ í‘œì‹œ\n",
    "                        st.markdown(\"### ğŸ“ ë‹µë³€\")\n",
    "                        st.write(result[\"result\"])\n",
    "                        \n",
    "                        # ì°¸ì¡° ë¬¸ì„œ\n",
    "                        with st.expander(\"ğŸ“š ì°¸ì¡° ë¬¸ì„œ\"):\n",
    "                            for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                                st.markdown(f\"**ì°¸ì¡° {i+1}:**\")\n",
    "                                st.write(doc.page_content[:400] + \"...\")\n",
    "                                st.markdown(\"---\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "            \n",
    "            # ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"### ğŸ” ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\")\n",
    "            search_query = st.text_input(\"ê²€ìƒ‰ í‚¤ì›Œë“œ:\")\n",
    "            \n",
    "            if st.button(\"ê²€ìƒ‰\") and search_query:\n",
    "                try:\n",
    "                    similar_docs = vectorstore.similarity_search(search_query, k=3)\n",
    "                    for i, doc in enumerate(similar_docs):\n",
    "                        with st.expander(f\"ê²°ê³¼ {i+1}\"):\n",
    "                            st.write(doc.page_content[:600] + \"...\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
    "        try:\n",
    "            os.unlink(tmp_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    st.warning(\"OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "    st.info(\"API Key: https://platform.openai.com\")\n",
    "'''\n",
    "    \n",
    "    try:\n",
    "        with open('langchain_pdf_app.py', 'w', encoding='utf-8') as f:\n",
    "            f.write(langchain_app_code)\n",
    "        st.success(\"âœ… langchain_pdf_app.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì„¤ì¹˜ ê°€ì´ë“œ\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### ğŸ”§ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì‹¤í–‰\")\n",
    "\n",
    "st.markdown(\"**í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜:**\")\n",
    "st.code(\"\"\"\n",
    "pip install streamlit\n",
    "pip install langchain\n",
    "pip install langchain-openai\n",
    "pip install langchain-community\n",
    "pip install pypdf\n",
    "pip install faiss-cpu\n",
    "\"\"\", language=\"bash\")\n",
    "\n",
    "st.markdown(\"**ì‹¤í–‰:**\")\n",
    "st.code(\"streamlit run langchain_pdf_app.py\", language=\"bash\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
