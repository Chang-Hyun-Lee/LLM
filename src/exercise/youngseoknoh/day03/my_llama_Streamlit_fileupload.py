import streamlit as st
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex
from llama_index.llms.openai import OpenAI
import os
import shutil

# ì„ì‹œ ì—…ë¡œë“œ ë””ë ‰í† ë¦¬
UPLOAD_DIR = "uploaded_docs"

st.set_page_config(page_title="ë¬¸ì„œ ì„¤ëª… ì±—ë´‡", layout="centered")
st.title("ğŸ“„ ë¬¸ì„œ ì„¤ëª… ì–´í”Œë¦¬ì¼€ì´ì…˜")

# ì—…ë¡œë“œ ì²˜ë¦¬
uploaded_file = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF, TXT ë“±)", type=["pdf", "txt", "md"])
if uploaded_file:
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    if os.path.exists(UPLOAD_DIR):
        shutil.rmtree(UPLOAD_DIR)
    os.makedirs(UPLOAD_DIR, exist_ok=True)

    # íŒŒì¼ ì €ì¥
    with open(os.path.join(UPLOAD_DIR, uploaded_file.name), "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.success(f"'{uploaded_file.name}' ì—…ë¡œë“œ ì™„ë£Œ!")

    # ë°ì´í„° ë¡œë“œ ë° ì¸ë±ì‹±
    with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        documents = SimpleDirectoryReader(UPLOAD_DIR).load_data()
        index = VectorStoreIndex.from_documents(documents)
        query_engine = index.as_query_engine(llm=OpenAI(model="gpt-4"))

    # ì§ˆì˜ì°½
    user_question = st.text_input("ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”:")
    if user_question:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            response = query_engine.query(user_question)
            st.markdown("### ğŸ¤– ë‹µë³€:")
            st.write(response.response)

    # ìš”ì•½ ë²„íŠ¼
    if st.button("ë¬¸ì„œ ì „ì²´ ìš”ì•½"):
        with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
            summary = query_engine.query("ì´ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì¤˜.")
            st.markdown("### ğŸ“ ìš”ì•½:")
            st.write(summary)
