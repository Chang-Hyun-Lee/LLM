import streamlit as st
from openai import OpenAI
import os

# OpenAI client ê°ì²´ ìƒì„± (í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ìŒ)
client = OpenAI()

# Streamlit ì„¤ì •
st.set_page_config(page_title="Chat with GPT", page_icon="ğŸ’¬")
st.title("ğŸ’¬ GPT ë©€í‹°í„´ ì±„íŒ…")

# ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤."}]

# ì´ì „ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages[1:]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

if prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° ì¶œë ¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # GPT ì‘ë‹µ ì¶œë ¥
    with st.chat_message("assistant"):
        with st.spinner("GPTê°€ ìƒê° ì¤‘..."):
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=st.session_state.messages,
                stream=True
            )

            full_response = ""
            placeholder = st.empty()
            for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    placeholder.markdown(full_response)

    # ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})