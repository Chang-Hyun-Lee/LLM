{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit=\"섭씨\"):\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"24\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"지금 서울날씨를 섭씨로 알려줘.\"}]\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"특정 지역의 날씨를 알려줍니다.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"지역이름. 예) 서울, 부산, 제주도\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"섭씨\", \"화씨\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"서울\",\"unit\":\"섭씨\"}', name='get_current_weather'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = messages,\n",
    "    functions = functions,\n",
    "    function_call = \"auto\",\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 서울의 날씨는 섭씨 24도이며, 맑고 바람이 불고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "if response_message.function_call is not None:\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }\n",
    "    function_name = response_message.function_call.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args['location'],\n",
    "        unit=function_args['unit']\n",
    "    )\n",
    "\n",
    "    messages.append(response_message)\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9u7VdIra004EVU2Ez1qe1i9L', function=Function(arguments='{\"location\":\"대전\",\"unit\":\"섭씨\"}', name='get_current_weather'), type='function')])\n",
      "ChatCompletionMessageToolCall(id='call_9u7VdIra004EVU2Ez1qe1i9L', function=Function(arguments='{\"location\":\"대전\",\"unit\":\"섭씨\"}', name='get_current_weather'), type='function')\n",
      "<class 'openai.types.chat.chat_completion_message_tool_call.ChatCompletionMessageToolCall'>\n",
      "<class 'openai.types.chat.chat_completion_message_tool_call.Function'>\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"지금 대전 날씨를 섭씨로 알려줘.\"}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\":\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"특정 지역의 날씨를 알려줍니다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"지역이름. 예) 서울, 부산, 제주도\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"섭씨\", \"화씨\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\" if tools is not None else None\n",
    "    )\n",
    "response_message = response.choices[0].message\n",
    "print(response_message)\n",
    "print(response_message.tool_calls[0])\n",
    "print(type(response_message.tool_calls[0]))\n",
    "print(type(response_message.tool_calls[0].function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 대전의 날씨는 약 24도 섭씨입니다. 맑고 바람이 부는 날씨입니다.\n"
     ]
    }
   ],
   "source": [
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}\n",
    "\n",
    "for tool_call in response_message.tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args['location'],\n",
    "        unit=function_args['unit']\n",
    "    )\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": json.dumps(function_response, ensure_ascii=False)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "second_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '지금 대전 날씨를 섭씨로 알려줘.'}, {'tool_call_id': 'call_9u7VdIra004EVU2Ez1qe1i9L', 'role': 'function', 'name': 'get_current_weather', 'content': '\"{\\\\\"location\\\\\": \\\\\"\\\\\\\\ub300\\\\\\\\uc804\\\\\", \\\\\"temperature\\\\\": \\\\\"24\\\\\", \\\\\"unit\\\\\": \\\\\"\\\\\\\\uc12d\\\\\\\\uc528\\\\\", \\\\\"forecast\\\\\": [\\\\\"sunny\\\\\", \\\\\"windy\\\\\"]}\"'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.38.0-py3-none-any.whl (59.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn>=0.14.0\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tomlkit<0.14.0,>=0.12.0\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Collecting typer<1.0,>=0.12\n",
      "  Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart>=0.0.18\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/lib/python3/dist-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/lib/python3/dist-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (11.3.0)\n",
      "Collecting fastapi<1.0,>=0.115.2\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (4.14.1)\n",
      "Collecting orjson~=3.0\n",
      "  Downloading orjson-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==1.11.0\n",
      "  Downloading gradio_client-1.11.0-py3-none-any.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.5/324.5 KB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (2.2.6)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n",
      "Collecting brotli>=1.1.0\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ruff>=0.9.3\n",
      "  Downloading ruff-0.12.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/lib/python3/dist-packages (from gradio) (5.4.1)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (2.3.1)\n",
      "Collecting aiofiles<25.0,>=22.0\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Collecting semantic-version~=2.0\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting groovy~=0.1\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio) (2.11.7)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting huggingface-hub>=0.28.1\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 KB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websockets<16.0,>=10.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 KB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5.0,>=3.0->gradio) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 KB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from typer<1.0,>=0.12->gradio) (8.0.3)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (1.26.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, brotli, uvicorn, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, mdurl, hf-xet, groovy, fsspec, filelock, ffmpy, aiofiles, markdown-it-py, huggingface-hub, starlette, rich, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "Successfully installed aiofiles-24.1.0 brotli-1.1.0 fastapi-0.116.1 ffmpy-0.6.0 filelock-3.18.0 fsspec-2025.7.0 gradio-5.38.0 gradio-client-1.11.0 groovy-0.1.2 hf-xet-1.1.5 huggingface-hub-0.33.4 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.11.0 pydub-0.25.1 python-multipart-0.0.20 rich-14.0.0 ruff-0.12.4 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.47.2 tomlkit-0.13.3 typer-0.16.0 uvicorn-0.35.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://e5ae8192f198687136.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e5ae8192f198687136.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"ㅎㅇ \" + name + \"씨!\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn = greet,\n",
    "    inputs = gr.Textbox(),\n",
    "    outputs = \"text\"\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/route_utils.py\", line 350, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 2235, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1746, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/utils.py\", line 917, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_37877/2720801309.py\", line 2, in sepia\n",
      "    sepia_filter = np.array([\n",
      "NameError: name 'np' is not defined\n"
     ]
    }
   ],
   "source": [
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189],\n",
    "        [0.349, 0.686, 0.168],\n",
    "        [0.272, 0.534, 0.131]    \n",
    "    ])\n",
    "\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, gr.Image(width=200, height=200), \"image\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37877/1231079666.py:39: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "/tmp/ipykernel_37877/1231079666.py:39: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/route_utils.py\", line 350, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 2235, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1758, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/utils.py\", line 762, in async_iteration\n",
      "    return await anext(iterator)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/utils.py\", line 753, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/utils.py\", line 736, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/gradio/utils.py\", line 900, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "  File \"/tmp/ipykernel_37877/1231079666.py\", line 20, in bot\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/openai/lib/_old_api.py\", line 39, in __call__\n",
      "openai.lib._old_api.APIRemovedInV1: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.update(value=\"\", interactive=False)\n",
    "\n",
    "def add_file(history, file):\n",
    "    history = history + [((file.name,), None)]\n",
    "    return history\n",
    "\n",
    "def bot(history):\n",
    "    user_message = history[-1][0]  # 마지막 사용자 입력\n",
    "\n",
    "    # ✅ GPT에게 메시지 전달\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",  # 또는 \"gpt-4\" 등\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"당신은 친절한 AI 챗봇입니다.\"},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        stream=True  # ⏳ 스트리밍으로 출력\n",
    "    )\n",
    "\n",
    "    history[-1][1] = \"\"  # 답변 초기화\n",
    "\n",
    "    for chunk in response:\n",
    "        if 'choices' in chunk and len(chunk['choices']) > 0:\n",
    "            delta = chunk['choices'][0]['delta']\n",
    "            if 'content' in delta:\n",
    "                history[-1][1] += delta['content']\n",
    "                yield history  # 실시간 업데이트\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        [],\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        avatar_images=(None, (os.path.join(\"avatar.png\"))),\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            scale=4,\n",
    "            show_label=False,\n",
    "            placeholder=\"텍스트를 입력하고 엔터를 치거나 이미지를 업로드하세요\",\n",
    "            container=False,\n",
    "        )\n",
    "        btn = gr.UploadButton(\"Upload\", file_types=[\"image\", \"video\", \"audio\"])\n",
    "\n",
    "    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(server_name='0.0.0.0')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
