{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdcaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d307e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ìŠµ1: ì—”ë¹„ë””ì•„ì˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë¶„ì„í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "# ì‹¤ìŠµ2: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§€ì—­ê³¼ ì§ˆë¬¸ì— ë§ëŠ” ì§€ì—­ ìŒì‹ì ì„ ê²€ìƒ‰í•´ì„œ ì¶”ì²œí•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.\n",
    "# ì˜ˆ) íŒêµì— ìˆëŠ” ê´œì°®ì€ ì´íƒˆë¦¬ì•ˆ ì‹ë‹¹ì„ ëª‡ê°œ ì¶”ì²œí•´ì¤„ë˜?\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ìŠµ1: ì—”ë¹„ë””ì•„ì˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë¶„ì„í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "import yfinance as yf\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import openai\n",
    "\n",
    "end = datetime.now()\n",
    "start = end - relativedelta(years=1)\n",
    "\n",
    "df = yf.download(\"NVDA\", start, end)\n",
    "df.columns = ['Close','High','Low','Open','Volume']\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer)\n",
    "\n",
    "csv_data = csv_buffer.getvalue()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¤ìŒì€ ì—”ë¹„ë””ì•„ì˜ ë‚ ì§œë³„ ì£¼ê°€ ë°ì´í„°ì•¼. ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì„œ ë³´ê³ í•´ì¤˜. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ëŠ” ì—†ì• ê³  í…ìŠ¤íŠ¸ë¡œë§Œ ì¶œë ¥í•´ì¤˜\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": csv_data\n",
    "    }\n",
    "  ],\n",
    "  temperature = 0,\n",
    "  max_tokens = 1024,\n",
    "  top_p = 1,\n",
    "  frequency_penalty = 0,\n",
    "  presence_penalty = 0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ìŠµ2: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§€ì—­ê³¼ ì§ˆë¬¸ì— ë§ëŠ” ì§€ì—­ ìŒì‹ì ì„ ê²€ìƒ‰í•´ì„œ ì¶”ì²œí•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.\n",
    "# ì˜ˆ) íŒêµì— ìˆëŠ” ê´œì°®ì€ ì´íƒˆë¦¬ì•ˆ ì‹ë‹¹ì„ ëª‡ê°œ ì¶”ì²œí•´ì¤„ë˜?\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import urllib.request\n",
    "\n",
    "client_id = \"cWCyG67A6biwOuThF11b\"\n",
    "client_secret = \"itwHxt2ACJ\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "question = input(\"ğŸ“¢ ë‚˜ì—ê²Œ ì§ˆë¬¸í•´ë´\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì§€ì—­ëª…(location), ì—…ì¢…(category), ê°¯ìˆ˜(count)ë¥¼ ì¶”ì¶œí•´ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\n",
    "                    ì§€ì—­ëª…ì„ ë™ê¹Œì§€ í•´ì„œ ë” ìì„¸íˆ ë½‘ì•„ì„œ ì‘ë‹µí•˜ì„¸ìš”.\n",
    "                    locationì´ë‚˜ categoryì— ì—¬ëŸ¬ ê°œê°€ ìˆëŠ” ê²½ìš° ,(ì‰¼í‘œ)ë¡œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.\n",
    "                    ì˜ˆ:{\\\"location\\\": \\\"ë™íƒ„ ì„ìš°ë™,ë¶€ì‚° ë‹¹ê°ë™\\\", \\\"category\\\": \\\"ë§›ì§‘,ì¹´í˜\\\", \\\"count\\\": 5}\n",
    "                 \"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": question\n",
    "    }\n",
    "  ],\n",
    "  temperature = 0,\n",
    "  max_tokens = 1024,\n",
    "  top_p = 1,\n",
    "  frequency_penalty = 0,\n",
    "  presence_penalty = 0\n",
    ")\n",
    "\n",
    "parsed = json.loads(response.choices[0].message.content)\n",
    "locations = [loc.strip() for loc in parsed.get(\"location\", \"\").split(\",\")]\n",
    "categories = [cat.strip() for cat in parsed.get(\"category\", \"\").split(\",\")]\n",
    "count = parsed.get(\"count\", 3)\n",
    "\n",
    "def search_naver_local(query, count):\n",
    "    encText = urllib.parse.quote(query)\n",
    "    url = f\"https://openapi.naver.com/v1/search/local.json?query={encText}&display={count}\"\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\", client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "\n",
    "    if rescode == 200:\n",
    "        response_body = response.read()\n",
    "        data = json.loads(response_body.decode('utf-8'))\n",
    "        return data.get(\"items\", [])\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "for loc in locations:\n",
    "    for cat in categories:\n",
    "        keyword = f\"{loc} {cat}\"\n",
    "        print(f\"\\nğŸ” {keyword} ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "        results = search_naver_local(keyword, count)\n",
    "        if not results:\n",
    "            print(\"  âŒ ê²°ê³¼ ì—†ìŒ\")\n",
    "        for i, item in enumerate(results, 1):\n",
    "            print(f\"  [{i}] {item['title'].strip('<b>').strip('</b>')}\")\n",
    "            print(f\"     ì£¼ì†Œ: {item['address']}\")\n",
    "            print(f\"     ë§í¬: {item['link']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ìŠµ: ì‚¼ì„±ì „ì ì£¼ê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ function(tool)ìœ¼ë¡œ ìˆ˜ì •í•˜ì—¬, \n",
    "# ë‹¤ë¥¸ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ ì •í•´ì§„ ë‚´ìš©ëŒ€ë¡œ(ì¢…ëª©, ì‹œì‘ë‚ ì§œ, ì¢…ë£Œë‚ ì§œ) ê°€ì ¸ì™€ì„œ ë‹µí•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "def get_current_weather(location, unit=\"ì„­ì”¨\"):\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"24\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"ì§€ê¸ˆ ì„œìš¸ë‚ ì”¨ë¥¼ ì„­ì”¨ë¡œ ì•Œë ¤ì¤˜.\"}]\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"íŠ¹ì • ì§€ì—­ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"ì§€ì—­ì´ë¦„. ì˜ˆ) ì„œìš¸, ë¶€ì‚°, ì œì£¼ë„\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"ì„­ì”¨\", \"í™”ì”¨\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ìŠµ1: gradioì˜ chatbot interfaceë¥¼ ì‚¬ìš©í•˜ì—¬ ChatGPTì™€ ìŠ¤íŠ¸ë¦¬ë°í•˜ë©´ì„œ ëŒ€í™”í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì„±í•˜ì‹œì˜¤.\n",
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.update(value=\"\", interactive=False)\n",
    "\n",
    "def add_file(history, file):\n",
    "    history = history + [((file.name,), None)]\n",
    "    return history\n",
    "\n",
    "def bot(history):\n",
    "    user_message = history[-1][0]  # ë§ˆì§€ë§‰ ì‚¬ìš©ì ì…ë ¥\n",
    "\n",
    "    # âœ… GPTì—ê²Œ ë©”ì‹œì§€ ì „ë‹¬\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # ë˜ëŠ” \"gpt-4\" ë“±\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.\"},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        stream=True  # â³ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥\n",
    "    )\n",
    "\n",
    "    history[-1][1] = \"\"  # ë‹µë³€ ì´ˆê¸°í™”\n",
    "\n",
    "    for chunk in response:\n",
    "        if 'choices' in chunk and len(chunk['choices']) > 0:\n",
    "            delta = chunk['choices'][0]['delta']\n",
    "            if 'content' in delta:\n",
    "                history[-1][1] += delta['content']\n",
    "                yield history  # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        [],\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        avatar_images=(None, (os.path.join(\"avatar.png\"))),\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            scale=4,\n",
    "            show_label=False,\n",
    "            placeholder=\"í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  ì—”í„°ë¥¼ ì¹˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\",\n",
    "            container=False,\n",
    "        )\n",
    "        btn = gr.UploadButton(\"Upload\", file_types=[\"image\", \"video\", \"audio\"])\n",
    "\n",
    "    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(server_name='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cad776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‹¤ìŠµ2: ë§Œë“  ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ë©€í‹°í„´ìœ¼ë¡œ ìˆ˜ì •í•˜ì‹œì˜¤.\n",
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.update(value=\"\", interactive=False)\n",
    "\n",
    "def add_file(history, file):\n",
    "    history = history + [((file.name,), None)]\n",
    "    return history\n",
    "\n",
    "def bot(history):\n",
    "    # ì „ì²´ history â†’ GPT ë©”ì‹œì§€ í¬ë§·ìœ¼ë¡œ ë³€í™˜\n",
    "    messages = [{\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.\"}]\n",
    "    for user, assistant in history[:-1]:\n",
    "        messages.append({\"role\": \"user\", \"content\": user})\n",
    "        if assistant is not None:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ì¶”ê°€\n",
    "    messages.append({\"role\": \"user\", \"content\": history[-1][0]})\n",
    "\n",
    "    # GPT í˜¸ì¶œ\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    history[-1][1] = \"\"\n",
    "    for chunk in response:\n",
    "        if \"choices\" in chunk and len(chunk[\"choices\"]) > 0:\n",
    "            delta = chunk[\"choices\"][0][\"delta\"]\n",
    "            if \"content\" in delta:\n",
    "                history[-1][1] += delta[\"content\"]\n",
    "                yield history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        [],\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        avatar_images=(None, (os.path.join(\"chat.jpg\"))),\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            scale=4,\n",
    "            show_label=False,\n",
    "            placeholder=\"í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  ì—”í„°ë¥¼ ì¹˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\",\n",
    "            container=False,\n",
    "        )\n",
    "        btn = gr.UploadButton(\"Upload\", file_types=[\"image\", \"video\", \"audio\"])\n",
    "\n",
    "    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc17d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì†Œë…€ì™€ ê¹€ì†Œì—°ì˜ ê´€ê³„ì— ëŒ€í•œ ì •ë³´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ë‘ ì¸ë¬¼ ê°„ì˜ ê´€ê³„ì— ëŒ€í•´ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‹¤ìŠµ: langchainì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ pdf íŒŒì¼ì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ëŠ” ChatGPT ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.\n",
    "# !pip install -qU pypdf\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "loader = PyPDFLoader(\"ì†Œë‚˜ê¸°.pdf\")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "#embeddings = HuggingFaceEmbeddings() # sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding = embeddings,\n",
    ").from_loaders([loader])\n",
    "\n",
    "index.query(\"ì†Œë…€ì™€ ê¹€ì†Œì—°ì€ ì–´ë–¤ ê´€ê³„ì¸ê°€?\", llm = model, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
