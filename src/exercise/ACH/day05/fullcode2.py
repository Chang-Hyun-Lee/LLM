import os
import streamlit as st
import json
from pykrx import stock

from langchain import hub
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import tool
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import SystemMessagePromptTemplate
from langchain_core.messages import HumanMessage, AIMessage

# ------- ì£¼ì‹ ë„êµ¬ -------
@tool
def get_market_ohlcv(start_date, end_date, ticker):
    """Return prices within given dates for ticker stock. start_date and end_date should be 'YYYYMMDD' format."""
    start_date = start_date.strip()
    end_date = end_date.strip()
    ticker = ticker.strip()
    stock_name = stock.get_market_ticker_name(ticker)
    df = stock.get_market_ohlcv(start_date, end_date, ticker)
    df['ì¢…ëª©ëª…'] = [stock_name] * len(df)
    return json.dumps(df.to_dict(orient='records'), ensure_ascii=False)

# ------- ì£¼ì‹ í‚¤ì›Œë“œ íŒë³„ -------
def is_stock_question(text):
    stock_keywords = [
        "ì£¼ê°€", "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "í‹°ì»¤", "ì°¨íŠ¸", "ìƒì¥", "KRX", "PER", "EPS",
        "ë§¤ì¶œ", "ì¬ë¬´", "ì¢…ëª©", "ì‹œê°€ì´ì•¡", "ë°°ë‹¹", "ê±°ë˜ëŸ‰", "ê°€ê²©", "ì£¼ì‹", "ì ì •ê°€ì¹˜", "íˆ¬ì",
        "ì‚¼ì„±ì „ì", "ì¹´ì¹´ì˜¤", "ë„¤ì´ë²„", "LGì—ë„ˆì§€", "í˜„ëŒ€ì°¨", "POSCO", "SKí•˜ì´ë‹‰ìŠ¤"
    ]
    return any(k in text for k in stock_keywords)

# ------- ì£¼ì‹ Agent ì´ˆê¸°í™” -------
@st.cache_resource
def init_agent():
    openai_api_key = os.getenv("OPENAI_API_KEY")
    model = ChatOpenAI(model="gpt-4o-mini", temperature=0, openai_api_key=openai_api_key, streaming=False)
    prompt = hub.pull("hwchase17/openai-tools-agent")
    prompt.messages[0] = SystemMessagePromptTemplate.from_template(
        "ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì£¼ì‹ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì¢…ëª©, ì°¨íŠ¸, ì£¼ê°€, ê¸°ì—… ë“± ì£¼ì‹ ë° íˆ¬ì ê´€ë ¨ ì •ë³´ë¥¼ ìš”ì²­ë°›ìœ¼ë©´ ì „ë¬¸ì ìœ¼ë¡œ ì˜ê²¬ì„ ë‚´ì–´ ë¶„ì„í•´ ì£¼ì„¸ìš”."
    )
    tools = [get_market_ohlcv]
    agent = create_openai_tools_agent(
        model.with_config({"tags": ["agent_llm"]}), tools, prompt
    )
    agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(
        {"run_name": "Agent"}
    )
    return model, agent_executor

# ------- ë©”ì‹œì§€ ë³€í™˜ (Streamlit â†’ LangChain) -------
def convert_to_langchain_messages(messages):
    langchain_msgs = []
    for m in messages:
        if m["role"] == "user":
            langchain_msgs.append(HumanMessage(content=m["content"]))
        elif m["role"] == "assistant":
            langchain_msgs.append(AIMessage(content=m["content"]))
    return langchain_msgs

# ------- ì¼ë°˜ LLM ë©€í‹°í„´ ì²˜ë¦¬ -------
def call_general_llm(messages):
    openai_api_key = os.getenv("OPENAI_API_KEY")
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, openai_api_key=openai_api_key, streaming=False)
    langchain_messages = convert_to_langchain_messages(messages)
    return llm.predict_messages(langchain_messages).content

# ------- ì£¼ì‹ Agent ë‹¨ë°œ ì²˜ë¦¬ -------
def chat_with_bot(agent_executor, messages):
    # í˜„ì¬ LangChain AgentëŠ” ë©€í‹°í„´ ì§€ì›ì´ ì•½í•¨ â†’ ìµœì‹  user ë©”ì‹œì§€ë§Œ ì‚¬ìš©
    user_input = messages[-1]["content"]
    response = agent_executor.invoke({"input": user_input})
    return response["output"]

# ------- Streamlit App -------
def main():
    st.title("ğŸ“ˆ ë©€í‹° ì±—ë´‡: ì£¼ì‹ + ì¼ë°˜ ëŒ€í™”")

    model, agent_executor = init_agent()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì´ì „ ëŒ€í™” ì¶œë ¥
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input(placeholder="ëŒ€í™”ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    if user_input:
        # ë©”ì‹œì§€ ì €ì¥ ë° ì¶œë ¥
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # ì‘ë‹µ ìƒì„±
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            if is_stock_question(user_input):
                response = chat_with_bot(agent_executor, st.session_state.messages)
            else:
                response = call_general_llm(st.session_state.messages)

        # ì‘ë‹µ ì €ì¥ ë° ì¶œë ¥
        st.session_state.messages.append({"role": "assistant", "content": response})
        with st.chat_message("assistant"):
            st.markdown(response)

# ------- ì‹¤í–‰ -------
if __name__ == "__main__":
    main()
