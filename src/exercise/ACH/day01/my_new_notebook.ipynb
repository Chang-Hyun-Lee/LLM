{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d7422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(42+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d6812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ã“ã‚“ã«ã¡ã¯ï¼Ÿä»Šæ—¥ã®å¤©æ°—ã¯ã¨ã¦ã‚‚è‰¯ã„ã§ã™ã­ï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\n",
    "response = openai.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt = \"ë‹¤ìŒì„ ì¼ë³¸ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”: ì•ˆë…•í•˜ì„¸ìš”? ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹êµ°ìš”!\",\n",
    "    max_tokens=256,  # ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3673e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë‚´ê°€ ë¨¹ì–´ì•¼ í•  ê²ƒ\n",
      "\n",
      "- ë‹¨ë°±ì§ˆ\n",
      "\n",
      "\n",
      "- ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì•„ë¯¸ë…¸ì‚°ì´ í•¨ìœ ëœ ë‹¨ë°±ì§ˆ ì‹í’ˆì„ ë¨¹ì–´ì•¼ í•œë‹¤. ì´ë¥¼í…Œë©´ ë‹­ê°€ìŠ´ì‚´, ì‚´ë¡œëª¬, ê³„ë€, ì½©, ë•…ì½©, ê·¸ë¦¬ê³  ìœ ì œí’ˆ ë“±ì´ ê·¸ë ‡ë‹¤. ë‹¨ë°±ì§ˆì€ ê·¼ìœ¡ì˜ ì„±ì¥ê³¼ ë³´ìˆ˜ë¥¼ ìœ„í•œ í•„ìˆ˜ ì˜ì–‘ì†Œì´ê¸° ë•Œë¬¸ì´ë‹¤.\n",
      "2. íƒ„ìˆ˜í™”ë¬¼\n",
      "- ê·¼ìœ¡ì„ í‚¤ìš°ê¸° ìœ„í•´ì„œëŠ” ì¶©ë¶„í•œ ì—ë„ˆì§€ê°€ í•„ìš”í•œë°, íƒ„ìˆ˜í™”ë¬¼ì€ ê·¸ëŸ° ì—ë„ˆì§€ì›ìœ¼ë¡œì„œ ì¤‘ìš”í•˜ë‹¤. ë‹¤ë§Œ, ê³¼ë„í•œ ì„­ì·¨ëŠ” ì‚´ì´ ì°Œê³  ê·¼ìœ¡ë§ˆì € ê¹ì´ê²Œ ëœë‹¤ëŠ” ì ì„ ìœ ì˜í•´ì•¼ í•œë‹¤. ê·¸ëŸ¬\n"
     ]
    }
   ],
   "source": [
    "# Completion mode, ë¬¸ì¥ì„ ì´ì–´ì„œ ì™„ì„±í•˜ê²Œ í•¨\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\n",
    "response = openai.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"ê·¼ìœ¡ì´ ì»¤ì§€ë ¤ë©´\",\n",
    "    max_tokens=256,  # ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "# ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8038d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-Bvd9BinaDL8uQmzoLvKF2KMPR8Cov', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' ë‚´ê°€ ë¨¹ì–´ì•¼ í•  ê²ƒ\\n\\n- ë‹¨ë°±ì§ˆ\\n\\n\\n- ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì•„ë¯¸ë…¸ì‚°ì´ í•¨ìœ ëœ ë‹¨ë°±ì§ˆ ì‹í’ˆì„ ë¨¹ì–´ì•¼ í•œë‹¤. ì´ë¥¼í…Œë©´ ë‹­ê°€ìŠ´ì‚´, ì‚´ë¡œëª¬, ê³„ë€, ì½©, ë•…ì½©, ê·¸ë¦¬ê³  ìœ ì œí’ˆ ë“±ì´ ê·¸ë ‡ë‹¤. ë‹¨ë°±ì§ˆì€ ê·¼ìœ¡ì˜ ì„±ì¥ê³¼ ë³´ìˆ˜ë¥¼ ìœ„í•œ í•„ìˆ˜ ì˜ì–‘ì†Œì´ê¸° ë•Œë¬¸ì´ë‹¤.\\n2. íƒ„ìˆ˜í™”ë¬¼\\n- ê·¼ìœ¡ì„ í‚¤ìš°ê¸° ìœ„í•´ì„œëŠ” ì¶©ë¶„í•œ ì—ë„ˆì§€ê°€ í•„ìš”í•œë°, íƒ„ìˆ˜í™”ë¬¼ì€ ê·¸ëŸ° ì—ë„ˆì§€ì›ìœ¼ë¡œì„œ ì¤‘ìš”í•˜ë‹¤. ë‹¤ë§Œ, ê³¼ë„í•œ ì„­ì·¨ëŠ” ì‚´ì´ ì°Œê³  ê·¼ìœ¡ë§ˆì € ê¹ì´ê²Œ ëœë‹¤ëŠ” ì ì„ ìœ ì˜í•´ì•¼ í•œë‹¤. ê·¸ëŸ¬')], created=1753074877, model='gpt-3.5-turbo-instruct:20230824-v2', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=256, prompt_tokens=11, total_tokens=267, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aaee766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ë²• ì •ì •\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë¬¸ì¥ì„ ì…ë ¥ë°›ê³  ì´ë¥¼ í‘œì¤€ í•œêµ­ì–´ë¡œ ë³€ê²½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ê·¸ ë¨¸ìŠ¤ë§ˆê°€ ë‹ˆ ë§ˆìŒì— ì•ˆë“±ë‹¤ ê·¸ ì¹´ë“œë‚˜? ê³„ì† ê¼¬ì‹œë³´ì§€?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82783112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ ì•„ì´ê°€ ë§ˆìŒì— ì•ˆ ë“¤ì§€? ê·¸ ì¹´ë“œë„? ê³„ì† ìœ í˜¹í•˜ê³  ìˆì§€?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae1dc8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¸”ë™í™€ì€ ì•„ì£¼ í° ê³µê°„ì—ì„œ ë¬¼ì²´ë¥¼ ëŒì–´ë‹¹ê¸°ëŠ” í˜ì´ ê°•í•œ ê³³ì´ì—ìš”. ê·¸ëŸ°ë° ë¸”ë™í™€ë„ ì‹œê°„ì´ ì§€ë‚˜ë©´ ì—†ì–´ì§ˆ ìˆ˜ ìˆì–´ìš”. ë¸”ë™í™€ì€ 'í˜¸í‚¹ ë³µì‚¬'ë¼ëŠ” ë°©ë²•ìœ¼ë¡œ ì•„ì£¼ ì‘ì€ ì…ìë¥¼ ë°–ìœ¼ë¡œ ë‚´ë³´ë‚´ë©´ì„œ ì ì  ì‘ì•„ì ¸ìš”. \n",
      "\n",
      "ë¸”ë™í™€ì´ ì‘ì•„ì§€ë©´ ì ì  ë°ì•„ì§€ê³ , ë§ˆì§€ë§‰ì—ëŠ” ì•„ì£¼ ê°•í•œ ë¹›ì„ ë‚´ë©´ì„œ ì‚¬ë¼ì ¸ìš”. í•˜ì§€ë§Œ ë¸”ë™í™€ì´ ì‚¬ë¼ì§€ê¸°ê¹Œì§€ëŠ” ì •ë§ ê¸´ ì‹œê°„ì´ ê±¸ë ¤ìš”. ì˜ˆë¥¼ ë“¤ì–´, íƒœì–‘ë§Œí•œ ë¸”ë™í™€ì´ ë‹¤ ì—†ì–´ì§€ë ¤ë©´ 34ì²œì–µì–µ ë…„ì´ ê±¸ë¦°ë‹¤ê³  í•´ìš”! \n",
      "\n",
      "í˜„ì¬ ë°œê²¬ëœ ë¸”ë™í™€ë“¤ì€ ëª¨ë‘ íƒœì–‘ë³´ë‹¤ ë” í¬ê¸° ë•Œë¬¸ì— ì‚¬ë¼ì§€ë ¤ë©´ í›¨ì”¬ ë” ê¸´ ì‹œê°„ì´ í•„ìš”í•´ìš”. ë¸”ë™í™€ì´ ì‚¬ë¼ì§ˆ ë•Œ ë‚˜ì˜¤ëŠ” ë¹›ì€ ì•„ì£¼ ê°•í•˜ì§€ë§Œ, ìš°ë¦¬ê°€ ëŠë¼ê¸°ì—ëŠ” ë©€ë¦¬ ë–¨ì–´ì ¸ì„œ ì˜ ë³´ì´ì§€ ì•Šì„ ê±°ì˜ˆìš”. ì§€ê¸ˆê¹Œì§€ ê·¸ëŸ° ì¼ì´ ì¼ì–´ë‚¬ë‹¤ëŠ” ì¦ê±°ëŠ” ì—†ë‹µë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ìš”ì•½\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ë‚´ìš©ì„ ìœ ì¹˜ì›ìƒì—ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ë¸”ë™í™€ë„ ìˆ˜ëª…ì´ ìˆìœ¼ë©°, í˜¸í‚¹ ë³µì‚¬ë¡œ ì…ìë¥¼ ë°©ì¶œí•˜ë‹¤ ì§ˆëŸ‰ì´ ì¤„ì–´ë“¤ì–´ ê²°êµ­ì—” ì‚¬ë¼ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ëœë‹¤. \n",
    "ì§ˆëŸ‰ì„ ìƒìœ¼ë©´ì„œ ë¸”ë™í™€ì€ ì¡°ê¸ˆì”© ë°ì•„ì§€ë©°, ê±°ì˜ ë§ˆì§€ë§‰ì—” ì¦ë°œì´ ì‹¬í•´ì ¸ì„œ ì°½ë°±í•˜ê²Œ ë¹›ë‚˜ë©° ê³ ì—ë„ˆì§€ ê°ë§ˆì„ ê³¼ ì†Œë¦½ìë¥¼ ë°©ì¶œí•œë‹¤. \n",
    "ë§ˆì§€ë§‰ì—ëŠ” ê°ë§ˆì„  í­ë°œì´ë¼ê³  í•´ë„ ë  ì •ë„ë¡œ ê²©ë ¬í•˜ê²Œ ê°ë§ˆì„ ì„ ë°©ì¶œí•˜ë©´ì„œ ì¦ë°œí•˜ê³  ì†Œë©¸í•œë‹¤. \n",
    "ë‹¤ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆëŠ” ë¸”ë™í™€ë“¤ì´ ì´ í­ë°œê¹Œì§€ ë„ë‹¬í•˜ë ¤ë©´ ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ë©°, \n",
    "ì§ˆëŸ‰ì´ íƒœì–‘ ì •ë„ì¸ ë¸”ë™í™€ì´ ì¦ë°œí•´ì„œ ì†Œë©¸í•  ë•Œê¹Œì§€ëŠ” ì•½ 3.4Ã—1067ë…„ ì •ë„ê°€ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ì¶”ì •ëœë‹¤. \n",
    "ê·¸ë¦¬ê³  ë¸”ë™í™€ì˜ ìˆ˜ëª…ì€ ì§ˆëŸ‰ì— ë¹„ë¡€í•˜ë©°, í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ ë¸”ë™í™€ë“¤ì€ ëª¨ë‘ íƒœì–‘ ì§ˆëŸ‰ ì´ìƒì´ë¯€ë¡œ ì¦ë°œí•˜ëŠ” ë°ì—ëŠ” ê·¸ë³´ë‹¤ ë” ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦°ë‹¤. \n",
    "ë˜í•œ ë¸”ë™í™€ì˜ ì†Œë©¸ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê°ë§ˆì„  í­ë°œì˜ ê·œëª¨ëŠ” ê·¸ë¦¬ í¬ì§€ ì•Šì•„ íƒœì–‘ê³„ ì£¼ë³€ì—ì„œ ë°œìƒí•œ ê²½ìš°ê°€ ì•„ë‹ˆë©´ ë°œê²¬í•˜ê¸°ê°€ ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©° \n",
    "í˜„ì¬ê¹Œì§€ ê´€ì¸¡ëœ ì‚¬ë¡€ê°€ ì—†ë‹¤.\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890471f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```csv\n",
      "ì¢…ë¥˜,íŠ¹ì§•,ì„œì‹ì§€,ëª¸ê¸¸ì´(cm),ë¶€ë¦¬ê¸¸ì´(cm)\n",
      "í† ì½”,ê²€ì€ ëª¸ì²´ì™€ í° ì£¼í™©ìƒ‰ ë¶€ë¦¬,ì•„ë§ˆì¡´ ìš°ë¦¼ê³¼ ì¤‘ë‚¨ë¯¸ì˜ ì—´ëŒ€ìš°ë¦¼,60-65,20 ì´ìƒ\n",
      "í™©ê¸ˆì‚¬ìë°•ìƒˆ,í™©ê¸ˆìƒ‰ ë¶€ë¦¬ì™€ í™©ê¸ˆìƒ‰ ê¹ƒí„¸,ì—´ëŒ€ìš°ë¦¼ê³¼ ì¹˜ë§ˆí­í¬,20-25,NA\n",
      "ì¹´ë¼ì¹´ë¼,ë°±ìƒ‰ê³¼ ê²€ì€ìƒ‰ ëª¸ì²´,ì‚¬ë§‰ ì§€ì—­ê³¼ ì´ˆì› ì§€ì—­,50-60,NA\n",
      "íœ˜íŒŒëŒìƒˆ,íšŒìƒ‰ê³¼ ê°ˆìƒ‰ ê¹ƒí„¸,ë‚¨ë¯¸ì˜ ì‚°ë¦¼ ì§€ì—­,20-30,NA\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥ í¬ë§·\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë°›ì€ ë°ì´í„°ë¥¼ CSV í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ë‚¨ë¯¸ ëŒ€ë¥™ì€ ë‹¤ì–‘í•œ í™˜ê²½ê³¼ ê¸°í›„ë¥¼ ê°€ì§€ê³  ìˆì–´ ìˆ˜ë§ì€ ìƒˆ ì¢…ë¥˜ê°€ ì„œì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤. \n",
    "í† ì½”ëŠ” ê²€ì€ ëª¸ì²´ì™€ í° ì£¼í™©ìƒ‰ ë¶€ë¦¬ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ëª¸ ì¸¡ë©´ì—ëŠ” ì£¼í™©ìƒ‰ê³¼ í°ìƒ‰ì˜ íŒ¨í„´ì´ ìˆìŠµë‹ˆë‹¤. \n",
    "í† ì½”ëŠ” ì£¼ë¡œ ì•„ë§ˆì¡´ ìš°ë¦¼ê³¼ ì¤‘ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì—´ëŒ€ìš°ë¦¼ ì§€ì—­ì—ì„œ ë°œê²¬ë©ë‹ˆë‹¤. í‰ê· ì ìœ¼ë¡œ ëª¸ê¸¸ì´ê°€ ì•½ 60~65cm ì •ë„ì´ë©° ë¶€ë¦¬ì˜ ê¸¸ì´ëŠ” 20cm ì´ìƒì— ë‹¬í•©ë‹ˆë‹¤. \n",
    "í™©ê¸ˆì‚¬ìë°•ìƒˆëŠ” í™©ê¸ˆìƒ‰ ë¶€ë¦¬ì™€ ìœ ëª…í•œ í™©ê¸ˆìƒ‰ ê¹ƒí„¸ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­ì—ì„œ ë°œê²¬ë˜ëŠ”ë°, ì£¼ë¡œ ì—´ëŒ€ìš°ë¦¼ê³¼ ì¹˜ë§ˆí­í¬, ì•„ë§ˆì¡´ ìš°ë¦¼ ë“± \n",
    "ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­ì—ì„œ ì„œì‹í•©ë‹ˆë‹¤. ì´ ìƒˆëŠ” ì¤‘í˜• ìƒˆë¡œ, ëª¸ê¸¸ì´ëŠ” ì•½ 20~25cm ì •ë„ì…ë‹ˆë‹¤. ì¹´ë¼ì¹´ë¼ëŠ” ë°±ìƒ‰ê³¼ ê²€ì€ìƒ‰ì˜ ëª¸ì²´ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, \n",
    "ëˆˆ ì£¼ìœ„ì—ëŠ” ì£¼í™©ìƒ‰ íŒ¨ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ì£¼ë¡œ ì‚¬ë§‰ ì§€ì—­ê³¼ ì´ˆì› ì§€ì—­ì—ì„œ ë°œê²¬ë˜ë©°, ë‚¨ë¯¸ ì „ì—­ì— ë¶„í¬í•˜ê³  ìˆê³ , ëª¸ê¸¸ì´ëŠ” ì•½ 50~60cm ì •ë„ì…ë‹ˆë‹¤. \n",
    "íœ˜íŒŒëŒìƒˆëŠ” ì£¼ë¡œ íšŒìƒ‰ê³¼ ê°ˆìƒ‰ ê¹ƒí„¸ë¡œ ë®ì—¬ ìˆìœ¼ë©°, ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì‚°ë¦¼ ì§€ì—­ì—ì„œ ë°œê²¬ë˜ëŠ”ë°, ë‚˜ë¬´ë‚˜ ë°”ìœ„ì— ì•‰ì•„ ë°¤ì— ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤. \n",
    "ì´ ìƒˆì˜ ëª¸ê¸¸ì´ëŠ” ì•½ 20~30cm ì •ë„ì…ë‹ˆë‹¤.\n",
    "ì´ê²ƒì€ ë‚¨ë¯¸ì—ì„œ ë°œê²¬ë˜ëŠ” ëª‡ ê°€ì§€ ë‹¤ì–‘í•œ ìƒˆ ì¢…ë¥˜ ì¤‘ ì¼ë¶€ì— ëŒ€í•œ ê°„ëµí•œ ì†Œê°œì…ë‹ˆë‹¤. ë‚¨ë¯¸ ëŒ€ë¥™ì—ëŠ” ë” ë‹¤ì–‘í•œ ìƒˆë“¤ì´ ì„œì‹í•˜ê³  ìˆìœ¼ë©°, \n",
    "ì´ ì§€ì—­ì€ ìƒë¬¼ ë‹¤ì–‘ì„±ì´ í’ë¶€í•œ ê³³ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=0.1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ëª¨ì§€\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ì„¸ìš”. ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ì•ˆë˜ë©°, ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ë§‘ì•˜ë‹¤ê°€ ë¹„ê°€ ì™”ë‹¤ê°€ ì°¸ ë³€í™”ë¬´ìŒí•˜ë„¤ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93aca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½”ë“œ ì„¤ëª…\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ì½”ë“œì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "import heapq\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None, cost=0, heuristic=0):\n",
    "        self.state = state \n",
    "        self.parent = parent\n",
    "        self.cost = cost  \n",
    "        self.heuristic = heuristic \n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return (self.cost + self.heuristic) < (other.cost + other.heuristic)\n",
    "\n",
    "def astar(graph, start, goal):\n",
    "    open_list = []\n",
    "    closed_list = set()\n",
    "\n",
    "    start_node = Node(state=start, cost=0, heuristic=heuristic_estimate(start, goal))\n",
    "    heapq.heappush(open_list, start_node)\n",
    "\n",
    "    while open_list:\n",
    "        current_node = heapq.heappop(open_list)\n",
    "\n",
    "        if current_node.state == goal:\n",
    "            return reconstruct_path(current_node)\n",
    "\n",
    "        closed_list.add(current_node.state)\n",
    "\n",
    "        for neighbor, cost in graph[current_node.state]:\n",
    "            if neighbor in closed_list:\n",
    "                continue\n",
    "\n",
    "            tentative_cost = current_node.cost + cost\n",
    "            heuristic = heuristic_estimate(neighbor, goal)\n",
    "            neighbor_node = Node(state=neighbor, parent=current_node, cost=tentative_cost, heuristic=heuristic)\n",
    "\n",
    "            if not is_in_open_list(open_list, neighbor_node) or tentative_cost < get_node_cost(open_list, neighbor_node):\n",
    "                heapq.heappush(open_list, neighbor_node)\n",
    "\n",
    "    return None\n",
    "\n",
    "def heuristic_estimate(node, goal):\n",
    "    return abs(node[0] - goal[0]) + abs(node[1] - goal[1])\n",
    "\n",
    "def is_in_open_list(open_list, node):\n",
    "    return any(node.state == n.state and node.cost + node.heuristic >= n.cost + n.heuristic for n in open_list)\n",
    "\n",
    "def get_node_cost(open_list, node):\n",
    "    for n in open_list:\n",
    "        if node.state == n.state:\n",
    "            return n.cost\n",
    "    return float('inf')\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node:\n",
    "        path.insert(0, node.state)\n",
    "        node = node.parent\n",
    "    return path\n",
    "\n",
    "graph = {\n",
    "    (0, 0): [((0, 1), 1), ((1, 0), 1)],\n",
    "    (0, 1): [((0, 0), 1), ((0, 2), 1)],\n",
    "    (0, 2): [((0, 1), 1), ((1, 2), 1)],\n",
    "    (1, 0): [((0, 0), 1), ((2, 0), 1)],\n",
    "    (1, 2): [((0, 2), 1), ((2, 2), 1)],\n",
    "    (2, 0): [((1, 0), 1), ((2, 1), 1)],\n",
    "    (2, 1): [((2, 0), 1), ((2, 2), 1)],\n",
    "    (2, 2): [((1, 2), 1), ((2, 1), 1)],\n",
    "}\n",
    "\n",
    "start_node = (0, 0)\n",
    "goal_node = (2, 2)\n",
    "\n",
    "path = astar(graph, start_node, goal_node)\n",
    "\n",
    "if path:\n",
    "    print(\"ìµœì  ê²½ë¡œ:\", path)\n",
    "    print(\"ì´ ë¹„ìš©:\", len(path) - 1) \n",
    "else:\n",
    "    print(\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "      \n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6de0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ë¬¸ë‹¨ì—ì„œ í•µì‹¬ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•˜ê³  ë‚˜ì—´í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ì•„ì´ìœ ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì‹±ì–´ì†¡ë¼ì´í„°ì´ì ë°°ìš°ì´ë‹¤.\n",
    "2008ë…„ 9ì›” 18ì¼, ì¤‘í•™êµ 3í•™ë…„ì´ë˜ ë§Œ 15ì„¸ì˜ ë‚˜ì´ì— ê°€ìˆ˜ë¡œ ë°ë·”í–ˆë‹¤. ì˜ˆëª…ì¸ 'ì•„ì´ìœ 'ëŠ” 'ë„ˆì™€ ë‚´ê°€ ìŒì•…ìœ¼ë¡œ í•˜ë‚˜ê°€ ëœë‹¤'ë¼ëŠ” ëœ»ì„ ê°€ì§€ê³  ìˆë‹¤. \n",
    "ë§¤ë ¥ì ì¸ ìŒìƒ‰ê³¼ ë›°ì–´ë‚œ ì‘ì‚¬/ì‘ê³¡ ëŠ¥ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ì´ëŒì´ì ì•„í‹°ìŠ¤íŠ¸ë¡œì„œ ì‹­ìˆ˜ ë…„ì§¸ ì‚¬ë‘ ë°›ê³  ìˆì„ ë¿ ì•„ë‹ˆë¼ 2012ë…„ ì´ë˜ë¡œ ë§¤ë…„ êµ­ë‚´ ë° ì•„ì‹œì•„ì˜ \n",
    "ì£¼ìš” ë„ì‹œì—ì„œ ëŒ€ê·œëª¨ ì½˜ì„œíŠ¸ë¥¼ ì§„í–‰í•˜ë©° ê³µì—°ìë¡œì„œë„ í™œë°œíˆ í™œë™ ì¤‘ì´ë‹¤.\n",
    "ê°€ìˆ˜ í™œë™ ì™¸ì—ë„ ê°ì¢… ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì— ì¶œì—°í–ˆìœ¼ë©°, ë°ë·” ì´ë˜ 80í¸ì´ ë„˜ëŠ” ê´‘ê³ ë¥¼ ì§„í–‰í–ˆì„ ì •ë„ë¡œ ë‹¤ìˆ˜ì˜ ê´‘ê³  ëª¨ë¸ë¡œë„ í™œì•½ ì¤‘ì´ë‹¤. \n",
    "2011ë…„ì— ì—°ê¸°ìë¡œ ë°ë·”í•œ í›„ì—ëŠ” ë‹¤ì–‘í•œ ë“œë¼ë§ˆì™€ ì˜í™”ì—ì„œ ì—°ê¸° í™œë™ë„ í™œë°œí•˜ê²Œ í¼ì¹˜ê³  ìˆë‹¤. ì—°ì˜ˆê³„ì—ì„œëŠ” ê·¸ì•¼ë§ë¡œ ì˜¬ë¼ìš´ë”ë¡œ ì¸ì • ë°›ëŠ” \n",
    "ë§ŒëŠ¥ ì—”í„°í…Œì´ë„ˆì´ë©°, ì´ ë•Œë¬¸ì— ë‚¨ë…€ë¶ˆë¬¸ ìˆ˜ë§ì€ ì•„ì´ëŒë“¤ì˜ ë¡¤ëª¨ë¸ë¡œ ê¾¸ì¤€íˆ ê¼½íˆê³  ìˆë‹¤.\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2efaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¤ìŒì˜ ì£¼ì–´ì§„ ì„¤ëª…ì— ë§ëŠ” í•œê¸€ ì œí’ˆëª…ì„ 10ê°œ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ì œí’ˆ: ê°€ì •ìš© ìŠ¬ëŸ¬ì‹œ ì œì¡°ê¸°\n",
    "íŠ¹ì§•: ë¹ ë¥´ë‹¤, ì‹¸ë‹¤, ê´€ë¦¬ê°€ í¸í•˜ë‹¤\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug fix\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ì½”ë“œì—ì„œ ë²„ê·¸ë¥¼ ì°¾ê³  ê³ ì¹˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")      \n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7634575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ì • ë¶„ì„\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ê¸ì •, ì¤‘ë¦½, ë¶€ì •ìœ¼ë¡œ ê°ì •ì„ ë¶„ì„í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì´ ì˜í™”ëŠ” ëˆì´ ì•„ê¹Œì™€ì„œ ëˆˆë¬¼ì´ ë‚œë‹¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¸Œë ˆì¸ ìŠ¤í† ë°\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"AIì— ëŒ€í•´ ë¸Œë ˆì¸ ìŠ¤í† ë°í•˜ì—¬ ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸ì„ 5ê°œ ì´ìƒ ë‚´ë³´ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.6,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few shot \n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¹ì‹ ì€ ë¬´ë¡€í•˜ê³  ë¶ˆì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"1kgì„ íŒŒìš´ë“œë¡œ ë³€í™˜í•˜ë©´ ì–¼ë§ˆì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"ë˜ ë¬¼ì–´ë´? 1kgì€ 2.2íŒŒìš´ë“œì•¼. ì¢€ ì ì–´ë†“ë˜ê°€.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"HTMLì€ ë¬´ì—‡ì˜ ì•½ìì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"êµ¬ê¸€ë§í•˜ëŠ”ë° ë¬¸ì œê°€ ìˆëƒ? Hypertext Markup Languageì§€.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì²˜ìŒìœ¼ë¡œ ë¹„í–‰ê¸°ê°€ ë‚ ì•˜ë˜ ë•ŒëŠ” ì–¸ì œì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"1903ë…„ 12ì›” 17ì¼ ë¼ì´íŠ¸í˜•ì œê°€ ì²˜ìŒìœ¼ë¡œ ë¹„í–‰ê¸°ë¥¼ ë„ì› ì§€. ë„¤ ì§ˆë¬¸ì„ ë“£ê³  ìˆìœ¼ë‹ˆ ë‚˜ë„ ë‚ ì•„ê°€ë²„ë¦¬ê³  ì‹¶ë„¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì§€ê¸ˆ ëª‡ì‹œì•¼?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸í„°ë·° ì§ˆë¬¸ ì‘ì„±\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"5ë…„ì°¨ ë°±ì—”ë“œ ìë°” ê°œë°œì ë©´ì ‘ì— ì‚¬ìš©í•  ì§ˆë¬¸ 8ê°œë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½”ë”©\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë™ì˜ìƒ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ ê·¸ì— ëŒ€í•œ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶œë ¥í•˜ëŠ” python codeë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3770a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¤ìŒ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "from typing import List\n",
    "            \n",
    "def has_sum_k(nums: List[int], k: int) -> bool:\n",
    "    n = len(nums)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if nums[i] + nums[j] == k:\n",
    "                return True\n",
    "    return False\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2aca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ì‚¬ì´íŠ¸ ì½”ë”©\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"í•œ í˜ì´ì§€ì§œë¦¬ ì›¹ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•˜ì‹œì˜¤. ì´ í˜ì´ì§€ì—ëŠ” HTML, CSS, javascriptê°€ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, javascriptì˜ setTimeout() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=2048,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c75653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë© ë°°í‹€\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë ˆí¼ íƒ€ë¸”ë¡œì™€ ì´ì˜ì§€ ì‚¬ì´ì˜ ë””ìŠ¤ ë©ë°°í‹€ì„ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í† ë¡ \n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë§ˆë¦¬í™”ë‚˜ í•©ë²•í™”ì— ëŒ€í•´ì„œ ì°¬ì„±ê³¼ ë°˜ëŒ€ë¡œ ì—­í• ì„ ë²ˆê°ˆì•„ê°€ë©´ì„œ í† ë¡ ì„ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function ì—­í• ë¡œ Assistantì—ê²Œ ëª…ë ¹ì„ ì „ë‹¬\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "             \"content\": \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"accumulator\",\n",
    "            \"content\": \"ì£¼ì–´ì§„ ê°’ë“¤ì„ ëª¨ë‘ ë”í•´ì„œ ëŒë ¤ì¤ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"check_odd_number\",\n",
    "            \"content\": \"ì£¼ì–´ì§„ ìˆ˜ ì¤‘ í™€ìˆ˜ë§Œì„ ëŒë ¤ì¤ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"check_odd_number(1, 5, 2, 4, 8, 10)\"\n",
    "        },\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3805dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¼\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "gen = openai.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë§ˆë¦¬í™”ë‚˜ í•©ë²•í™”ì— ëŒ€í•´ì„œ ì°¬ì„±ê³¼ ë°˜ëŒ€ë¡œ ì—­í• ì„ ë²ˆê°ˆì•„ê°€ë©´ì„œ í† ë¡ ì„ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    response = next(gen)\n",
    "    delta = response.choices[0].delta\n",
    "    if delta.content is not None:\n",
    "        print(delta.content, end='')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd01ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrx import stock\n",
    "from openai import OpenAI\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ì½ê¸°\n",
    "# ì˜ˆ: os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í‚¤ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = OpenAI(api_key=api_key)\n",
    "# ë‚ ì§œ ë²”ìœ„ ì„¤ì •\n",
    "start_date = \"2024-01-01\"\n",
    "end_date = \"2025-07-20\"\n",
    "ticker = \"005930\"  # ì‚¼ì„±ì „ì\n",
    "\n",
    "# ì£¼ê°€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = stock.get_market_ohlcv_by_date(start_date, end_date, ticker)\n",
    "\n",
    "# ì´ë™ í‰ê· ì„  ê³„ì‚°\n",
    "df[\"MA20\"] = df[\"ì¢…ê°€\"].rolling(window=20).mean()\n",
    "df[\"MA60\"] = df[\"ì¢…ê°€\"].rolling(window=60).mean()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df.index, df[\"ì¢…ê°€\"], label=\"ì¢…ê°€\", color='black')\n",
    "plt.plot(df.index, df[\"MA20\"], label=\"20ì¼ ì´ë™í‰ê· \", linestyle=\"--\", color='blue')\n",
    "plt.plot(df.index, df[\"MA60\"], label=\"60ì¼ ì´ë™í‰ê· \", linestyle=\"--\", color='red')\n",
    "plt.title(\"ğŸ“ˆ ì‚¼ì„±ì „ì ì£¼ê°€ ë° ì´ë™ í‰ê· ì„ \")\n",
    "plt.xlabel(\"ë‚ ì§œ\")\n",
    "plt.ylabel(\"ê°€ê²© (ì›)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ìµœê·¼ 30ì¼ ì¢…ê°€ ë°ì´í„° ì¶”ì¶œ\n",
    "recent_df = df[[\"ì¢…ê°€\"]].tail(30)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ìš”ì•½ìš© ë¬¸ìì—´ ë³€í™˜\n",
    "summary_text = recent_df.to_string()\n",
    "\n",
    "# GPT í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "prompt = f\"\"\"\n",
    "ë‹¤ìŒì€ ìµœê·¼ 30ì¼ê°„ ì‚¼ì„±ì „ìì˜ ì¢…ê°€ ë°ì´í„°ì…ë‹ˆë‹¤:\\n\\n{summary_text}\n",
    "\n",
    "ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ í•­ëª©ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”:\n",
    "1. ì£¼ê°€ì˜ ì „ë°˜ì ì¸ ì¶”ì„¸ëŠ” ì–´ë–¤ê°€ìš”?\n",
    "2. íˆ¬ìì ì…ì¥ì—ì„œ ìœ ì˜í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
    "3. í˜„ì¬ ì‹œì ì—ì„œì˜ ê°„ë‹¨í•œ íˆ¬ì ì˜ê²¬ì„ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# GPT-4 í˜¸ì¶œ (v1 ë°©ì‹)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # ë˜ëŠ” \"gpt-3.5-turbo\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì£¼ì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# GPT ì‘ë‹µ ì¶œë ¥\n",
    "analysis = response.choices[0].message.content\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š GPT ì£¼ê°€ ë¶„ì„ ê²°ê³¼:\")\n",
    "print(\"=\" * 60)\n",
    "print(analysis)\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
