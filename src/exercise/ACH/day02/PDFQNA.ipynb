{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819433ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "/tmp/ipykernel_16218/2716360779.py:55: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv  # ğŸ”„ ì¶”ê°€ëœ ë¶€ë¶„\n",
    "\n",
    "# ğŸ” OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ì½ê¸°\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # ë³€ìˆ˜ëª… ìˆ˜ì •\n",
    "if api_key is None:\n",
    "    raise ValueError(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ ì„¤ì •\n",
    "conversation_chain = None\n",
    "chat_history = []\n",
    "\n",
    "def process_pdf(pdf_file_path):\n",
    "    \"\"\"PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    global conversation_chain\n",
    "    \n",
    "    try:\n",
    "        if pdf_file_path is None:\n",
    "            return \"âŒ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        # PDF íŒŒì¼ ë¡œë“œ ë° ì²˜ë¦¬\n",
    "        loader = PyPDFLoader(pdf_file_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        if not documents:\n",
    "            return \"âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ PDF íŒŒì¼ì„ ì‹œë„í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        # ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=150,\n",
    "            length_function=len\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        if not chunks:\n",
    "            return \"âŒ PDF ë‚´ìš©ì„ ë¶„í• í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "        # ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "        \n",
    "        # ëŒ€í™” ë©”ëª¨ë¦¬ ë° ê²€ìƒ‰ ì²´ì¸ ìƒì„±\n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=ChatOpenAI(temperature=0.7, model_name=\"gpt-4\"),\n",
    "            retriever=vectorstore.as_retriever(),\n",
    "            memory=memory\n",
    "        )\n",
    "        \n",
    "        # ì „ì—­ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\n",
    "        global chat_history\n",
    "        chat_history = []\n",
    "        \n",
    "        return \"âœ… PDFê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"âŒ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "def answer_query(query, history):\n",
    "    \"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.\"\"\"\n",
    "    global conversation_chain, chat_history\n",
    "    \n",
    "    if not query.strip():\n",
    "        return history\n",
    "    \n",
    "    if conversation_chain is None:\n",
    "        return history + [(query, \"âš ï¸ PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\")]\n",
    "    \n",
    "    # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€\n",
    "    history.append((query, \"\"))\n",
    "    \n",
    "    try:\n",
    "        # LangChainì„ í†µí•´ ë‹µë³€ ìƒì„±\n",
    "        response = conversation_chain.invoke({\"question\": query})\n",
    "        answer = response[\"answer\"]\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "        chat_history.append((query, answer))\n",
    "        history[-1] = (query, answer)\n",
    "        \n",
    "    except Exception as e:\n",
    "        history[-1] = (query, f\"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "def reset_chat():\n",
    "    \"\"\"ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    return []\n",
    "\n",
    "# í…ìŠ¤íŠ¸ í•„ë“œ ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "def clear_text():\n",
    "    return \"\"\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# ğŸ“„ PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "    gr.Markdown(\"PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            # íŒŒì¼ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸\n",
    "            pdf_input = gr.File(\n",
    "                label=\"PDF íŒŒì¼ ì—…ë¡œë“œ\", \n",
    "                file_types=[\".pdf\"],\n",
    "                type=\"filepath\"  # íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ ì‚¬ìš©\n",
    "            )\n",
    "            upload_button = gr.Button(\"PDF ì²˜ë¦¬í•˜ê¸°\", variant=\"primary\")\n",
    "            status_text = gr.Textbox(label=\"ìƒíƒœ\", interactive=False)\n",
    "            clear_button = gr.Button(\"ëŒ€í™” ì´ˆê¸°í™”\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(\n",
    "                [], \n",
    "                elem_id=\"chatbot\", \n",
    "                height=500,\n",
    "                avatar_images=(None, \"https://api.dicebear.com/7.x/bottts/svg?seed=gpt\")\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                query_input = gr.Textbox(\n",
    "                    placeholder=\"PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...\",\n",
    "                    label=\"ì§ˆë¬¸\",\n",
    "                    lines=2,\n",
    "                    interactive=True,\n",
    "                    elem_id=\"query_input\"\n",
    "                )\n",
    "                submit_btn = gr.Button(\"ì „ì†¡\", variant=\"primary\")\n",
    "    \n",
    "    # ì´ë²¤íŠ¸ ì—°ê²°\n",
    "    upload_button.click(\n",
    "        fn=process_pdf,\n",
    "        inputs=[pdf_input],\n",
    "        outputs=[status_text]\n",
    "    )\n",
    "    \n",
    "    # ì§ˆë¬¸ ì œì¶œ ë°©ë²• 1: í…ìŠ¤íŠ¸ë°•ìŠ¤ ì—”í„°í‚¤\n",
    "    query_input.submit(\n",
    "        fn=answer_query,\n",
    "        inputs=[query_input, chatbot],\n",
    "        outputs=[chatbot]\n",
    "    ).then(\n",
    "        fn=clear_text,  # ì‘ë‹µ í›„ ì…ë ¥ í•„ë“œ ì§€ìš°ê¸°\n",
    "        inputs=None,\n",
    "        outputs=[query_input]\n",
    "    )\n",
    "    \n",
    "    # ì§ˆë¬¸ ì œì¶œ ë°©ë²• 2: ì „ì†¡ ë²„íŠ¼\n",
    "    submit_btn.click(\n",
    "        fn=answer_query,\n",
    "        inputs=[query_input, chatbot],\n",
    "        outputs=[chatbot]\n",
    "    ).then(\n",
    "        fn=clear_text,  # ì‘ë‹µ í›„ ì…ë ¥ í•„ë“œ ì§€ìš°ê¸°\n",
    "        inputs=None,\n",
    "        outputs=[query_input]\n",
    "    )\n",
    "    \n",
    "    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼\n",
    "    clear_button.click(\n",
    "        fn=reset_chat,\n",
    "        outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "# ìë°”ìŠ¤í¬ë¦½íŠ¸ë¡œ Enter í‚¤ ì´ë²¤íŠ¸ ì¶”ê°€\n",
    "demo.load(js=\"\"\"\n",
    "function setupEnterKey() {\n",
    "    const textbox = document.getElementById('query_input').querySelector('textarea');\n",
    "    textbox.addEventListener('keydown', function(event) {\n",
    "        if (event.key === 'Enter' && !event.shiftKey) {\n",
    "            event.preventDefault();\n",
    "            const submitButton = document.querySelector('button.primary');\n",
    "            submitButton.click();\n",
    "        }\n",
    "    });\n",
    "}\n",
    "\n",
    "// DOMì´ ì™„ì „íˆ ë¡œë“œëœ í›„ ì‹¤í–‰\n",
    "if (document.readyState === 'complete' || document.readyState === 'interactive') {\n",
    "    setTimeout(setupEnterKey, 1000);\n",
    "} else {\n",
    "    document.addEventListener('DOMContentLoaded', function() {\n",
    "        setTimeout(setupEnterKey, 1000);\n",
    "    });\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# ì•± ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
