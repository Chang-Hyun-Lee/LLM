{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25117a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv  # ğŸ”„ ì¶”ê°€ëœ ë¶€ë¶„\n",
    "\n",
    "# ğŸ” OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ì½ê¸°\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # ë³€ìˆ˜ëª… ìˆ˜ì •\n",
    "if api_key is None:\n",
    "    raise ValueError(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# Gradio interface í•¨ìˆ˜\n",
    "def respond(user_message, chat_history):\n",
    "    # ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "    chat_history.append((user_message, \"\"))\n",
    "    messages = []\n",
    "    \n",
    "    # ì±„íŒ… ê¸°ë¡ì„ OpenAI API í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    for user, assistant in chat_history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user})\n",
    "        if assistant:  # ë¹ˆ ì‘ë‹µì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    \n",
    "    # ì‘ë‹µ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë°\n",
    "    bot_response = \"\"\n",
    "    for chunk in openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    ):\n",
    "        if chunk.choices[0].delta.content:\n",
    "            bot_response += chunk.choices[0].delta.content\n",
    "            chat_history[-1] = (user_message, bot_response)\n",
    "            yield chat_history\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...\", show_label=False, lines=1)\n",
    "    clear = gr.Button(\"ëŒ€í™” ì´ˆê¸°í™”\")\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], chatbot)\n",
    "    msg.submit(lambda: \"\", None, msg, queue=False)  # ì…ë ¥ í•„ë“œ ë¹„ìš°ê¸°\n",
    "    clear.click(lambda: [], None, chatbot, queue=False)  # ëŒ€í™” ì´ˆê¸°í™”\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91858b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë©€í‹° í„´ êµ¬í˜„\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv  # ğŸ”„ ì¶”ê°€ëœ ë¶€ë¶„\n",
    "\n",
    "# ğŸ” OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ì½ê¸°\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # ë³€ìˆ˜ëª… ìˆ˜ì •\n",
    "if api_key is None:\n",
    "    raise ValueError(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë©€í‹°í„´ ëŒ€í™” ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def chat(message, history):\n",
    "    \"\"\"ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\n",
    "    history = history or []\n",
    "    \n",
    "    # OpenAI APIì— ì „ì†¡í•  ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    messages = [{\"role\": \"system\", \"content\": \"ì €ëŠ” ë„ì›€ì„ ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\"}]\n",
    "    \n",
    "    # ëŒ€í™” ê¸°ë¡ ì¶”ê°€\n",
    "    for human, ai in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": human})\n",
    "        if ai:  # AI ì‘ë‹µì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€\n",
    "            messages.append({\"role\": \"assistant\", \"content\": ai})\n",
    "    \n",
    "    # ìƒˆ ë©”ì‹œì§€ ì¶”ê°€\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    # ìƒˆ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì— ì¶”ê°€\n",
    "    history.append((message, \"\"))\n",
    "    \n",
    "    # ì‘ë‹µ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë°\n",
    "    full_response = \"\"\n",
    "    for chunk in openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    ):\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            full_response += chunk.choices[0].delta.content\n",
    "            # ë§ˆì§€ë§‰ ëŒ€í™” í•­ëª©ì˜ AI ì‘ë‹µ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸\n",
    "            history[-1] = (message, full_response)\n",
    "            yield history\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ë©€í‹°í„´ ëŒ€í™” AI ì±—ë´‡\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        [],\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        avatar_images=(None, \"https://api.dicebear.com/7.x/bottts/svg?seed=gpt\"),\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(\n",
    "            placeholder=\"ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...\", \n",
    "            show_label=False,\n",
    "            lines=1,\n",
    "            container=False,\n",
    "            scale=12\n",
    "        )\n",
    "        submit_btn = gr.Button(\"ì „ì†¡\", scale=1)\n",
    "    \n",
    "    with gr.Row():\n",
    "        clear_btn = gr.Button(\"ëŒ€í™” ì´ˆê¸°í™”\")\n",
    "        \n",
    "    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬\n",
    "    msg.submit(\n",
    "        fn=chat,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=chatbot,\n",
    "        queue=True\n",
    "    ).then(\n",
    "        fn=lambda: \"\",\n",
    "        inputs=None,\n",
    "        outputs=msg\n",
    "    )\n",
    "    \n",
    "    submit_btn.click(\n",
    "        fn=chat,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=chatbot,\n",
    "        queue=True\n",
    "    ).then(\n",
    "        fn=lambda: \"\",\n",
    "        inputs=None,\n",
    "        outputs=msg\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(lambda: [], None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)  # share=Trueë¡œ ì„¤ì •í•˜ë©´ ê³µê°œ URLì´ ìƒì„±ë©ë‹ˆë‹¤, False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
