import streamlit as st
from llama_index import VectorStoreIndex, ServiceContext, Document
from llama_index.llms import OpenAI
import openai
import os
import shutil
from llama_index import StorageContext, load_index_from_storage
from dotenv import load_dotenv
from PyPDF2 import PdfReader
import docx2txt
import glob

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if api_key is None:
    st.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

openai.api_key = api_key

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.title("LlamaIndex ë¬¸ì„œ ê´€ë¦¬ ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "chat_engine" not in st.session_state:
    st.session_state.chat_engine = None
if "current_file" not in st.session_state:
    st.session_state.current_file = None
if "file_summary" not in st.session_state:
    st.session_state.file_summary = {}

# ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
storage_dir = "./storage"
os.makedirs(storage_dir, exist_ok=True)

# ì‚¬ì´ë“œë°” - íŒŒì¼ ê´€ë¦¬ ì„¹ì…˜
st.sidebar.title("íŒŒì¼ ê´€ë¦¬")

# íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥
uploaded_file = st.sidebar.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf", "txt", "docx"])

# íŒŒì¼ ë‚´ìš© ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_file(file):
    if file.type == "text/plain":
        return file.getvalue().decode("utf-8")
    elif file.type == "application/pdf":
        pdf_reader = PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        return docx2txt.process(file)
    return ""

# íŒŒì¼ ìš”ì•½ ìƒì„± í•¨ìˆ˜
def generate_file_summary(text, file_name):
    try:
        llm = OpenAI(model="gpt-3.5-turbo", temperature=0.5)
        summary_prompt = f"ë‹¤ìŒ ë¬¸ì„œì˜ ë‚´ìš©ì„ 200ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text[:2000]}..."
        summary = llm.complete(summary_prompt)
        return summary.text
    except Exception as e:
        st.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
def get_file_list():
    files = []
    for dir_name in os.listdir(storage_dir):
        dir_path = os.path.join(storage_dir, dir_name)
        if os.path.isdir(dir_path):
            for file_path in glob.glob(os.path.join(dir_path, "*.*")):
                if os.path.isfile(file_path) and not file_path.endswith((".gitignore", ".DS_Store")):
                    file_name = os.path.basename(file_path)
                    files.append((file_name, dir_name))
    return files

# íŒŒì¼ ì²˜ë¦¬
if uploaded_file:
    # íŒŒì¼ëª…ìœ¼ë¡œ ë””ë ‰í† ë¦¬ ìƒì„±
    file_dir = os.path.join(storage_dir, os.path.splitext(uploaded_file.name)[0])
    os.makedirs(file_dir, exist_ok=True)
    
    # íŒŒì¼ ì €ì¥
    file_path = os.path.join(file_dir, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getvalue())
    
    # íŒŒì¼ ë‚´ìš© ì¶”ì¶œ
    text = extract_text_from_file(uploaded_file)
    
    # íŒŒì¼ ìš”ì•½ ìƒì„±
    if uploaded_file.name not in st.session_state.file_summary:
        summary = generate_file_summary(text, uploaded_file.name)
        st.session_state.file_summary[uploaded_file.name] = summary
    
    # ì €ì¥ëœ ì¸ë±ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists(os.path.join(file_dir, "index")):
        st.sidebar.info("ì €ì¥ëœ ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        # ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ
        storage_context = StorageContext.from_defaults(persist_dir=os.path.join(file_dir, "index"))
        index = load_index_from_storage(storage_context)
        st.session_state.chat_engine = index.as_chat_engine(verbose=True)
    else:
        st.sidebar.info("ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        if text:
            documents = [Document(text=text)]
            
            # ì¸ë±ìŠ¤ ìƒì„±
            service_context = ServiceContext.from_defaults(llm=OpenAI(model="gpt-3.5-turbo", temperature=0.5))
            index = VectorStoreIndex.from_documents(documents, service_context=service_context)
            
            # ì¸ë±ìŠ¤ ì €ì¥
            index.storage_context.persist(os.path.join(file_dir, "index"))
            st.session_state.chat_engine = index.as_chat_engine(verbose=True)
            st.sidebar.success("ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.sidebar.error("íŒŒì¼ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    st.session_state.current_file = uploaded_file.name
    st.session_state.messages = []  # ìƒˆ íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ëŒ€í™” ì´ˆê¸°í™”

# íŒŒì¼ ëª©ë¡ í‘œì‹œ
file_list = get_file_list()
if file_list:
    st.sidebar.subheader("ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
    for file_name, dir_name in file_list:
        col1, col2, col3 = st.sidebar.columns([3, 1, 1])
        with col1:
            if st.button(f"ğŸ“„ {file_name}", key=f"select_{file_name}"):
                file_dir = os.path.join(storage_dir, dir_name)
                if os.path.exists(os.path.join(file_dir, "index")):
                    storage_context = StorageContext.from_defaults(persist_dir=os.path.join(file_dir, "index"))
                    index = load_index_from_storage(storage_context)
                    st.session_state.chat_engine = index.as_chat_engine(verbose=True)
                    st.session_state.current_file = file_name
                    st.session_state.messages = []  # íŒŒì¼ ë³€ê²½ ì‹œ ëŒ€í™” ì´ˆê¸°í™”
        with col2:
            if st.button("ğŸ”", key=f"view_{file_name}"):
                file_dir = os.path.join(storage_dir, dir_name)
                file_path = os.path.join(file_dir, file_name)
                if os.path.exists(file_path):
                    with open(file_path, "rb") as f:
                        file_content = f.read()
                    
                    if file_name.endswith(".txt"):
                        st.sidebar.text_area("íŒŒì¼ ë‚´ìš©", file_content.decode("utf-8"), height=200)
                    elif file_name.endswith(".pdf"):
                        st.sidebar.info(f"{file_name} - PDF íŒŒì¼ì€ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    elif file_name.endswith(".docx"):
                        st.sidebar.info(f"{file_name} - DOCX íŒŒì¼ì€ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        with col3:
            if st.button("âŒ", key=f"delete_{file_name}"):
                file_dir = os.path.join(storage_dir, dir_name)
                if os.path.exists(file_dir):
                    shutil.rmtree(file_dir)
                    st.experimental_rerun()

# í˜„ì¬ ì„ íƒëœ íŒŒì¼ í‘œì‹œ
if st.session_state.current_file:
    st.subheader(f"í˜„ì¬ íŒŒì¼: {st.session_state.current_file}")
    
    # íŒŒì¼ ìš”ì•½ í‘œì‹œ
    if st.session_state.current_file in st.session_state.file_summary:
        with st.expander("íŒŒì¼ ìš”ì•½ ë³´ê¸°", expanded=False):
            st.write(st.session_state.file_summary[st.session_state.current_file])

# ëŒ€í™” ì¸í„°í˜ì´ìŠ¤
st.subheader("ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ê¸°")

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì±—ë´‡ ì‘ë‹µ ìƒì„±
    if st.session_state.chat_engine:
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = st.session_state.chat_engine.chat(prompt)
                st.markdown(response.response)
                st.session_state.messages.append({"role": "assistant", "content": response.response})
    else:
        with st.chat_message("assistant"):
            st.markdown("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê¸°ì¡´ ë¬¸ì„œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.session_state.messages.append({"role": "assistant", "content": "ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê¸°ì¡´ ë¬¸ì„œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."})

# ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
    st.session_state.messages = []
    st.experimental_rerun()

# íŒŒì¼ ì „ì²´ ë‚´ìš© ì„¤ëª… ê¸°ëŠ¥
if st.session_state.current_file and st.button("íŒŒì¼ ì „ì²´ ë‚´ìš© ì„¤ëª…"):
    if st.session_state.chat_engine:
        with st.spinner("íŒŒì¼ ë‚´ìš© ë¶„ì„ ì¤‘..."):
            prompt = "ì´ ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš©ì„ ìƒì„¸íˆ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            response = st.session_state.chat_engine.chat(prompt)
            
            st.subheader("íŒŒì¼ ë‚´ìš© ì„¤ëª…")
            st.write(response.response)
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.session_state.messages.append({"role": "assistant", "content": response.response})

# ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ (ì¶”ê°€ ê¸°ëŠ¥)
if st.session_state.current_file:
    with st.expander("ê³ ê¸‰ ë¶„ì„ ì˜µì…˜", expanded=False):
        if st.button("ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"):
            if st.session_state.chat_engine:
                with st.spinner("í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘..."):
                    prompt = "ì´ ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ 10ê°œì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ê°ê°ì— ëŒ€í•´ ê°„ëµíˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                    response = st.session_state.chat_engine.chat(prompt)
                    st.write(response.response)
        
        if st.button("í•µì‹¬ ì§ˆë¬¸ ìƒì„±"):
            if st.session_state.chat_engine:
                with st.spinner("ì§ˆë¬¸ ìƒì„± ì¤‘..."):
                    prompt = "ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë…ìê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” 5ê°€ì§€ ì¤‘ìš”í•œ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
                    response = st.session_state.chat_engine.chat(prompt)
                    st.write(response.response)

# ì‚¬ìš© ì•ˆë‚´
with st.expander("ì‚¬ìš© ë°©ë²•", expanded=False):
    st.markdown("""
    ### ì‚¬ìš© ë°©ë²•
    1. **íŒŒì¼ ì—…ë¡œë“œ**: ì‚¬ì´ë“œë°”ì—ì„œ PDF, TXT, DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.
    2. **íŒŒì¼ ì„ íƒ**: ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ì—ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.
    3. **ì§ˆë¬¸í•˜ê¸°**: ì„ íƒí•œ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.
    4. **íŒŒì¼ ê´€ë¦¬**: íŒŒì¼ ëª©ë¡ì—ì„œ íŒŒì¼ì„ ë³´ê±°ë‚˜ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    5. **ì „ì²´ ë‚´ìš© ì„¤ëª…**: 'íŒŒì¼ ì „ì²´ ë‚´ìš© ì„¤ëª…' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¬¸ì„œ ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•´ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ### íŒ
    - êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ëŒ€í™”ëŠ” ì—°ì†ì ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤. ì´ì „ ì§ˆë¬¸ì„ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

# í‘¸í„°
st.markdown("---")
st.markdown("LlamaIndexì™€ Streamlitìœ¼ë¡œ ë§Œë“  ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡ | ê°œë°œ: 2023")