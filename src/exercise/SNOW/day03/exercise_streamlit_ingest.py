import streamlit as st
import tempfile

from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# ì„¸ì…˜ ìƒíƒœ ê¸°ë°˜ QA ì²´ì¸ ì´ˆê¸°í™”
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None
    st.session_state.chat_history = []

# íƒ€ì´í‹€ í‘œì‹œ
st.title("ğŸ“„ GPT-4o PDF ì±—ë´‡")
st.caption("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ í•´ë‹¹ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ GPT-4oê°€ ì§ˆë¬¸ì— ì‘ë‹µí•©ë‹ˆë‹¤.")

# PDF ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

# PDF ì²˜ë¦¬
if uploaded_file and st.session_state.qa_chain is None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        pdf_path = tmp_file.name

    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    chunks = splitter.split_documents(documents)

    embedding_model = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(chunks, embedding_model)

    retriever = vectorstore.as_retriever()
    llm = ChatOpenAI(model_name="gpt-4o")

    st.session_state.qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
    st.success("âœ… PDF ë¡œë”© ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

# ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
if st.session_state.qa_chain:
    for chat in st.session_state.chat_history:
        with st.chat_message("user"):
            st.markdown(chat["user"])
        with st.chat_message("assistant"):
            st.markdown(chat["bot"])

    user_input = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    if user_input:
        with st.chat_message("user"):
            st.markdown(user_input)

        response = st.session_state.qa_chain.run(user_input)

        with st.chat_message("assistant"):
            st.markdown(response)

        st.session_state.chat_history.append({
            "user": user_input,
            "bot": response
        })