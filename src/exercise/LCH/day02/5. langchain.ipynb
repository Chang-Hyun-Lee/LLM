{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967c53a9-cb65-49a5-99f4-145651f38bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/ubuntu/.local/lib/python3.10/site-packages (1.97.0)\n",
      "Requirement already satisfied: langchain in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-openai in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-community in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.3.70)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (21.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/.local/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ubuntu/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain-core==0.2.17\n",
    "#!pip install langchain-openai==0.1.17\n",
    "#!pip install pydantic==1.10.8\n",
    "#!pip install pydantic_core==2.18.2\n",
    "!pip install -U openai langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020041bc-3149-4195-b28f-4d38c65cbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-search-results in /home/ubuntu/.local/lib/python3.10/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->google-search-results) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->google-search-results) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->google-search-results) (2025.7.14)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wikipedia in /home/ubuntu/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from wikipedia) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ubuntu/.local/lib/python3.10/site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.7.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (4.14.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in /home/ubuntu/.local/lib/python3.10/site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in /home/ubuntu/.local/lib/python3.10/site-packages (5.0.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (2.7.1)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (4.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (0.33.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (4.53.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (1.7.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.7.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence_transformers) (3.0.3)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch>=1.11.0->sentence_transformers) (59.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.7.14)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/.local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results\n",
    "!pip install wikipedia\n",
    "!pip install faiss-cpu \n",
    "!pip install sentence_transformers \n",
    "!pip install tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a332d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field # 예전 방식\n",
    "\n",
    "# from pydantic import BaseModel # 새로운 방식\n",
    "\n",
    "from pydantic.v1 import BaseModel # pydantic.v1 호환이 필요한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd2a51b-6740-4a14-8ad9-fb59e3ec001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131074/2744496630.py:15: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  aimsg = chat([sys, msg])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1990년대의 재즈는 다양한 스타일과 아티스트들이 활발히 활동했던 시기입니다. 다음은 1990년대에 발매된 추천할 만한 재즈 곡 5곡입니다:\\n\\n1. **\"Moanin\\'\" - Thelonious Monk Quartet** (1995)  \\n   - 이 곡은 전설적인 피아니스트인 씨어노니어스 몽크의 연주로, 그의 독창적인 하모니와 리듬을 느낄 수 있습니다.\\n\\n2. **\"Come Away With Me\" - Norah Jones** (2002)  \\n   - 비록 2000년대 초반에 발표된 곡이지만, 1990년대의 재즈 영향을 많이 받았습니다. 노라 존스의 부드러운 목소리와 감성적인 멜로디가 매력적입니다.\\n\\n3. **\"Tutu\" - Miles Davis** (1986)  \\n   - 1986년에 발매되었지만, 90년대 재즈 씬에 큰 영향을 미쳤습니다. 마일스 데이비스의 혁신적이고 전자적인 음색을 경험할 수 있습니다.\\n\\n4. **\"In a Silent Way\" - Miles Davis** (1990)  \\n   - 마일스 데이비스의 클래식 트랙을 다시 편곡하여 1990년대에 새롭게 발표된 버전입니다. 이 곡에서도 그의 독창적인 스타일이 돋보입니다.\\n\\n5. **\"What’s Going On\" - The Robert Glasper Experiment** (2012)  \\n   - 1990년대 재즈의 흐름을 계승하며 R&B와 힙합 요소를 혼합한 곡으로, 현대 재즈의 발전 방향을 보여줍니다.\\n\\n이 곡들은 1990년대의 재즈 장르에서 중요한 위치를 차지하고 있습니다. 한번 들어보세요!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예전에 사용한대로 AI, Human, System message를 배열로 전달\n",
    "\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "sys = SystemMessage(content=\"당신은 음악 추천을 해주는 전문 AI입니다.\")\n",
    "msg = HumanMessage(content='1990년대 재즈 5곡만 추천해줘.')\n",
    "\n",
    "aimsg = chat([sys, msg])\n",
    "aimsg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e5f17c-6a25-4489-919f-b1e477368296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131074/1939471710.py:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'베트남에는 매력적인 여행지가 많습니다! 몇 가지 추천해드릴게요:\\n\\n1. **하롱베이**: 유네스코 세계유산으로 유명한 이곳은 아름다운 섬과 석회암 기둥들로 구성된 장관을 자랑합니다. 1박 2일 동안 크루즈를 즐기며 섬 탐험, 카약, 해양 액티비티를 할 수 있습니다.\\n\\n2. **호이안**: 잘 보존된 고대 도시로, 유네스코 세계유산에 등록되어 있습니다. 고풍스러운 건축물, 전통시장, 야경을 즐길 수 있으며, 자전거를 타고 주변 농촌을 탐방하는 것도 추천합니다.\\n\\n3. **다낭**: 해변과 현대적인 도시가 어우러진 곳으로, 바나힐스의 황금다리와 미케 비치 등 다양한 관광명소가 있습니다. 근처 호이안과 함께 방문하기에도 좋습니다.\\n\\n4. **하노이**: 수도인 하노이는 베트남의 역사와 문화를 느낄 수 있는 장소입니다. 노이바이 공항에서 짧은 거리이며, 맛있는 길거리 음식과 시장 탐방, 호안끼엠 호수에서의 여유로운 시간도 즐길 수 있습니다.\\n\\n여행 일정과 취향에 맞춰 선택해보세요!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예전에 사용한대로 AI, Human, System message를 배열로 전달\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "sys = SystemMessage(content=\"당신은 여행을 추천해주는 전문 AI입니다.\")\n",
    "msg1 = HumanMessage(content='베트남 사파에 1박 2일 여행 가면 충분할까?')\n",
    "msg2 = AIMessage(content='사파는 1박 2일로 가기에는 너무 멉니다. 일정을 조정하거나 다른 여행지를 선택하시면 어떨까요?')\n",
    "msg3 = HumanMessage(content='음 ... 그러면 어디가 좋을까?')\n",
    "\n",
    "aimsg = chat([sys, msg1, msg2, msg3])\n",
    "aimsg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5f966f-2923-4af7-9e96-bab696d6c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI 여행 추천 서비스 만드는 회사 이름 추천해줘. 기억에 남는 한글 이름으로'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate를 사용하여 각 LLM에 맞는 prompt를 지정할 수 있음\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"상품\"],\n",
    "    template=\"{상품} 만드는 회사 이름 추천해줘. 기억에 남는 한글 이름으로\",\n",
    ")\n",
    "\n",
    "prompt.format(상품=\"AI 여행 추천 서비스\") # 변수가 여러 개 일 때, 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ae1232-2911-463a-838f-47eb2cbf5de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131074/2518977364.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=chat, prompt=prompt)\n",
      "/tmp/ipykernel_131074/2518977364.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(상품=\"학원 추천 서비스\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'여기 몇 가지 기억에 남는 한글 이름 추천드립니다:\\n\\n1. **학원찾기**\\n2. **배움길**\\n3. **학습마당**\\n4. **지식연결**\\n5. **꿈동산**\\n6. **스마트학습**\\n7. **탐구소**\\n8. **교육서퍼**\\n9. **학원하모니**\\n10. **배움사랑**\\n\\n이 중에서 마음에 드는 것이 있길 바랍니다!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "chain.run(상품=\"학원 추천 서비스\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cede08e-1a08-40de-b79a-edee95d7950c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나는 프로그래밍을 사랑해.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 Prompt 별 template 지정도 가능\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)  \n",
    "\n",
    "template=\"You are a helpful assisstant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "\n",
    "chatchain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chatchain.run(input_language=\"English\", output_language=\"Korean\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e138db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numexpr in /home/ubuntu/.local/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from numexpr) (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96ce4ed-c8cd-453a-941f-67f937037653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m아마존의 창업자를 찾고 그의 나이와 배우자의 나이를 알아야 한다. 먼저 아마존의 창업자를 검색해 보겠다.  \n",
      "Action: wikipedia  \n",
      "Action Input: 아마존 창립자  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m아마존의 창립자에 대한 정보를 찾기 위해 다른 검색어를 사용해 보겠다.  \n",
      "Action: wikipedia  \n",
      "Action Input: Amazon founder  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Amazon (company)\n",
      "Summary: Amazon.com, Inc., doing business as Amazon, is an American multinational technology company engaged in e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. Founded in 1994 by Jeff Bezos in Bellevue, Washington, the company originally started as an online marketplace for books but gradually expanded its offerings to include a wide range of product categories, referred to as \"The Everything Store\". Today, Amazon is considered one of the Big Five American technology companies, the other four being Alphabet, Apple, Meta, and Microsoft.\n",
      "The company has multiple subsidiaries, including Amazon Web Services, providing cloud computing; Zoox, a self-driving car division; Kuiper Systems, a satellite Internet provider; and Amazon Lab126, a computer hardware R&D provider. Other subsidiaries include Ring, Twitch, IMDb, and Whole Foods Market. Its acquisition of Whole Foods in August 2017 for US$13.4 billion substantially increased its market share and presence as a physical retailer. Amazon also distributes a variety of downloadable and streaming content through its Amazon Prime Video, MGM+, Amazon Music, Twitch, Audible and Wondery units. It publishes books through its publishing arm, Amazon Publishing, produces and distributes film and television content through Amazon MGM Studios, including the Metro-Goldwyn-Mayer studio it acquired in March 2022, and owns Brilliance Audio and Audible, which produce and distribute audiobooks, respectively. Amazon also produces consumer electronics—most notably, Kindle e-readers, Echo devices, Fire tablets, and Fire TVs.\n",
      "Amazon has a reputation as a disruptor of industries through technological innovation and aggressive reinvestment of profits into capital expenditures. As of 2023, it is the world's largest online retailer and marketplace, smart speaker provider, cloud computing service through AWS, live-streaming service through Twitch, and Internet company as measured by revenue and market share. In 2021, it surpassed Walmart as the world's largest retailer outside of China, driven in large part by its paid subscription plan, Amazon Prime, which has 200 million subscribers worldwide. It is the second-largest private employer in the United States and the second-largest company in the world and in the U.S. by revenue as of 2024 (after Walmart). As of October 2024, Amazon is the 12th-most visited website in the world and 84% of its traffic comes from the United States. Amazon is also the global leader in research and development spending, with R&D expenditure of US$73 billion in 2022. Amazon has been criticized for its business practices, including surveillance partnerships, poor worker conditions, anti-union efforts, environmental harm, anti-competitive behavior, censorship controversies, and exploitative treatment of small businesses and suppliers.\n",
      "\n",
      "Page: Jeff Bezos\n",
      "Summary: Jeffrey Preston Bezos ( BAY-zohss; né Jorgensen; born January 12, 1964) is an American businessman best known as the founder, executive chairman, and former president and CEO of Amazon, the world's largest e-commerce and cloud computing company. According to Forbes, as of May 2025, Bezos's estimated net worth exceeded $220 billion, making him the third richest person in the world. He was the wealthiest person from 2017 to 2021, according to Forbes and the Bloomberg Billionaires Index.\n",
      "Bezos was born in Albuquerque and raised in Houston and Miami. He graduated from Princeton University in 1986 with degrees in electrical engineering and computer science. He worked on Wall Street in a variety of related fields from 1986 to early 1994. Bezos founded Amazon in mid-1994 on a road trip from New York City to Seattle. The company began as an online bookstore and has since expanded to a variety of other e-commerce products and services, including video and audio streaming, cloud computing, and artificial intelligence. It is the world's largest online sales company, the\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mJeff Bezos는 아마존의 창립자이며, 그의 생년월일은 1964년 1월 12일이다. 현재 2023년 기준으로 그의 나이는 59세이다. 다음으로 그의 배우자에 대한 정보를 찾아보겠다.  \n",
      "Action: wikipedia  \n",
      "Action Input: Jeff Bezos spouse  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Lauren Sánchez\n",
      "Summary: Lauren Wendy Sánchez Bezos (née Sánchez; born December 19, 1969) is an American philanthropist and former journalist. She is a licensed pilot and founder of Black Ops Aviation, an aerial film and production company. Sánchez has been a guest host on The View, co-host on KTTV Fox 11's Good Day L.A. and anchor on the Fox 11 News at Ten, and anchor and special correspondent on Extra. She has also been a regular contributor on shows including Larry King Live, The Joy Behar Show and Showbiz Tonight. \n",
      "In 2024, Sánchez released her debut children's book, The Fly Who Flew to Space, which became a New York Times bestseller. On April 14, 2025, Sánchez flew as a passenger in Blue Origin NS-31, an all-female spaceflight aboard the New Shepard rocket.\n",
      "In June 2025, Sánchez married Jeff Bezos, the third-richest person in the world.\n",
      "\n",
      "Page: Miguel Bezos\n",
      "Summary: Miguel Ángel \"Mike\" Bezos Pérez (Spanish pronunciation: [miˈɣel ˈβesos]; born (1945-09-29)September 29, 1945) is a Cuban-American billionaire and philanthropist who provided the initial investment to launch Amazon.com. He is a co-founder of the Bezos Family Foundation.\n",
      "He is the adoptive father of Jeff Bezos, the father of Mark Bezos, and the husband of Jackie Bezos.\n",
      "\n",
      "Page: Jackie Bezos\n",
      "Summary: Jacklyn Bezos (née Gise, formerly Jorgensen; born December 29, 1946) is the mother of Jeff and Mark Bezos. She provided the initial investment to launch Amazon.com. As a philanthropist, she is a co-founder of the Bezos Family Foundation.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mJeff Bezos의 배우자는 Lauren Sánchez이며, 그녀의 생년월일은 1969년 12월 19일이다. 현재 2023년 기준으로 그녀의 나이는 53세이다. 이제 Jeff Bezos와 Lauren Sánchez의 나이를 곱해 보겠다.  \n",
      "Action: Calculator  \n",
      "Action Input: 59 * 53  \u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3127\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: 3127\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3127'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatOpenAI를 LLM으로 사용하는 agent\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0) \n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=chat)\n",
    "\n",
    "agent = initialize_agent(tools, llm=chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True) \n",
    "\n",
    "agent.run(\"아마존의 창업자는 누구인가? 그의 나이와 배우자의 나이를 곱하면 얼마인가?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84a01db-ce84-4ddf-be0d-9976ba3580ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/ubuntu/.local/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fd2cf789900>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fd2cf941390>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_proxy=''), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fd2cf789900>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fd2cf941390>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_proxy=''), output_parser=StrOutputParser(), llm_kwargs={}))>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47498a86-a6b0-4e43-bbe3-e84d6e338b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Useful for when you need to answer questions about math.\n"
     ]
    }
   ],
   "source": [
    "print(agent.tools[0].description)\n",
    "print(agent.tools[1].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c1c5cf-26f1-448f-8687-784ca932ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131074/2149845611.py:4: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(llm=chat, verbose=True)\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pydantic/main.py:253: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 인공지능에서 LLM이 뭐야?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LLM은 \"Large Language Model\"의 약자로, 대규모 언어 모델을 의미해요. 이러한 모델은 많은 양의 텍스트 데이터를 학습하여 자연어를 이해하고 생성하는 능력을 가집니다. LLM은 여러 가지 언어 처리 작업을 수행할 수 있는데, 예를 들어 텍스트 생성, 번역, 요약, 질문 응답 등이 있어요.\\n\\n이 모델들은 신경망 구조를 기반으로 하며, 특히 변환기(transformer) 아키텍처를 많이 사용합니다. 대규모 데이터셋을 사용해 사전 훈련된 후, 특정 작업에 맞게 미세 조정(fine-tuning)됩니다. 예를 들어, OpenAI의 GPT 시리즈도 LLM의 일종으로, 다양한 대화와 문서 생성에 활용되고 있죠!\\n\\n혹시 LLM에 대해 더 궁금한 부분이 있을까요?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "conversation = ConversationChain(llm=chat, verbose=True)\n",
    "conversation.predict(input=\"인공지능에서 LLM이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bd1f46e-daa1-4098-8d3e-4c36f4ec0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 인공지능에서 LLM이 뭐야?\n",
      "AI: LLM은 \"Large Language Model\"의 약자로, 대규모 언어 모델을 의미해요. 이러한 모델은 많은 양의 텍스트 데이터를 학습하여 자연어를 이해하고 생성하는 능력을 가집니다. LLM은 여러 가지 언어 처리 작업을 수행할 수 있는데, 예를 들어 텍스트 생성, 번역, 요약, 질문 응답 등이 있어요.\n",
      "\n",
      "이 모델들은 신경망 구조를 기반으로 하며, 특히 변환기(transformer) 아키텍처를 많이 사용합니다. 대규모 데이터셋을 사용해 사전 훈련된 후, 특정 작업에 맞게 미세 조정(fine-tuning)됩니다. 예를 들어, OpenAI의 GPT 시리즈도 LLM의 일종으로, 다양한 대화와 문서 생성에 활용되고 있죠!\n",
      "\n",
      "혹시 LLM에 대해 더 궁금한 부분이 있을까요?\n",
      "Human: PLM과의 차이를 설명해줘.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PLM은 \"Pre-trained Language Model\"의 약자로, 사전 훈련된 언어 모델을 의미해요. LLM과 PLM은 서로 밀접하게 관련되어 있지만, 몇 가지 차이점이 있어요.\\n\\n1. **규모**: LLM은 일반적으로 대규모 모델을 지칭하는 반면, PLM은 사전 훈련된 언어 모델이라는 더 넓은 개념을 포함합니다. 모든 LLM은 PLM이지만, 모든 PLM이 LLM인 것은 아니죠. PLM은 크기와 관계없이 사전 훈련된 모델을 의미할 수 있습니다.\\n\\n2. **학습 방식**: PLM은 대량의 텍스트 데이터에 대한 사전 훈련을 통해 일반적인 언어 이해 능력을 배양합니다. 그런 다음 특정 작업에 대해 미세 조정될 수 있습니다. LLM도 비슷한 접근 방식을 따르지만, 더 많은 매개변수와 더 복잡한 아키텍처를 사용하여 훨씬 더 정교한 언어 생성과 이해를 할 수 있습니다.\\n\\n3. **용도**: LLM은 보통 다양한 언어 처리 작업을 수행하는 데 더 적합하고, PLM은 특정 응용 프로그램에 맞춰 조정되는 경우가 많습니다. 하지만 두 모델 모두 질문 응답, 번역, 텍스트 생성 등 여러 작업에 활용될 수 있습니다.\\n\\n이렇듯 LLM과 PLM은 개념적으로 연결되어 있지만, 그 크기와 성능, 응용 방식에서 차이가 있어요. 더 궁금한 점이 있으면 말씀해 주세요!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"PLM과의 차이를 설명해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b7e4767-87f5-4731-be17-7d74b9a309f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='인공지능에서 LLM이 뭐야?', additional_kwargs={}, response_metadata={}), AIMessage(content='LLM은 \"Large Language Model\"의 약자로, 대규모 언어 모델을 의미해요. 이러한 모델은 많은 양의 텍스트 데이터를 학습하여 자연어를 이해하고 생성하는 능력을 가집니다. LLM은 여러 가지 언어 처리 작업을 수행할 수 있는데, 예를 들어 텍스트 생성, 번역, 요약, 질문 응답 등이 있어요.\\n\\n이 모델들은 신경망 구조를 기반으로 하며, 특히 변환기(transformer) 아키텍처를 많이 사용합니다. 대규모 데이터셋을 사용해 사전 훈련된 후, 특정 작업에 맞게 미세 조정(fine-tuning)됩니다. 예를 들어, OpenAI의 GPT 시리즈도 LLM의 일종으로, 다양한 대화와 문서 생성에 활용되고 있죠!\\n\\n혹시 LLM에 대해 더 궁금한 부분이 있을까요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='PLM과의 차이를 설명해줘.', additional_kwargs={}, response_metadata={}), AIMessage(content='PLM은 \"Pre-trained Language Model\"의 약자로, 사전 훈련된 언어 모델을 의미해요. LLM과 PLM은 서로 밀접하게 관련되어 있지만, 몇 가지 차이점이 있어요.\\n\\n1. **규모**: LLM은 일반적으로 대규모 모델을 지칭하는 반면, PLM은 사전 훈련된 언어 모델이라는 더 넓은 개념을 포함합니다. 모든 LLM은 PLM이지만, 모든 PLM이 LLM인 것은 아니죠. PLM은 크기와 관계없이 사전 훈련된 모델을 의미할 수 있습니다.\\n\\n2. **학습 방식**: PLM은 대량의 텍스트 데이터에 대한 사전 훈련을 통해 일반적인 언어 이해 능력을 배양합니다. 그런 다음 특정 작업에 대해 미세 조정될 수 있습니다. LLM도 비슷한 접근 방식을 따르지만, 더 많은 매개변수와 더 복잡한 아키텍처를 사용하여 훨씬 더 정교한 언어 생성과 이해를 할 수 있습니다.\\n\\n3. **용도**: LLM은 보통 다양한 언어 처리 작업을 수행하는 데 더 적합하고, PLM은 특정 응용 프로그램에 맞춰 조정되는 경우가 많습니다. 하지만 두 모델 모두 질문 응답, 번역, 텍스트 생성 등 여러 작업에 활용될 수 있습니다.\\n\\n이렇듯 LLM과 PLM은 개념적으로 연결되어 있지만, 그 크기와 성능, 응용 방식에서 차이가 있어요. 더 궁금한 점이 있으면 말씀해 주세요!', additional_kwargs={}, response_metadata={})]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d6347c-2c99-4d28-b9e6-b7585d72a043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Created a chunk of size 2293, which is longer than the specified 1000\n",
      "Created a chunk of size 2843, which is longer than the specified 1000\n",
      "Created a chunk of size 6664, which is longer than the specified 1000\n",
      "Created a chunk of size 2194, which is longer than the specified 1000\n",
      "Created a chunk of size 1471, which is longer than the specified 1000\n",
      "Created a chunk of size 2774, which is longer than the specified 1000\n",
      "Created a chunk of size 1873, which is longer than the specified 1000\n",
      "Created a chunk of size 3432, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 2746, which is longer than the specified 1000\n",
      "Created a chunk of size 3230, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "# https://api.python.langchain.com/en/latest/api_reference.html#module-langchain.document_loaders\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(web_path=\"https://ko.wikipedia.org/wiki/IU\")\n",
    "documents = loader.load()\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "692cd1a0-48c1-48b6-977c-a2a48ea96fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/IU', 'title': '아이유 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='아이유 - 위키백과, 우리 모두의 백과사전\\n\\n\\n본문으로 이동\\n\\n주 메뉴\\n\\n주 메뉴\\n사이드바로 이동\\n숨기기\\n\\n\\t\\t둘러보기\\n\\t\\n\\n\\n대문최근 바뀜요즘 화제임의의 문서로\\n\\n\\t\\t사용자 모임\\n\\t\\n\\n\\n사랑방사용자 모임관리 요청\\n\\n\\t\\t편집 안내\\n\\t\\n\\n\\n소개도움말정책과 지침질문방\\n\\n검색\\n\\n검색\\n\\n\\n보이기\\n\\n\\n기부\\n\\n계정 만들기\\n\\n로그인\\n\\n\\n개인 도구\\n\\n기부 계정 만들기 로그인\\n\\n\\n목차\\n사이드바로 이동\\n숨기기\\n\\n\\n처음 위치\\n\\n1\\n학력\\n\\n\\n2\\n활동\\n\\n\\n활동 하위섹션 토글하기\\n\\n2.1\\n2008-2010\\n\\n\\n2.2\\n2011-2013\\n\\n\\n2.3\\n2014-2016\\n\\n\\n2.4\\n2017-2018\\n\\n\\n2.5\\n2019-2020\\n\\n\\n2.6\\n2021-2022\\n\\n\\n2.7\\n2023-2024\\n\\n\\n2.8\\n2025\\n\\n\\n3\\n음반 목록\\n\\n\\n4\\n음반 외 활동 목록\\n\\n\\n5\\n수상 및 후보 목록\\n\\n\\n6\\n사건\\n\\n\\n7\\n같이 보기\\n\\n\\n8\\n각주\\n\\n\\n각주 하위섹션 토글하기\\n\\n8.1\\n내용주\\n\\n\\n8.2\\n참조주\\n\\n\\n9\\n외부 링크\\n\\n\\n목차 토글\\n\\n아이유\\n\\n63개 언어'),\n",
       " Document(metadata={'source': 'https://ko.wikipedia.org/wiki/IU', 'title': '아이유 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='العربيةمصرىتۆرکجهBasa BaliBikol CentralБългарскиCatalàCebuanoکوردیČeštinaDanskDeutschKadazandusunΕλληνικάEnglishEsperantoEspañolEestiEuskaraفارسیSuomiFrançaisहिन्दीKreyòl ayisyenMagyarՀայերենInterlinguaBahasa IndonesiaItaliano日本語JawaҚазақшаکٲشُرLatinaMāoriമലയാളംМонголBahasa Melayuမြန်မာဘာသာNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийSimple EnglishSlovenčinaSoomaaligaСрпски / srpskiSesothoSundaSvenskaதமிழ்ไทยTagalogSetswanaTürkçeУкраїнськаOʻzbekcha / ўзбекчаTiếng Việt中文閩南語 / Bân-lâm-gí粵語\\n\\n링크 편집\\n\\n문서토론\\n\\n한국어\\n\\n읽기원본 보기역사 보기\\n\\n도구\\n\\n도구\\n사이드바로 이동\\n숨기기\\n\\n\\t\\t동작\\n\\t\\n\\n\\n읽기원본 보기역사 보기\\n\\n\\t\\t일반\\n\\t\\n\\n\\n여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기고유 링크문서 정보이 문서 인용하기축약된 URL 얻기QR코드 다운로드\\n\\n\\t\\t인쇄/내보내기\\n\\t\\n\\n\\n책 만들기PDF로 다운로드인쇄용 판\\n\\n\\t\\t다른 프로젝트\\n\\t\\n\\n\\n위키미디어 공용위키데이터 항목\\n\\n보이기\\n사이드바로 이동\\n숨기기\\n\\n\\n위키백과, 우리 모두의 백과사전.'),\n",
       " Document(metadata={'source': 'https://ko.wikipedia.org/wiki/IU', 'title': '아이유 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='(IU에서 넘어옴)\\n  다른 뜻에 대해서는 아이유 (동음이의) 문서를 참고하십시오. IU는 여기로 연결됩니다. 다른 뜻에 대해서는 IU (동음이의) 문서를 참고하십시오.\\n아이유2022년 11월 25일 청룡영화상에서의 아이유기본 정보본명이지은출생1993년 5월 16일(1993-05-16)(32세)대한민국 서울특별시 성동구 송정동성별여성직업가수, 배우장르댄스, 발라드, 어쿠스틱, R&B활동 시기2008년~학력동덕여자고등학교 (졸업)레이블카카오엔터테인먼트, EMI 뮤직 재팬소속사EDAM 엔터테인먼트서명웹사이트edam-ent.com유튜브채널이지금 [IU Official]분야일상, 음악개설일2017년 2월 13일구독자 수978만\\xa0명(2024년 10월 6일 기준)총 조회수3,150,968,674회(2024년 10월 6일 기준)vte\\n\\n아이유(IU, 본명:\\xa0이지은, 李知恩[1], 1993년 5월 16일~)는 대한민국의 싱어송라이터, 작곡가, 배우이다. 2007년 로엔 엔터테인먼트(현 카카오 엔터테인먼트) 연습생으로 전속 계약을 맺고 15세의 나이에 2008년 첫 EP인 로스트 앤 파운드(Lost and Found)를 통해 가수로 데뷔했다.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36be6f88-571b-4010-bbdb-af25b75a43bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131074/4030962451.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "#embeddings = HuggingFaceEmbeddings() # sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding=embeddings,\n",
    "    ).from_loaders([loader])\n",
    "\n",
    "# 파일로 저장\n",
    "index.vectorstore.save_local(\"faiss-nj-IU\")\n",
    "# db = FAISS.load_local(\"faiss-nj-IU\", embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c656357-f0e7-439b-b6c6-14927f4e7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아이유의 데뷔곡은 2008년에 발매된 EP \"로스트 앤 파운드(Lost and Found)\"에 수록된 곡으로, 타이틀곡은 \"미아\"입니다.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유의 데뷔곡은?\", llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aebc9b7c-64b9-4cd5-be7d-f2e525e6a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아이유는 1993년 5월 16일에 태어났으므로, 2024년 기준으로 32세입니다.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유의 나이는?\", llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1917167b-5b64-4e99-9b8e-17a6047d5787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아이유는 1993년 5월 16일에 태어났으므로, 2025년 7월 22일 기준으로 32세입니다.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유의 나이는? (오늘은 2025년 7월 22일)\", llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "403356b0-5ef9-45a1-b0d7-743866575946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그에 대한 정보는 제시된 문맥에 포함되어 있지 않습니다. 따라서 아이유가 지금까지 총 몇 회의 콘서트를 했는지에 대해서는 알지 못합니다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유는 지금까지 총 콘서트를 몇회했는가?\", llm=chat, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
