import streamlit as st
import requests
import json
import os
from langchain_openai import OpenAI
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import pandas as pd
from langchain.docstore.document import Document

# API í‚¤ ì„¤ì •
GOCAMPING_API_KEY = "K2AYhwdzrV2Si6dE0o2o4teC1rALEVMixfdEP1Fqb8LwXQ52mSS1DMeBj8ZPhfMKr8ZguxMCI8L%2BYcFAgsLMiQ%3D%3D"
os.environ["OPENAI_API_KEY"] = "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"

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìº í•‘ì¥ ì¶”ì²œ ë„ìš°ë¯¸", page_icon="â›º")
st.title("â›º ìº í•‘ì¥ ì¶”ì²œ ì‹œìŠ¤í…œ")

def get_camping_data(keyword: str = ""):
    """ê³ ìº í•‘ APIì—ì„œ ìº í•‘ì¥ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        # ê²€ìƒ‰ì–´ê°€ ìˆëŠ” ê²½ìš° searchList API ì‚¬ìš©
        if keyword:
            url = f"http://apis.data.go.kr/B551011/GoCamping/searchList"
            params = {
                'serviceKey': GOCAMPING_API_KEY,
                'numOfRows': 50,  # ë” ë§ì€ ê²°ê³¼
                'pageNo': 1,
                'MobileOS': 'ETC',
                'MobileApp': 'TestApp',
                '_type': 'json',
                'keyword': keyword
            }
        else:
            url = f"http://apis.data.go.kr/B551011/GoCamping/basedList"
            params = {
                'serviceKey': GOCAMPING_API_KEY,
                'numOfRows': 50,
                'pageNo': 1,
                'MobileOS': 'ETC',
                'MobileApp': 'TestApp',
                '_type': 'json'
            }
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        return data['response']['body']['items']['item']
            
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return []

def create_vectorstore(camping_data):
    """ìº í•‘ì¥ ë°ì´í„°ë¡œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
    # ìº í•‘ì¥ ë°ì´í„°ë¥¼ ë¬¸ì„œ í˜•íƒœë¡œ ë³€í™˜
    documents = []
    for camp in camping_data:
        text = f"""
        ìº í•‘ì¥ëª…: {camp['facltNm']}
        ì£¼ì†Œ: {camp['addr1']}
        ì†Œê°œ: {camp['lineIntro']}
        ì…ì§€: {camp.get('lctCl', '')}
        ì—…ì¢…: {camp.get('induty', '')}
        ìš´ì˜ê¸°ê°„: {camp.get('operPdCl', '')}
        ì „í™”: {camp.get('tel', '')}
        í™ˆí˜ì´ì§€: {camp.get('homepage', '')}
        """
        documents.append(text)
    
    # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents([Document(page_content=doc) for doc in documents], embeddings)
    
    return vectorstore, documents

def analyze_camping_sites(query: str, camping_data: list) -> str:
    """LangChain ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•œ ìº í•‘ì¥ ë¶„ì„"""
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    df = pd.DataFrame(camping_data)
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    df = df[['facltNm', 'addr1', 'lineIntro', 'tel', 'lctCl', 'induty', 'operPdCl', 'sbrsCl', 'posblFcltyCl']]
    
    # ì—ì´ì „íŠ¸ ìƒì„±
    llm = OpenAI(temperature=0.7, model_name="gpt-3.5-turbo-instruct")
    agent = create_pandas_dataframe_agent(
        llm,
        df,
        verbose=True,
        handle_parsing_errors=True,
        allow_dangerous_code=True
    )
    
    # ë¶„ì„ í”„ë¡¬í”„íŠ¸
    prompt = f"""
ì‚¬ìš©ìê°€ ì°¾ëŠ” ì¡°ê±´: {query}

ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ìº í•‘ì¥ì„ ì°¾ì•„ì£¼ì„¸ìš”:
1. facltNm: ìº í•‘ì¥ëª…
2. addr1: ì£¼ì†Œ
3. lineIntro: í•œì¤„ì†Œê°œ
4. lctCl: ì…ì§€ (ì‚°, ìˆ², ê³„ê³¡, í•´ë³€ ë“±)
5. induty: ì—…ì¢… (ì¼ë°˜ì•¼ì˜ì¥, ê¸€ë¨í•‘, ì¹´ë¼ë°˜ ë“±)
6. sbrsCl: ë¶€ëŒ€ì‹œì„¤
7. posblFcltyCl: ì£¼ë³€ì´ìš©ê°€ëŠ¥ì‹œì„¤

ë¶„ì„ ë‹¨ê³„:
1. ì‚¬ìš©ì ì¡°ê±´ê³¼ ê°€ì¥ ì˜ ë§ëŠ” ìº í•‘ì¥ 3ê³³ì„ ì°¾ì•„ì£¼ì„¸ìš”
2. ê° ìº í•‘ì¥ì˜ ì¥ë‹¨ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”
3. ì‹œì„¤ê³¼ ì£¼ë³€ í™˜ê²½ì„ ê³ ë ¤í•œ ì¶”ì²œ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”

í•œê¸€ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
    
    try:
        response = agent.run(prompt)
        return response
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì‚¬ì´ë“œë°”ì— ê²€ìƒ‰ í¼ ë°°ì¹˜
with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰ ì„¤ì •")
    search_query = st.text_input(
        "ì›í•˜ëŠ” ìº í•‘ì¥ ì¡°ê±´ì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: ë°”ë‹¤ê°€ ë³´ì´ëŠ” ì¡°ìš©í•œ ìº í•‘ì¥",
        help="ìì—°í™˜ê²½, ì‹œì„¤, ë¶„ìœ„ê¸° ë“± ì›í•˜ëŠ” ì¡°ê±´ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”."
    )
    
    search_button = st.button("ê²€ìƒ‰ ì‹œì‘", type="primary")

# ë©”ì¸ í™”ë©´ì— ê²°ê³¼ í‘œì‹œ
if search_button and search_query:
    try:
        with st.spinner("ìº í•‘ì¥ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            # ê²€ìƒ‰ì–´ë¡œ ìº í•‘ì¥ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            camping_data = get_camping_data(search_query)
            
            if not camping_data:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
            else:
                # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                df = pd.DataFrame(camping_data)
                
                # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ í‘œì‹œ
                st.success(f"ì´ {len(df)}ê°œì˜ ìº í•‘ì¥ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
                st.subheader("ğŸ“ ê²€ìƒ‰ëœ ìº í•‘ì¥ ëª©ë¡")
                display_df = df[['facltNm', 'addr1', 'lineIntro', 'tel', 'lctCl', 'induty']].copy()
                display_df.columns = ['ìº í•‘ì¥ëª…', 'ì£¼ì†Œ', 'ì†Œê°œ', 'ì—°ë½ì²˜', 'ì…ì§€', 'ì—…ì¢…']
                st.dataframe(display_df, use_container_width=True)
                
                # AI ë¶„ì„ ê²°ê³¼
                with st.spinner("AIê°€ ìº í•‘ì¥ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    analysis = analyze_camping_sites(search_query, camping_data)
                    st.subheader("ğŸ¤– AI ìº í•‘ì¥ ì¶”ì²œ")
                    st.write(analysis)
                    
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
else:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì›í•˜ëŠ” ìº í•‘ì¥ ì¡°ê±´ì„ ì…ë ¥í•˜ê³  ê²€ìƒ‰ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    st.markdown("""
    ### ğŸ’¡ ê²€ìƒ‰ íŒ
    - ìì—°í™˜ê²½ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•´ë³´ì„¸ìš”
        - ì˜ˆ: "ë°”ë‹¤ê°€ ë³´ì´ëŠ” ìº í•‘ì¥"
        - ì˜ˆ: "ì‚°ì† ê³„ê³¡ ê·¼ì²˜ ìº í•‘ì¥"
    - ì›í•˜ëŠ” ì‹œì„¤ì´ë‚˜ ë¶„ìœ„ê¸°ë¥¼ ì„¤ëª…í•´ë³´ì„¸ìš”
        - ì˜ˆ: "ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥í•œ ì¡°ìš©í•œ ìº í•‘ì¥"
        - ì˜ˆ: "ê¸€ë¨í•‘ ì‹œì„¤ì´ ìˆëŠ” ê°€ì¡± ìº í•‘ì¥"
    """)