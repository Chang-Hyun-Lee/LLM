import gradio as gr
import openai
import base64
import io
from PIL import Image

# --- ì „ì—­ ë³€ìˆ˜ ---
client = None

# --- API í‚¤ ì„¤ì • í•¨ìˆ˜ ---
def set_api_key(api_key):
    """API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    global client
    if not api_key or not api_key.startswith("sk-"):
        client = None
        return ("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", gr.update(visible=True))
    try:
        client = openai.OpenAI(api_key=api_key)
        client.models.list()  # API í‚¤ ìœ íš¨ì„± ê²€ì¦
        return ("âœ… API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!", gr.update(visible=False))
    except Exception as e:
        client = None
        return (f"âŒ API í‚¤ ì¸ì¦ ì˜¤ë¥˜: {e}", gr.update(visible=True))

# --- ì´ë¯¸ì§€ ì¸ì½”ë”© í•¨ìˆ˜ ---
def encode_image(pil_image):
    """PIL ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
    buffer = io.BytesIO()
    pil_image.save(buffer, format="JPEG", quality=75)
    return base64.b64encode(buffer.getvalue()).decode('utf-8')

# --- ëŒ€í™” ìŠ¤íŠ¸ë¦¼ í•¨ìˆ˜ ---
def chat_stream(message, image, chatbot_display, api_history):
    """
    ì‚¬ìš©ì ì…ë ¥ê³¼ ëŒ€í™” ê¸°ë¡ì„ ë°›ì•„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•˜ê³ , ì…ë ¥ì°½ì„ ë¹„ì›ë‹ˆë‹¤.
    - chatbot_display: í™”ë©´ì— ë³´ì´ëŠ” ì±„íŒ… ë‚´ì—­ (HTML í¬í•¨)
    - api_history: OpenAI APIì™€ í†µì‹ í•˜ê¸° ìœ„í•œ ìˆœìˆ˜í•œ ë°ì´í„° ë‚´ì—­
    """
    message = message or ""
    yield chatbot_display, api_history, None, ""

    if not client:
        chatbot_display.append([message, "âŒ ë¨¼ì € ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."])
        yield chatbot_display, api_history, None, ""
        return

    try:
        api_messages = list(api_history)
        
        if image:
            base64_image = encode_image(image)
            content_parts = []

            if message.strip():
                content_parts.append({"type": "text", "text": message.strip()})

            content_parts.append({
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
            })

            api_messages.append({"role": "user", "content": content_parts})

        else:
            api_messages.append({"role": "user", "content": message})

        display_message = message
        if image:
            base64_image_display = encode_image(image)
            img_html = f'<img src="data:image/jpeg;base64,{base64_image_display}" style="max-width: 150px; max-height: 150px; display: block; margin-bottom: 10px;">'
            display_message = f"{img_html}{message}" if message else img_html
        
        chatbot_display.append([display_message, ""])

        if image:
            chatbot_display[-1][1] = "ğŸ–¼ï¸ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
            yield chatbot_display, api_history, None, ""

        stream = client.chat.completions.create(
            model="gpt-4o",
            messages=api_messages,
            stream=True,
            max_tokens=2048
        )

        full_response = ""
        for i, chunk in enumerate(stream):
            content = chunk.choices[0].delta.content
            if content:
                if i == 0 and image:
                    chatbot_display[-1][1] = ""
                full_response += content
                chatbot_display[-1][1] = full_response
                yield chatbot_display, api_history, None, ""

        api_history.append(api_messages[-1])
        api_history.append({"role": "assistant", "content": full_response})

    except Exception as e:
        error_message = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"
        chatbot_display[-1][1] = error_message
        yield chatbot_display, api_history, None, ""

# --- Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    api_history = gr.State([])

    gr.Markdown("## ğŸ¤– Gradio ë©€í‹°ëª¨ë‹¬ ì±—ë´‡ (ìµœì¢… ì™„ì„±ë³¸)")
    gr.Markdown("ì¢Œì¸¡ì— OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ê³ , ì´ë¯¸ì§€(ì„ íƒ)ì™€ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

    with gr.Row():
        with gr.Column(scale=2):
            gr.Markdown("### API ì„¤ì •")
            api_key_input = gr.Textbox(label="OpenAI API Key", placeholder="sk-...", type="password")
            api_status = gr.Markdown("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            set_key_button = gr.Button("API í‚¤ ì„¤ì •", variant="primary")
        with gr.Column(scale=5):
            chatbot = gr.Chatbot(label="ëŒ€í™”ì°½", height=600, render_markdown=True, bubble_full_width=False)
            with gr.Row():
                image_input = gr.Image(type="pil", label="ì´ë¯¸ì§€ ì—…ë¡œë“œ", height=150, scale=1)
                chat_input = gr.Textbox(label="ë©”ì‹œì§€ ì…ë ¥", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", scale=4)
            submit_button = gr.Button("ì „ì†¡", variant="primary")

    set_key_button.click(
        fn=set_api_key,
        inputs=[api_key_input],
        outputs=[api_status, api_key_input]
    )

    submit_listener = [chat_input, image_input, chatbot, api_history]
    output_components = [chatbot, api_history, image_input, chat_input]

    chat_input.submit(
        fn=chat_stream,
        inputs=submit_listener,
        outputs=output_components
    )

    submit_button.click(
        fn=chat_stream,
        inputs=submit_listener,
        outputs=output_components
    )

# --- ì›¹ ì„œë²„ ì‹¤í–‰ ---
demo.launch(inbrowser=True)
