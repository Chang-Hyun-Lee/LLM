# Day 3 ì‹¤ìŠµ: Streamlit PDF ChatGPT ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
# ì‹¤í–‰ ëª…ë ¹: streamlit run app.py

import streamlit as st
import os
import tempfile
from pathlib import Path
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import pickle

# ingest.py ëª¨ë“ˆ ì„í¬íŠ¸ (ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•¨)
from ingest import DocumentIngestor

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PDF ChatGPT",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .bot-message {
        background-color: #f5f5f5;
        border-left: 4px solid #4caf50;
    }
    .sidebar-header {
        font-size: 1.2rem;
        font-weight: bold;
        color: #333;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

class StreamlitPDFChatBot:
    def __init__(self):
        self.initialize_session_state()
    
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        if 'vectorstore' not in st.session_state:
            st.session_state.vectorstore = None
        if 'conversation_chain' not in st.session_state:
            st.session_state.conversation_chain = None
        if 'api_key_valid' not in st.session_state:
            st.session_state.api_key_valid = False
        if 'processing' not in st.session_state:
            st.session_state.processing = False
    
    def validate_api_key(self, api_key):
        """OpenAI API í‚¤ ê²€ì¦"""
        try:
            os.environ["OPENAI_API_KEY"] = api_key
            # ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ í‚¤ ê²€ì¦
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            client.models.list()
            return True
        except Exception:
            return False
    
    def setup_conversation_chain(self, api_key):
        """ëŒ€í™” ì²´ì¸ ì„¤ì •"""
        try:
            # LLM ì„¤ì •
            llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                temperature=0.7,
                api_key=api_key
            )
            
            # ë©”ëª¨ë¦¬ ì„¤ì •
            memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )
            
            # ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸ ìƒì„±
            if st.session_state.vectorstore:
                conversation_chain = ConversationalRetrievalChain.from_llm(
                    llm=llm,
                    retriever=st.session_state.vectorstore.as_retriever(
                        search_kwargs={"k": 3}
                    ),
                    memory=memory,
                    return_source_documents=True,
                    output_key="answer"  # ë©”ëª¨ë¦¬ì— ì €ì¥í•  í‚¤ ëª…ì‹œ
                )
                st.session_state.conversation_chain = conversation_chain
                return True
        except Exception as e:
            st.error(f"ëŒ€í™” ì²´ì¸ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
        return False
    
    def process_uploaded_file(self, uploaded_file, api_key):
        """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬"""
        if uploaded_file is None:
            return False
        
        try:
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # ë¬¸ì„œ ì¸ë±ì„œ ìƒì„±
            ingestor = DocumentIngestor(api_key)
            
            # PDF ì¸ë±ì‹±
            vectorstore = ingestor.ingest_pdf(tmp_file_path)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_file_path)
            
            if vectorstore:
                st.session_state.vectorstore = vectorstore
                return True
            
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        
        return False
    
    def load_saved_vectorstore(self, load_path, api_key):
        """ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ"""
        try:
            embeddings = OpenAIEmbeddings(api_key=api_key)
            vectorstore = FAISS.load_local(load_path, embeddings)
            st.session_state.vectorstore = vectorstore
            return True
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def get_response(self, question):
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        if not st.session_state.conversation_chain:
            return "ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
        
        try:
            # ì§ˆë¬¸ ì²˜ë¦¬
            result = st.session_state.conversation_chain({"question": question})
            
            # ë‹µë³€ê³¼ ì¶œì²˜ ì¶”ì¶œ
            answer = result["answer"]
            source_documents = result.get("source_documents", [])
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€
            if source_documents:
                sources = []
                for doc in source_documents:
                    page = doc.metadata.get('page', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    sources.append(f"í˜ì´ì§€ {page}")
                
                answer += f"\n\nğŸ“š **ì¶œì²˜**: {', '.join(set(sources))}"
            
            return answer
            
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def render_sidebar(self):
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.markdown('<p class="sidebar-header">ğŸ”§ ì„¤ì •</p>', unsafe_allow_html=True)
            
            # OpenAI API í‚¤ ì…ë ¥
            api_key = st.text_input(
                "OpenAI API í‚¤",
                type="password",
                help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            if api_key:
                if self.validate_api_key(api_key):
                    st.success("âœ… API í‚¤ê°€ ìœ íš¨í•©ë‹ˆë‹¤")
                    st.session_state.api_key_valid = True
                    
                    # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ëŒ€í™” ì²´ì¸ ì„¤ì •
                    if st.session_state.vectorstore and not st.session_state.conversation_chain:
                        self.setup_conversation_chain(api_key)
                else:
                    st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤")
                    st.session_state.api_key_valid = False
            
            st.divider()
            
            # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
            st.markdown('<p class="sidebar-header">ğŸ“ íŒŒì¼ ì—…ë¡œë“œ</p>', unsafe_allow_html=True)
            
            uploaded_file = st.file_uploader(
                "PDF íŒŒì¼ ì„ íƒ",
                type="pdf",
                help="ë¶„ì„í•  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
            )
            
            if uploaded_file and st.session_state.api_key_valid:
                if st.button("ğŸ“„ PDF ì²˜ë¦¬í•˜ê¸°", type="primary"):
                    st.session_state.processing = True
                    
                    with st.spinner("PDFë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘..."):
                        if self.process_uploaded_file(uploaded_file, api_key):
                            self.setup_conversation_chain(api_key)
                            st.success("âœ… PDF ì²˜ë¦¬ ì™„ë£Œ!")
                            st.rerun()
                        else:
                            st.error("âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨")
                    
                    st.session_state.processing = False
            
            st.divider()
            
            # ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ ì„¹ì…˜
            st.markdown('<p class="sidebar-header">ğŸ’¾ ì €ì¥ëœ ì¸ë±ìŠ¤</p>', unsafe_allow_html=True)
            
            load_path = st.text_input(
                "ì¸ë±ìŠ¤ ê²½ë¡œ",
                placeholder="ì˜ˆ: ./vectorstore",
                help="ì´ì „ì— ì €ì¥í•œ ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ"
            )
            
            if load_path and st.session_state.api_key_valid:
                if st.button("ğŸ“‚ ì¸ë±ìŠ¤ ë¡œë“œ"):
                    if self.load_saved_vectorstore(load_path, api_key):
                        self.setup_conversation_chain(api_key)
                        st.success("âœ… ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!")
                        st.rerun()
            
            st.divider()
            
            # ìƒíƒœ ì •ë³´
            st.markdown('<p class="sidebar-header">ğŸ“Š ìƒíƒœ</p>', unsafe_allow_html=True)
            
            if st.session_state.vectorstore:
                st.success("âœ… PDFê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")
                if hasattr(st.session_state.vectorstore, 'index'):
                    doc_count = st.session_state.vectorstore.index.ntotal
                    st.info(f"ğŸ“„ ë¬¸ì„œ ì²­í¬: {doc_count}ê°œ")
            else:
                st.warning("âš ï¸ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
            
            if st.session_state.conversation_chain:
                st.success("âœ… ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤")
            else:
                st.warning("âš ï¸ ì±—ë´‡ ì„¤ì • í•„ìš”")
            
            # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
                st.session_state.messages = []
                if st.session_state.conversation_chain:
                    st.session_state.conversation_chain.memory.clear()
                st.rerun()
    
    def render_main_content(self):
        """ë©”ì¸ ì½˜í…ì¸  ë Œë”ë§"""
        # í—¤ë”
        st.markdown('<h1 class="main-header">ğŸ¤– PDF ChatGPT</h1>', unsafe_allow_html=True)
        st.markdown("---")
        
        # ì‹œì‘ ì•ˆë‚´
        if not st.session_state.vectorstore:
            st.info("""
            ğŸ‘‹ **í™˜ì˜í•©ë‹ˆë‹¤!** 
            
            ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‚¬ìš©í•˜ë ¤ë©´:
            1. ğŸ“ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
            2. ğŸ“ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ì„¸ìš”
            3. ğŸ’¬ PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”
            """)
            return
        
        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì±„íŒ… ì…ë ¥
        if prompt := st.chat_input("PDFì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # ë´‡ ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    response = self.get_response(prompt)
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        self.render_sidebar()
        self.render_main_content()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    chatbot = StreamlitPDFChatBot()
    chatbot.run()


if __name__ == "__main__":
    main()