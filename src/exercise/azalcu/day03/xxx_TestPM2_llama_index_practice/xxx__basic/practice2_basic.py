# basic/practice2_basic.py
import streamlit as st
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding

st.title("ğŸ’¬ ê¸°ì´ˆ: ë©€í‹°í„´ ëŒ€í™”")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

# API í‚¤ ì…ë ¥
api_key = st.text_input("OpenAI API Key", type="password")

if api_key:
    # LlamaIndex ì„¤ì •
    Settings.llm = OpenAI(api_key=api_key)
    Settings.embed_model = OpenAIEmbedding(api_key=api_key)
    
    # ë¬¸ì„œ ë¡œë“œ ë° ì±„íŒ… ì—”ì§„ ìƒì„±
    documents = SimpleDirectoryReader("../docs").load_data()
    index = VectorStoreIndex.from_documents(documents)
    chat_engine = index.as_chat_engine()
    
    st.success(f"âœ… {len(documents)}ê°œ ë¬¸ì„œë¡œ ëŒ€í™” ì¤€ë¹„ ì™„ë£Œ!")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ
        response = chat_engine.chat(prompt)
        st.session_state.messages.append({"role": "assistant", "content": str(response)})
        with st.chat_message("assistant"):
            st.markdown(str(response))
else:
    st.warning("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")