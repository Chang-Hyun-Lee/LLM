# intermediate/practice1_intermediate.py
import streamlit as st
import os
import tempfile
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings, Document
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¬¸ì„œ QA", page_icon="ğŸ“š", layout="wide")
st.title("ğŸ“š ì¤‘ê¸‰: ë¬¸ì„œ QA ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", type="password")
    
    st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        accept_multiple_files=True,
        type=['pdf', 'txt', 'docx', 'doc', 'md'],
        help="PDF, TXT, DOCX, DOC, MD íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
    )
    
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

# ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜
@st.cache_data
def process_uploaded_files(uploaded_files):
    if not uploaded_files:
        return None, "ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    documents = []
    processed_files = []
    
    try:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            # ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥
            for uploaded_file in uploaded_files:
                file_path = os.path.join(temp_dir, uploaded_file.name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                processed_files.append(uploaded_file.name)
            
            # SimpleDirectoryReaderë¡œ ë¬¸ì„œ ë¡œë“œ
            reader = SimpleDirectoryReader(temp_dir)
            documents = reader.load_data()
        
        if not documents:
            return None, "ë¬¸ì„œë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return documents, f"ì„±ê³µì ìœ¼ë¡œ {len(documents)}ê°œ ë¬¸ì„œë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤: {', '.join(processed_files)}"
    
    except Exception as e:
        return None, f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"

# ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜ (ìºì‹œ ì ìš©)
@st.cache_resource
def create_index(documents, _api_key):
    try:
        Settings.llm = OpenAI(api_key=_api_key)
        Settings.embed_model = OpenAIEmbedding(api_key=_api_key)
        return VectorStoreIndex.from_documents(documents)
    except Exception as e:
        st.error(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

# ë©”ì¸ ì˜ì—­ì„ ë‘ ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„í• 
col1, col2 = st.columns([1, 2])

with col1:
    st.header("ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼")
    if uploaded_files:
        for i, file in enumerate(uploaded_files, 1):
            file_size = len(file.getbuffer()) / 1024  # KB
            st.write(f"**{i}. {file.name}**")
            st.write(f"   ğŸ“ í¬ê¸°: {file_size:.1f} KB")
            st.write(f"   ğŸ“„ íƒ€ì…: {file.type}")
    else:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")

with col2:
    st.header("ğŸ’¬ ì§ˆë¬¸ & ë‹µë³€")
    
    if api_key and uploaded_files:
        # íŒŒì¼ ì²˜ë¦¬
        with st.spinner("ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘..."):
            documents, message = process_uploaded_files(uploaded_files)
        
        if documents:
            st.success(message)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            with st.spinner("AI ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                index = create_index(documents, api_key)
            
            if index:
                st.success("âœ… ì¤€ë¹„ ì™„ë£Œ! ì´ì œ ì§ˆë¬¸í•˜ì„¸ìš”")
                
                # ì§ˆë¬¸ ì…ë ¥
                question = st.text_area(
                    "ë¬¸ì„œì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", 
                    placeholder="ì˜ˆ: ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?\në¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ”?\níŠ¹ì • ì£¼ì œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    height=100
                )
                
                if st.button("ğŸ¤– ë‹µë³€ ìƒì„±", type="primary"):
                    if question:
                        try:
                            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                                query_engine = index.as_query_engine()
                                response = query_engine.query(question)
                            
                            st.write("### ğŸ“ AI ë‹µë³€")
                            st.write(response)
                            
                            # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
                            if hasattr(response, 'source_nodes') and response.source_nodes:
                                with st.expander("ğŸ“„ ì°¸ì¡°ëœ ë¬¸ì„œ ë¶€ë¶„"):
                                    for i, node in enumerate(response.source_nodes):
                                        st.write(f"**ì°¸ì¡° {i+1}:**")
                                        st.write(f"```\n{node.text[:300]}...\n```")
                                        if hasattr(node, 'score'):
                                            st.write(f"*ê´€ë ¨ë„: {node.score:.3f}*")
                                        st.write("---")
                                        
                        except Exception as e:
                            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    else:
                        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            st.error(message)
    
    elif not api_key:
        st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        st.markdown("""
        ### ğŸ”‘ API í‚¤ ì–»ëŠ” ë°©ë²•:
        1. [OpenAI Platform](https://platform.openai.com/api-keys) ì ‘ì†
        2. 'Create new secret key' í´ë¦­
        3. ìƒì„±ëœ í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥
        """)
    
    elif not uploaded_files:
        st.info("ğŸ“¤ ì‚¬ì´ë“œë°”ì—ì„œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        st.markdown("""
        ### ğŸ“‹ ì‚¬ìš© ë°©ë²•:
        1. **API í‚¤ ì…ë ¥**: OpenAI API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥
        2. **íŒŒì¼ ì—…ë¡œë“œ**: PDF, TXT, DOCX ë“±ì˜ ë¬¸ì„œ ì—…ë¡œë“œ
        3. **ì§ˆë¬¸ ì…ë ¥**: ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ ì‘ì„±
        4. **ë‹µë³€ í™•ì¸**: AIê°€ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ì œê³µ
        
        ### ğŸ’¡ ì§€ì› íŒŒì¼ í˜•ì‹:
        - ğŸ“„ PDF íŒŒì¼
        - ğŸ“ í…ìŠ¤íŠ¸ íŒŒì¼ (TXT, MD)
        - ğŸ“Š ì›Œë“œ ë¬¸ì„œ (DOCX, DOC)
        """)

# í•˜ë‹¨ì— ì¶”ê°€ ì •ë³´
st.markdown("---")

# ì˜ˆì‹œ ì§ˆë¬¸ë“¤
with st.expander("ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ"):
    st.markdown("""
    **ì¼ë°˜ì ì¸ ì§ˆë¬¸:**
    - ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”
    - ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
    - í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”
    
    **êµ¬ì²´ì ì¸ ì§ˆë¬¸:**
    - [íŠ¹ì • ì£¼ì œ]ì— ëŒ€í•´ ì–´ë–»ê²Œ ì„¤ëª…í•˜ê³  ìˆë‚˜ìš”?
    - ë¬¸ì„œì—ì„œ ì–¸ê¸‰ëœ ìˆ«ì/ë°ì´í„°ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”
    - ê²°ë¡ ì´ë‚˜ ê¶Œì¥ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?
    
    **ë¶„ì„ì ì¸ ì§ˆë¬¸:**
    - ë¬¸ì„œì˜ ì¥ë‹¨ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”
    - ë‹¤ë¥¸ ê´€ì ì—ì„œëŠ” ì–´ë–»ê²Œ ë³¼ ìˆ˜ ìˆì„ê¹Œìš”?
    - ì‹¤ë¬´ì— ì–´ë–»ê²Œ ì ìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?
    """)

# ë””ë²„ê¹… ì •ë³´
with st.expander("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´"):
    st.write(f"ì—…ë¡œë“œëœ íŒŒì¼ ìˆ˜: {len(uploaded_files) if uploaded_files else 0}")
    st.write(f"API í‚¤ ì…ë ¥ë¨: {'âœ…' if api_key else 'âŒ'}")
    
    # íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸
    try:
        import llama_index
        st.write(f"llama-index: âœ… v{llama_index.__version__}")
    except:
        st.write("llama-index: âŒ ì„¤ì¹˜ í•„ìš”")
    
    try:
        import openai
        st.write(f"openai: âœ… v{openai.__version__}")
    except:
        st.write("openai: âŒ ì„¤ì¹˜ í•„ìš”")