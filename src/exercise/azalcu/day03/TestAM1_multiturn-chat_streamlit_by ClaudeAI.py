import streamlit as st
from openai import OpenAI
import os
from typing import Generator

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë©€í‹°í„´ ChatGPT ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        margin-bottom: 2rem;
    }
    .chat-container {
        max-height: 600px;
        overflow-y: auto;
        padding: 1rem;
        border-radius: 10px;
        background-color: #f8f9fa;
    }
    .stChatMessage {
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

class StreamlitChatBot:
    """Streamlitìš© ChatBot í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.client = None
        
    def initialize_client(self, api_key: str):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            self.client = OpenAI(api_key=api_key)
            return True
        except Exception as e:
            st.error(f"API í‚¤ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
            return False
    
    def get_response_streaming(self, messages: list) -> Generator[str, None, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ChatGPT ì‘ë‹µ ìƒì„±"""
        if not self.client:
            yield "âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            return
            
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                stream=True,
                max_tokens=1000,
                temperature=0.7
            )
            
            full_response = ""
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    yield full_response
                    
        except Exception as e:
            yield f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ChatBot ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
if 'chatbot' not in st.session_state:
    st.session_state.chatbot = StreamlitChatBot()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'api_key_set' not in st.session_state:
    st.session_state.api_key_set = False

# ë©”ì¸ í—¤ë”
st.markdown('<h1 class="main-header">ğŸ¤– ë©€í‹°í„´ ChatGPT ì±—ë´‡</h1>', unsafe_allow_html=True)
st.markdown('<p style="text-align: center; color: #666;">ChatGPTì™€ ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ ë‚˜ëˆ ë³´ì„¸ìš”! (Streamlit + ìŠ¤íŠ¸ë¦¬ë°)</p>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” - ì„¤ì • íŒ¨ë„
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        placeholder="sk-...",
        help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    
    if api_key and not st.session_state.api_key_set:
        if st.session_state.chatbot.initialize_client(api_key):
            st.session_state.api_key_set = True
            st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.session_state.api_key_set = False
    
    st.divider()
    
    # ëŒ€í™” ì„¤ì •
    st.subheader("ğŸ’¬ ëŒ€í™” ì„¤ì •")
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.success("ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()
    
    # í†µê³„ ì •ë³´
    st.divider()
    st.subheader("ğŸ“Š ëŒ€í™” í†µê³„")
    st.info(f"ğŸ’¬ ì´ ë©”ì‹œì§€ ìˆ˜: {len(st.session_state.messages)}")
    
    if st.session_state.messages:
        user_msgs = len([m for m in st.session_state.messages if m["role"] == "user"])
        assistant_msgs = len([m for m in st.session_state.messages if m["role"] == "assistant"])
        st.info(f"ğŸ‘¤ ì‚¬ìš©ì: {user_msgs}ê°œ")
        st.info(f"ğŸ¤– ChatGPT: {assistant_msgs}ê°œ")

# ë©”ì¸ ì±„íŒ… ì˜ì—­
col1, col2, col3 = st.columns([1, 8, 1])

with col2:
    # API í‚¤ í™•ì¸
    if not st.session_state.api_key_set:
        st.warning("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        st.info("ğŸ’¡ OpenAI API í‚¤ëŠ” https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ChatGPTì—ê²Œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # ChatGPT ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
            with st.chat_message("assistant"):
                response_placeholder = st.empty()
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                response_generator = st.session_state.chatbot.get_response_streaming(
                    st.session_state.messages
                )
                
                # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µ í‘œì‹œ
                full_response = ""
                for partial_response in response_generator:
                    full_response = partial_response
                    response_placeholder.markdown(partial_response + "â–Œ")
                
                # ìµœì¢… ì‘ë‹µ í‘œì‹œ (ì»¤ì„œ ì œê±°)
                response_placeholder.markdown(full_response)
                
                # ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
                st.session_state.messages.append({"role": "assistant", "content": full_response})

# í•˜ë‹¨ ì •ë³´ íŒ¨ë„
st.divider()

# í™•ì¥ ê°€ëŠ¥í•œ ì‚¬ìš©ë²• ì•ˆë‚´
with st.expander("ğŸ“– ì‚¬ìš©ë²• ë° ê¸°ëŠ¥ ì•ˆë‚´"):
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ğŸš€ ì£¼ìš” ê¸°ëŠ¥
        - **ë©€í‹°í„´ ëŒ€í™”**: ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µ
        - **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: ì‘ë‹µ ìƒì„± ê³¼ì •ì„ ì‹¤ì‹œê°„ í™•ì¸
        - **ëŒ€í™” ê¸°ë¡ ê´€ë¦¬**: ì–¸ì œë“  ëŒ€í™” ì´ˆê¸°í™” ê°€ëŠ¥
        - **í†µê³„ ì •ë³´**: ëŒ€í™” í˜„í™©ì„ í•œëˆˆì— í™•ì¸
        
        ### ğŸ’¡ ì‚¬ìš© íŒ
        - êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§ˆë¬¸ì„ í•˜ë©´ ë” ì¢‹ì€ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ì¡°í•˜ì—¬ ì—°ì†ì ì¸ ì§ˆë¬¸ ê°€ëŠ¥
        - ì£¼ì œë¥¼ ë°”ê¾¸ê³  ì‹¶ìœ¼ë©´ 'ëŒ€í™” ì´ˆê¸°í™”' ì‚¬ìš©
        """)
    
    with col2:
        st.markdown("""
        ### âš™ï¸ ì„¤ì • ë°©ë²•
        1. **API í‚¤ ë°œê¸‰**: OpenAI ì›¹ì‚¬ì´íŠ¸ì—ì„œ API í‚¤ ìƒì„±
        2. **í‚¤ ì…ë ¥**: ì‚¬ì´ë“œë°”ì˜ ì„¤ì • íŒ¨ë„ì— API í‚¤ ì…ë ¥
        3. **ëŒ€í™” ì‹œì‘**: í•˜ë‹¨ ì±„íŒ… ì…ë ¥ì°½ì— ë©”ì‹œì§€ ì‘ì„±
        4. **ì‘ë‹µ í™•ì¸**: ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ì‘ë‹µ í™•ì¸
        
        ### âš ï¸ ì£¼ì˜ì‚¬í•­
        - OpenAI API í‚¤ê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤
        - ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤
        - API ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ìš”ê¸ˆì´ ë¶€ê³¼ë©ë‹ˆë‹¤
        - API í‚¤ëŠ” ì•ˆì „í•˜ê²Œ ë³´ê´€í•˜ì„¸ìš”
        """)

# í‘¸í„°
st.markdown("---")
st.markdown(
    '<p style="text-align: center; color: #888; font-size: 0.8rem;">ğŸ’» Streamlitìœ¼ë¡œ êµ¬í˜„ëœ ë©€í‹°í„´ ChatGPT ì±—ë´‡ | ì½”ì‹œíŒŒêµìœ¡ Day3 ì‹¤ìŠµ</p>',
    unsafe_allow_html=True
)

if __name__ == "__main__":
    import subprocess
    import sys
    import os
    
    # í˜„ì¬ íŒŒì¼ì„ streamlitìœ¼ë¡œ ì‹¤í–‰
    try:
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", 
            __file__, 
            "--server.address", "0.0.0.0",
            "--server.port", "8501",
            "--browser.serverAddress", "localhost"
        ])
    except KeyboardInterrupt:
        print("Streamlit ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
