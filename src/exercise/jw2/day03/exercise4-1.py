# ì‹¤ìŠµ #1. llama_indexì™€ Streamlitì„ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ëœ íŒŒì¼ì— ëŒ€í•´ì„œ ë‹µë³€í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.
#ì‹¤ìŠµ #2. llama_indexì™€ Streamlitì„ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ëœ íŒŒì¼ì— ëŒ€í•´ì„œ ë‹µë³€í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ë©€í‹°í„´ìœ¼ë¡œ ë°”ê¾¸ì‹œì˜¤.
#ì‹¤ìŠµ #3. llama_indexì™€ Streamlitì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì—…ë¡œë“œí•œ íŒŒì¼ ì „ì²´ì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.
#ì‹¤ìŠµ #4. ì‹¤ìŠµ #3ì˜ ì–´í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ì—…í•˜ê³  ì‚­ì œí•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, SummaryIndex


#response = query_engine.query("ì†Œë…„ê³¼ ì†Œë…€ëŠ” ì–´ë””ì—ì„œ ì²˜ìŒ ë§Œë‚¬ë‚˜? í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì¤˜.")
#print(response)

import streamlit as st
import os
import openai

from tempfile import TemporaryDirectory

st.title("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")

# ì—¬ëŸ¬ íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥ (PDF, TXT ë“±)
uploaded_files = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf", "txt", "md"], accept_multiple_files=True)

documents = []

# ì²˜ìŒ ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ ìš”ì•½í•˜ëŠ” ë¶€ë¶„
@st.cache_data
def data_open(files):
    if files:
        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            with TemporaryDirectory() as tmpdir:
                for file in files:
                    file_path = os.path.join(tmpdir, file.name)
                    with open(file_path, "wb") as f:
                        f.write(file.read())

                documents = SimpleDirectoryReader(tmpdir).load_data()
                index = SummaryIndex.from_documents(documents)
                query_engine = index.as_query_engine()
                summary = query_engine.query("ì´ ë¬¸ì„œ ì „ì²´ë¥¼ ìš”ì•½í•´ì¤˜")
        return summary
    return None

summary = data_open(uploaded_files)

st.write("ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:")
if summary:  # summaryê°€ Noneì´ ì•„ë‹ ë•Œ
    st.write(summary.response)
else:
    st.write("ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

documents = SimpleDirectoryReader("data").load_data()
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()


openai.api_key = os.getenv("OPENAI_API_KEY")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

response = query_engine.query(f"{user_input}+í•œê¸€ë¡œ ë§í•´ì¤˜")

if user_input:
    
    st.session_state["messages"].append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)


    st.session_state["messages"].append({"role": "assistant", "content": response.response})
    with st.chat_message("assistant"):
        st.write(response.response)
