# ì‹¤ìŠµ #1. llama_indexì™€ Streamlitì„ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ëœ íŒŒì¼ì— ëŒ€í•´ì„œ ë‹µë³€í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.
#ì‹¤ìŠµ #2. llama_indexì™€ Streamlitì„ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ëœ íŒŒì¼ì— ëŒ€í•´ì„œ ë‹µë³€í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ë©€í‹°í„´ìœ¼ë¡œ ë°”ê¾¸ì‹œì˜¤.
#ì‹¤ìŠµ #3. llama_indexì™€ Streamlitì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì—…ë¡œë“œí•œ íŒŒì¼ ì „ì²´ì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.
#ì‹¤ìŠµ #4. ì‹¤ìŠµ #3ì˜ ì–´í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ì—…í•˜ê³  ì‚­ì œí•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, SummaryIndex

#response = query_engine.query("ì†Œë…„ê³¼ ì†Œë…€ëŠ” ì–´ë””ì—ì„œ ì²˜ìŒ ë§Œë‚¬ë‚˜? í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì¤˜.")
#print(response)

import streamlit as st
import os
import openai

from tempfile import TemporaryDirectory

st.title("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")

# ì—¬ëŸ¬ íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥ (PDF, TXT ë“±)
uploaded_files = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf", "txt", "md"], accept_multiple_files=True)

documents = []

@st.cache_data
def data_open(uploaded_files):
    if uploaded_files:
        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            with TemporaryDirectory() as tmpdir:
                for uploaded_file in uploaded_files:
                    file_path = os.path.join(tmpdir, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.read())

                # SimpleDirectoryReaderë¡œ ë¬¸ì„œ ì½ê¸°
                documents = SimpleDirectoryReader(tmpdir).load_data()
                index = SummaryIndex.from_documents(documents)
                query_engine = index.as_query_engine()
                summary = query_engine.query("ì´ ë¬¸ì„œ ì „ì²´ë¥¼ ìš”ì•½í•´ì¤˜")
        return summary, documents, query_engine

# ì—…ë¡œë“œ íŒŒì¼ì´ ìˆë‹¤ë©´ / ì—†ìœ¼ë©´ PASS => ì²˜ìŒ ì‹¤í–‰ì‹œ ì•„ë¬´ê²ƒë„ ì—†ëŠ”ë° ê°€ì ¸ì˜¤ê²Œ ë˜ë‹ˆ ì˜¤ë¥˜
if uploaded_files:
    summary, documents, query_engine = data_open(uploaded_files)


    st.success(f"âœ… ì´ {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.write("ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:")
    st.write(documents[-1].text[:100])
    st.write("ì¤„ê±°ë¦¬ ì„¤ëª…:")
    st.write(summary.response)



    openai.api_key = os.getenv("OPENAI_API_KEY")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    for msg in st.session_state["messages"]:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

    if user_input:
        
        st.session_state["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        response = query_engine.query(f"{user_input} (í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”)")

        st.session_state["messages"].append({"role": "assistant", "content": response.response})
        with st.chat_message("assistant"):
            st.write(response.response)
