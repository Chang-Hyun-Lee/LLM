{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71018c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76129/160439823.py:49: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "/tmp/ipykernel_76129/160439823.py:49: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7876\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실습 #1: gradio의 chatbot interface를 사용하여 ChatGPT와 스트리밍하면서 대화하는 인터페이스를 구성하시오.\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.update(value=\"\", interactive=False)\n",
    "\n",
    "def add_file(history, file):\n",
    "    history = history + [((file.name,), None)]\n",
    "    return history\n",
    "\n",
    "# 싱글턴 GPT 응답 생성\n",
    "def bot(history):\n",
    "    # 사용자의 마지막 질문만 전달\n",
    "    user_input = history[-1][0]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"너는 대화형 챗봇이야. 상냥하게 대답해줘.\"},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    # 스트리밍 응답 생성\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    history[-1][1] = \"\"  # 봇 응답 초기화\n",
    "\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta.content:\n",
    "            history[-1][1] += delta.content\n",
    "            time.sleep(0.02)\n",
    "            yield history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        [],\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        avatar_images=(None, (os.path.join(\"avatar.png\"))),\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            scale=4,\n",
    "            show_label=False,\n",
    "            placeholder=\"텍스트를 입력하고 엔터를 치거나 이미지를 업로드하세요\",\n",
    "            container=False,\n",
    "        )\n",
    "        btn = gr.UploadButton(\"Upload\", file_types=[\"image\", \"video\", \"audio\"])\n",
    "\n",
    "    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(server_name='0.0.0.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248edac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 #2: 만든 어플리케이션을 멀티턴(이전 대화 내용을 기억하고 문맥에 따라 응답하기 위함)으로 수정하시오.\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.update(value=\"\", interactive=False)\n",
    "\n",
    "def add_file(history, file):\n",
    "    history = history + [((file.name,), None)]\n",
    "    return history\n",
    "\n",
    "# GPT 응답 생성 및 스트리밍\n",
    "def bot(history):\n",
    "    # history를 ChatGPT가 이해할 수 있는 message 포맷으로 변환\n",
    "    messages = [{\"role\": \"system\", \"content\": \"너는 대화형 챗봇이야. 상냥하게 대답해줘.\"}]\n",
    "    for user, bot_response in history:\n",
    "        if isinstance(user, tuple):  # 파일 입력인 경우 무시\n",
    "            continue\n",
    "        messages.append({\"role\": \"user\", \"content\": user})\n",
    "        if bot_response:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "\n",
    "    # 응답을 스트리밍 형태로 생성\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    history[-1][1] = \"\"  # 봇 응답 초기화\n",
    "\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta.content:\n",
    "            history[-1][1] += delta.content\n",
    "            time.sleep(0.02)\n",
    "            yield history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        [],\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        avatar_images=(None, (os.path.join(\"avatar.png\"))),\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            scale=4,\n",
    "            show_label=False,\n",
    "            placeholder=\"텍스트를 입력하고 엔터를 치거나 이미지를 업로드하세요\",\n",
    "            container=False,\n",
    "        )\n",
    "        btn = gr.UploadButton(\"Upload\", file_types=[\"image\", \"video\", \"audio\"])\n",
    "\n",
    "    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(server_name='0.0.0.0')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
