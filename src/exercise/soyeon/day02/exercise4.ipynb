{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7ea3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six==20250506\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypdfium2>=4.18.0\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from pdfplumber) (11.3.0)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Downloading cryptography-45.0.5-cp37-abi3-manylinux_2_34_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
      "Collecting cffi>=1.14\n",
      "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m446.2/446.2 KB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.6/117.6 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed cffi-1.17.1 cryptography-45.0.5 pdfminer.six-20250506 pdfplumber-0.11.7 pycparser-2.22 pypdfium2-4.30.0\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ìŠµ #1: langchainì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ pdf íŒŒì¼ì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ëŠ” ChatGPT ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "!pip install -qU langchain_community\n",
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a466095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "import os\n",
    "\n",
    "# í™ˆ ë””ë ‰í† ë¦¬ í¬í•¨ëœ ê²½ë¡œë¥¼ ì•ˆì „í•˜ê²Œ í™•ì¥\n",
    "path = os.path.expanduser(\"~/work/koshipa-llm-2025-1st/src/exercise/soyeon/day02/ì†Œë‚˜ê¸°.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832a673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFPlumberLoader(path)\n",
    "docs = loader.load()\n",
    "documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d155e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '/home/ubuntu/work/koshipa-llm-2025-1st/src/exercise/soyeon/day02/ì†Œë‚˜ê¸°.pdf', 'file_path': '/home/ubuntu/work/koshipa-llm-2025-1st/src/exercise/soyeon/day02/ì†Œë‚˜ê¸°.pdf', 'page': 0, 'total_pages': 7, 'Author': 'MYHOME', 'Creator': 'Hwp 2018 10.0.0.11131', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20211129200550+09'00'\", 'ModDate': \"D:20211129200550+09'00'\", 'PDFVersion': '1.4'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì´ ê¸€ì€ ì†Œë…„ê³¼ ì†Œë…€ì˜ ì¼ìƒì ì¸ ìˆœê°„ì„ ë¬˜ì‚¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì†Œë…€ëŠ” ëŒ€ì¶”ë¥¼ ë”°ì„œ ì†Œë…„ì—ê²Œ ì£¼ë©°, ì œì‚¬ë¥¼ ì§€ë‚¼ ê²ƒì´ë¼ê³  ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ì†Œë…„ì€ ì†Œë…€ì˜ ì–´ê¹¨ë¥¼ ê°ì‹¸ì£¼ê³ , ë¹„ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ìˆ˜ìˆ«ë‹¨ ì†ìœ¼ë¡œ ë“¤ì–´ê°€ë ¤ í•©ë‹ˆë‹¤. ëŒ€í™” ì¤‘ì— ì†Œë…„ì˜ ê°€ì¡±ê³¼ ì†Œë…€ì˜ ê°€ì¡±ì— ëŒ€í•œ ì´ì•¼ê¸°ê°€ ì˜¤ê°€ë©°, ì†Œë…€ì˜ ì§‘ì•ˆì´ ì–´ë ¤ìš´ ìƒí™©ì— ì²˜í•´ ìˆë‹¤ëŠ” ì ì´ ë“œëŸ¬ë‚©ë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ì†Œë…„ê³¼ ì†Œë…€ì˜ ê´€ê³„ì™€ ê·¸ë“¤ì˜ ê°€ì¡± ìƒí™©ì´ ì—®ì—¬ ìˆëŠ” ì´ì•¼ê¸°ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "len(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "#embeddings = HuggingFaceEmbeddings() # sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding=embeddings,\n",
    "    ).from_loaders([loader])\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "\n",
    "index.query(\"ìš”ì•½í•´ì¤˜\", llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b924109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë‹µë³€:\n",
      " ì´ ì´ì•¼ê¸°ëŠ” ì†Œë…„ê³¼ ì†Œë…€ì˜ ì§§ì€ ë§Œë‚¨ê³¼ ê·¸ë“¤ ì‚¬ì´ì˜ ê°ì •ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì†Œë…„ì€ ì†Œë…€ì™€ í•¨ê»˜ ì‚°ì„ ì˜¤ë¥´ë©° ê½ƒì„ êº¾ê³ , ì†Œë…€ê°€ ë‹¤ì³¤ì„ ë•Œ ì†¡ì§„ì„ ë°œë¼ì£¼ëŠ” ë“± ì†Œë…€ì—ê²Œ í˜¸ê°ì„ ë³´ì…ë‹ˆë‹¤. ì†Œë…€ëŠ” ì„œìš¸ì—ì„œ ì˜¨ ì•„ì´ë¡œ, ì‹œê³¨ ìƒí™œì— ì ì‘í•˜ì§€ ëª»í•˜ê³  ì‹¬ì‹¬í•´í•©ë‹ˆë‹¤. ë‘˜ì€ í•¨ê»˜ ì‹œê°„ì„ ë³´ë‚´ë©° ê°€ê¹Œì›Œì§€ì§€ë§Œ, ì†Œë…€ëŠ” ê²°êµ­ ë³‘ìœ¼ë¡œ ì„¸ìƒì„ ë– ë‚˜ê²Œ ë©ë‹ˆë‹¤. ì†Œë…€ì˜ ì£½ìŒì€ ì†Œë…„ì—ê²Œ í° ì¶©ê²©ì„ ì£¼ë©°, ì†Œë…€ì˜ ë§ˆì§€ë§‰ ì†Œì›ì€ ìì‹ ì´ ì…ë˜ ì˜·ì„ ì…ê³  ë¬»íˆëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. ì´ì•¼ê¸°ëŠ” ì†Œë…„ì˜ ìˆœìˆ˜í•œ ê°ì •ê³¼ ì†Œë…€ì˜ ì£½ìŒì„ í†µí•´ ì‚¶ì˜ ë¬´ìƒí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "# 1. OpenAI API í‚¤ ì„¤ì •\n",
    "os.environ[\"OPENAI_API_KEY\"] \n",
    "\n",
    "# 2. PDF ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "path = os.path.expanduser(\"~/work/koshipa-llm-2025-1st/src/exercise/soyeon/day02/ì†Œë‚˜ê¸°.pdf\")\n",
    "loader = PDFPlumberLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "# 3. ë¬¸ì„œ ë¶„í• \n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 4. ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "# 5. Retriever QA ì²´ì¸ êµ¬ì„±\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0),\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# 6. ì§ˆë¬¸\n",
    "question = \"ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½í•´ì¤˜\"\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "# 7. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ“Œ ë‹µë³€:\\n\", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
