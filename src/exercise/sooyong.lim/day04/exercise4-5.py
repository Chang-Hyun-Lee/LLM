import os
import json
import requests
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from pykrx import stock
from openai import OpenAI
import xml.etree.ElementTree as ET

# LangChain ê´€ë ¨ ì„í¬íŠ¸ (ì£¼ê°€ ë¶„ì„ Agentì—ë§Œ ì‚¬ìš©)
from langchain import hub
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import tool
from langchain.chat_models import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
# TavilySearchResultsëŠ” ì£¼ê°€ ë¶„ì„ Agentê°€ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ì„ í•  ë•Œ í•„ìš”í•©ë‹ˆë‹¤.
# ë§Œì•½ Tavily APIë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ì´ ë¼ì¸ê³¼ Agent ì´ˆê¸°í™” ë¶€ë¶„ì—ì„œ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.
# from langchain_community.tools.tavily_search import TavilySearchResults

# âœ… API í‚¤ ì„¤ì • (ê¸°ì¡´ ì½”ë“œì˜ í•˜ë“œì½”ë”© ë°©ì‹ ìœ ì§€)
# OpenAI API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# ì¹´ì¹´ì˜¤ API í‚¤ (í•˜ë“œì½”ë”© ìœ ì§€)
KAKAO_REST_API_KEY = "c662192f1e74c3c14e16950ee0d6d5e1"
# GoCamping API í‚¤ (í•˜ë“œì½”ë”© ìœ ì§€)
CAMP_API_KEY = "DCvakj3KUyfmU0c%2FF7CbsLX4VXkEjGdcDfj1A0tFvZzJZL9h70OoFvmEeWVg54OdoXH7mOXwxIHM45Mx6IVxlA%3D%3D"

# --- Streamlit ì•± ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="GPT í†µí•© ì¶”ì²œê¸°", layout="wide")
st.title("ğŸ¯ GPT ê¸°ë°˜ í†µí•© ì¶”ì²œê¸°")

# ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ëŠ¥ ì„ íƒ
option = st.sidebar.selectbox("ê¸°ëŠ¥ ì„ íƒ", ["ë§›ì§‘ ì¶”ì²œ", "ìº í•‘ì¥ ì¶”ì²œ", "ì£¼ê°€ ë¶„ì„"])

# ==============================================================================
# --- ğŸ½ï¸ ë§›ì§‘ ì¶”ì²œ ê¸°ëŠ¥ ---
# ==============================================================================
if option == "ë§›ì§‘ ì¶”ì²œ":
    st.header("ğŸ½ï¸ GPT ë§›ì§‘ ì¶”ì²œê¸°")
    st.markdown("ì¹´ì¹´ì˜¤ APIì™€ GPTë¥¼ í™œìš©í•œ ì§€ì—­ ê¸°ë°˜ ë§›ì§‘ ì¶”ì²œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.")

    def search_restaurants_kakao(query, location, size=7):
        url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
        params = {
            "query": f"{location} {query}",
            "size": size,
            "page": 1,
            "sort": "accuracy",
            "category_group_code": "FD6",
        }
        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            results = response.json()
            return results.get("documents", [])
        except requests.exceptions.RequestException as e:
            st.error(f"ì¹´ì¹´ì˜¤ ë§›ì§‘ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return []

    def format_restaurants_for_gpt(restaurants):
        formatted = ""
        for r in restaurants:
            name = r.get("place_name", "ì´ë¦„ ì—†ìŒ")
            address = r.get("address_name", "ì£¼ì†Œ ì—†ìŒ")
            phone = r.get("phone", "ë²ˆí˜¸ ì—†ìŒ")
            category = r.get("category_name", "ì¹´í…Œê³ ë¦¬ ì—†ìŒ")
            formatted += f"{name} | {category} | ì£¼ì†Œ: {address} | ì „í™”: {phone}\n"
        return formatted

    def ask_gpt_to_recommend_restaurant(restaurants_text, location, user_question):
        prompt = (
            f"ì•„ë˜ëŠ” '{location}' ì§€ì—­ì˜ ìŒì‹ì  ëª©ë¡ì…ë‹ˆë‹¤:\n\n"
            f"{restaurants_text}\n\n"
            f"ì´ ì¤‘ì—ì„œ '{user_question}'ì— ë§ê²Œ 3ê³³ ì¶”ì²œí•˜ê³ , ê°„ë‹¨í•œ ì„¤ëª…ë„ ë§ë¶™ì—¬ì¤˜."
        )
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ìŒì‹ì  ì¶”ì²œ ë„ìš°ë¯¸ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=700
            )
            return response.choices[0].message.content
        except Exception as e:
            st.error(f"GPT ë§›ì§‘ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return "ë§›ì§‘ ì¶”ì²œì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    with st.form("restaurant_search_form"):
        location = st.text_input("ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í™ëŒ€, íŒêµ ë“±)", "")
        query = st.text_input("ì–´ë–¤ ìŒì‹ì ì´ ê¶ê¸ˆí•œê°€ìš”? (ì˜ˆ: ë¶„ìœ„ê¸° ì¢‹ì€ ì´íƒˆë¦¬ì•ˆ ì‹ë‹¹)", "")
        submitted = st.form_submit_button("ì¶”ì²œë°›ê¸°")

    if submitted:
        if not location or not query:
            st.warning("ì§€ì—­ê³¼ ê²€ìƒ‰ ì¡°ê±´ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ğŸ” ì¹´ì¹´ì˜¤ APIë¡œ ìŒì‹ì  ê²€ìƒ‰ ì¤‘..."):
                restaurants = search_restaurants_kakao(query, location)
                if not restaurants:
                    st.error("ê²€ìƒ‰ëœ ìŒì‹ì ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ì„ ì‹œë„í•´ ë³´ì„¸ìš”.")
                else:
                    restaurants_text = format_restaurants_for_gpt(restaurants)
                    st.subheader("ğŸ“‹ ê²€ìƒ‰ëœ ìŒì‹ì  ëª©ë¡")
                    st.text(restaurants_text) # GPT ë¶„ì„ì„ ìœ„í•œ ì›ë³¸ ë°ì´í„° í‘œì‹œ

                    with st.spinner("ğŸ¤– GPTì—ê²Œ ì¶”ì²œ ìš”ì²­ ì¤‘..."):
                        recommendation = ask_gpt_to_recommend_restaurant(restaurants_text, location, query)
                        st.subheader("ğŸ´ GPT ì¶”ì²œ ê²°ê³¼")
                        st.success(recommendation)

# ==============================================================================
# --- ğŸ•ï¸ ìº í•‘ì¥ ì¶”ì²œ ê¸°ëŠ¥ ---
# ==============================================================================
elif option == "ìº í•‘ì¥ ì¶”ì²œ":
    st.header("ğŸ•ï¸ GPT ìº í•‘ì¥ ì¶”ì²œê¸° (ê³µê³µë°ì´í„° ê¸°ë°˜)")
    st.markdown("**ê³µê³µë°ì´í„°í¬í„¸ì˜ GoCamping ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¡°ê±´ì— ë§ëŠ” ìº í•‘ì¥ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.**")

    @st.cache_data
    def fetch_campgrounds_from_api(num=15):
        url = (
            f"https://apis.data.go.kr/B551011/GoCamping/basedList"
            f"?serviceKey={CAMP_API_KEY}"
            f"&numOfRows={num}&pageNo=1&MobileOS=ETC&MobileApp=campApp&_type=xml"
        )
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            root = ET.fromstring(response.content)
            items = root.findall(".//item")

            campgrounds = []
            for item in items:
                name = item.findtext("facltNm", default="ì´ë¦„ ì—†ìŒ")
                addr = item.findtext("addr1", default="ì£¼ì†Œ ì—†ìŒ")
                line_intro = item.findtext("lineIntro", default="ì„¤ëª… ì—†ìŒ")
                feature = item.findtext("featureNm", default="íŠ¹ì§• ì •ë³´ ì—†ìŒ")
                campgrounds.append({
                    "ì´ë¦„": name,
                    "ì£¼ì†Œ": addr,
                    "ì„¤ëª…": line_intro,
                    "íŠ¹ì§•": feature,
                })
            return campgrounds
        except requests.exceptions.RequestException as e:
            st.error(f"ìº í•‘ì¥ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return []
        except ET.ParseError as e:
            st.error(f"ìº í•‘ì¥ ë°ì´í„° XML íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return []

    def format_campgrounds(camps):
        if not camps:
            return "ì‚¬ìš© ê°€ëŠ¥í•œ ìº í•‘ì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        text = ""
        for c in camps:
            text += f"{c['ì´ë¦„']} | {c['ì£¼ì†Œ']} | {c['íŠ¹ì§•']} | {c['ì„¤ëª…']}\n"
        return text.strip()

    def ask_gpt_to_recommend_camp(query: str) -> str:
        camps = fetch_campgrounds_from_api(15)
        if not camps:
            return "ìº í•‘ì¥ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

        formatted = format_campgrounds(camps)
        prompt = (
            f"ì•„ë˜ëŠ” ìµœê·¼ ìº í•‘ì¥ ëª©ë¡ì…ë‹ˆë‹¤:\n\n{formatted}\n\n"
            f"ì´ ì¤‘ ì‚¬ìš©ìê°€ '{query}' ì¡°ê±´ì— ë§ëŠ” ìº í•‘ì¥ì„ ì°¾ê³  ìˆì–´.\n"
            f"ì¡°ê±´ì— ì˜ ë§ëŠ” ê³³ 2~3ê³³ì„ ì¶”ì²œí•´ì£¼ê³ , ê°ê°ì˜ íŠ¹ì§•ë„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜."
        )
        try:
            # LangChain ChatOpenAI ëŒ€ì‹  ì§ì ‘ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (ì½”ë“œ ì¼ê´€ì„± ìœ ì§€)
            response = client.chat.completions.create(
                model="gpt-4o-mini", # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ìº í•‘ì¥ ì¶”ì²œ ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=700
            )
            return response.choices[0].message.content
        except Exception as e:
            st.error(f"GPT ìº í•‘ì¥ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return "ìº í•‘ì¥ ì¶”ì²œì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    with st.form("camp_search_form"):
        user_query = st.text_input("ìº í•‘ì¥ì— ëŒ€í•œ ì¡°ê±´ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°•ì›ë„ ì¡°ìš©í•œ ê³„ê³¡ ê·¼ì²˜)", "")
        submitted_camp = st.form_submit_button("ì¶”ì²œ ë°›ê¸°")

    if submitted_camp:
        if not user_query.strip():
            st.warning("ì¡°ê±´ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ğŸ¤– GPTê°€ ìº í•‘ì¥ì„ ì¶”ì²œí•˜ëŠ” ì¤‘..."):
                result = ask_gpt_to_recommend_camp(user_query)
                st.subheader("âœ… ì¶”ì²œ ìº í•‘ì¥")
                st.success(result)

# ==============================================================================
# --- ğŸ“ˆ ì£¼ê°€ ë¶„ì„ ê¸°ëŠ¥ ---
# ==============================================================================
elif option == "ì£¼ê°€ ë¶„ì„":
    st.header("ğŸ“ˆ GPT ì£¼ê°€ ë¶„ì„ê¸°")
    st.markdown("í•œêµ­ ì£¼ì‹ ì¢…ëª©ì˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPTê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

    # âœ… ì¢…ëª©ëª… â†’ í‹°ì»¤ ìë™ ë³€í™˜ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„±
    @st.cache_data
    def get_ticker_dict():
        tickers = stock.get_market_ticker_list("KOSPI") + stock.get_market_ticker_list("KOSDAQ")
        # ì¢…ëª©ëª…ì— í•œê¸€ì´ ë§ìœ¼ë¯€ë¡œ ensure_ascii=Falseë¡œ ì„¤ì •í•˜ì—¬ í•œê¸€ ê¹¨ì§ ë°©ì§€
        return {stock.get_market_ticker_name(t): t for t in tickers}

    # âœ… ì£¼ê°€ ì¡°íšŒ Tool (LangChain Agentê°€ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
    @tool
    def get_stock_price_data(ticker: str, days: int = 30):
        """ì§€ì •í•œ í‹°ì»¤ì— ëŒ€í•´ ìµœê·¼ Nì¼ê°„ ì£¼ê°€ ë°ì´í„°(OHLVC)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        ë‚ ì§œëŠ” YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ, ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€, ê±°ë˜ëŸ‰ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
        """
        end_date = datetime.today()
        # pykrxëŠ” ì˜ì—…ì¼ë§Œ ë°˜í™˜í•˜ë¯€ë¡œ, ìš”ì²­ ì¼ìˆ˜ë¥¼ ì—¬ìœ  ìˆê²Œ ì¡ê³  ë‚˜ì¤‘ì— ìë¦„
        start_date = end_date - timedelta(days=days * 1.5)

        try:
            df = stock.get_market_ohlcv_by_date(
                start_date.strftime('%Y%m%d'),
                end_date.strftime('%Y%m%d'),
                ticker
            )
            if df.empty:
                return f"ì¢…ëª© ì½”ë“œ {ticker}ì— ëŒ€í•œ ì£¼ê°€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            df = df.tail(days) # ìµœê·¼ days ì¼ ë°ì´í„°ë§Œ ì‚¬ìš©
            df = df.reset_index()
            df["ë‚ ì§œ"] = df["ë‚ ì§œ"].dt.strftime("%Y-%m-%d")
            # JSON ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ int/float ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì„ íƒ ì‚¬í•­, ê·¸ëŸ¬ë‚˜ ì•ˆì „)
            df['ì‹œê°€'] = df['ì‹œê°€'].apply(lambda x: f"{int(x):,}")
            df['ê³ ê°€'] = df['ê³ ê°€'].apply(lambda x: f"{int(x):,}")
            df['ì €ê°€'] = df['ì €ê°€'].apply(lambda x: f"{int(x):,}")
            df['ì¢…ê°€'] = df['ì¢…ê°€'].apply(lambda x: f"{int(x):,}")
            df['ê±°ë˜ëŸ‰'] = df['ê±°ë˜ëŸ‰'].apply(lambda x: f"{int(x):,}")

            return json.dumps(df.to_dict(orient="records"), ensure_ascii=False)
        except Exception as e:
            return f"ì£¼ê°€ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    # âœ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (Streamlit ì„¸ì…˜ ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ ìºì‹±)
    @st.cache_resource
    def init_agent():
        # ChatOpenAI ëª¨ë¸ì€ OpenAI í´ë¼ì´ì–¸íŠ¸ì™€ ë³„ê°œë¡œ LangChain Agentì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        # ë”°ë¼ì„œ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
        model = ChatOpenAI(model="gpt-4o-mini", temperature=0, streaming=True)
        prompt = hub.pull("hwchase17/openai-tools-agent")

        prompt.messages[0].prompt.template = (
            "ë„ˆëŠ” ì£¼ì‹ ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì—ì„œ í•œêµ­ ì£¼ì‹ ì¢…ëª©ëª…ì„ ì¶”ì¶œí•˜ê³  ì£¼ê°€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•´ì¤˜."
            " í•­ìƒ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , í•„ìš” ì‹œ ì£¼ê°€ ì¡°íšŒ ë„êµ¬(get_stock_price_data)ë¥¼ í™œìš©í•´."
            " ìµœì‹  ì •ë³´ëŠ” get_stock_price_data ë„êµ¬ë¥¼ í†µí•´ì„œë§Œ ì–»ì„ ìˆ˜ ìˆì–´."
            " ë‹µë³€ì€ í•­ìƒ ì¹œì ˆí•˜ê³  ìœ ìµí•˜ê²Œ ì œê³µí•´ì¤˜."
        )

        tools = [get_stock_price_data] # TavilySearchResultsëŠ” ì„ íƒ ì‚¬í•­ì´ë¯€ë¡œ ì œê±°
        agent = create_openai_tools_agent(model, tools, prompt)
        executor = AgentExecutor(agent=agent, tools=tools, verbose=False, handle_parsing_errors=True)
        return executor

    # âœ… Chat ìˆ˜í–‰ í•¨ìˆ˜
    def chat_with_agent(agent_executor, user_input):
        # LangChain AgentëŠ” ì¢…ëª©ëª… ë§¤ì¹­ ë¡œì§ì„ ì§ì ‘ í¬í•¨í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œ ì²˜ë¦¬
        ticker_dict = get_ticker_dict()
        matched_ticker = None
        matched_name = None

        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì¢…ëª©ëª… ë˜ëŠ” í‹°ì»¤ë¥¼ ì°¾ì•„ì„œ ì‹¤ì œ í‹°ì»¤ë¡œ ë³€í™˜
        # rapidfuzz ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ ì¢…ëª© ë§¤ì¹­ì„ ì¶”ê°€í•  ìˆ˜ ìˆì§€ë§Œ,
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ í¬í•¨ ì—¬ë¶€ë¡œ í™•ì¸
        for name, ticker in ticker_dict.items():
            if name in user_input or ticker in user_input:
                matched_ticker = ticker
                matched_name = name
                break

        if matched_ticker:
            # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì‹¤ì œ í‹°ì»¤ì™€ ì¢…ëª©ëª…ì„ í¬í•¨ì‹œì¼œ Agentê°€ ë” ì˜ ì´í•´í•˜ë„ë¡ ìœ ë„
            modified_input = f"ì¢…ëª©ëª… '{matched_name}' (í‹°ì»¤: {matched_ticker})ì— ëŒ€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤: {user_input}"
        else:
            modified_input = user_input # ë§¤ì¹­ë˜ëŠ” ì¢…ëª©ì´ ì—†ìœ¼ë©´ ì›ë³¸ ì…ë ¥ ì‚¬ìš©

        return agent_executor.invoke({"input": modified_input})["output"]

    # ğŸ”¹ Streamlit UI
    ticker_dict = get_ticker_dict() # ì¢…ëª©ëª…-í‹°ì»¤ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ
    agent_executor = init_agent() # Agent ì´ˆê¸°í™”

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ğŸ”¹ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ğŸ”¹ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input("ë¶„ì„í•  ì¢…ëª©ëª…ì´ë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'ì‚¼ì„±ì „ì ìµœê·¼ ì£¼ê°€ ì–´ë•Œ?', 'ì¹´ì¹´ì˜¤ 1ë…„ì¹˜ ì£¼ê°€ ë¶„ì„í•´ì¤˜')")

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.spinner("ğŸ¤– GPTê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                response = chat_with_agent(agent_executor, user_input)
            except Exception as e:
                response = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"

        st.session_state.messages.append({"role": "assistant", "content": response})
        with st.chat_message("assistant"):
            st.markdown(response)