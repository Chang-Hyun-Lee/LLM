import streamlit as st
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.node_parser import SentenceSplitter
import os

# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API Key ê°€ì ¸ì˜¤ê¸°
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")

# llama_index ì „ì—­ ì„¤ì •
Settings.llm = OpenAI(temperature=0, model="gpt-4o-mini")
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")
Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)

# Streamlit ì•±
st.title("ğŸ“„ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ")

# ì¸ë±ìŠ¤ ìƒì„±
@st.cache_resource
def load_index():
    documents = SimpleDirectoryReader("data").load_data()
    index = VectorStoreIndex.from_documents(documents)
    return index.as_query_engine()

query_engine = load_index()

# ì‚¬ìš©ì ì…ë ¥
query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

# ë‹µë³€ ì¶œë ¥
if query:
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        response = query_engine.query(query)
        st.success("âœ… ë‹µë³€")
        st.write(response.response)
