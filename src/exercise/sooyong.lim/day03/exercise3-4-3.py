import os
import streamlit as st
from llama_index.core import VectorStoreIndex, Settings, Document
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.node_parser import SentenceSplitter

from io import StringIO
import docx2txt
import tempfile

# OpenAI API í‚¤
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")

# LlamaIndex ì„¤ì •
Settings.llm = OpenAI(temperature=0, model="gpt-4o-mini")
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")
Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)

st.title("ğŸ“„ ì—…ë¡œë“œí•œ ë¬¸ì„œ ì „ì²´ ìš”ì•½")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.txt, .pdf, .docx)", type=["txt", "pdf", "docx"])

def load_file_text(uploaded_file):
    if uploaded_file.type == "text/plain":
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        return stringio.read()
    elif uploaded_file.type == "application/pdf":
        import fitz  # PyMuPDF
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name
        text = ""
        with fitz.open(tmp_path) as doc:
            for page in doc:
                text += page.get_text()
        return text
    elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name
        return docx2txt.process(tmp_path)
    else:
        return None

if uploaded_file is not None:
    file_text = load_file_text(uploaded_file)

    if file_text:
        st.success("íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

        # LlamaIndex ë¬¸ì„œë¡œ ë³€í™˜
        document = Document(text=file_text)

        # ì¸ë±ì‹± ë° ìš”ì•½
        index = VectorStoreIndex.from_documents([document])
        query_engine = index.as_query_engine(response_mode="tree_summarize")

        with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
            response = query_engine.query("ì´ ë¬¸ì„œë¥¼ ì „ì²´ì ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.")
            st.subheader("ğŸ“Œ ë¬¸ì„œ ìš”ì•½")
            st.write(response.response)
    else:
        st.error("íŒŒì¼ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
