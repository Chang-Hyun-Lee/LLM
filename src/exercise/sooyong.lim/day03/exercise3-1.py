import streamlit as st
import openai
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

st.title("Streamlitìœ¼ë¡œ ë§Œë“  ì±„íŒ… App")

# ê¸°ì¡´ ë©”ì‹œì§€ ì¶œë ¥ (ìˆœì„œëŒ€ë¡œ)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° ì¶œë ¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # GPT ì‘ë‹µ ë°›ê¸°
    with st.chat_message("assistant"):
        response_container = st.empty()  # ì±„íŒ… ì‹¤ì‹œê°„ ì¶œë ¥í•  ìë¦¬
        full_response = ""

        response_stream = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True,
            temperature=0.5,
            max_tokens=1024,
        )

        for chunk in response_stream:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                response_container.markdown(full_response + "â–Œ")

        response_container.markdown(full_response)  # ìµœì¢… ì‘ë‹µ í‘œì‹œ
        st.session_state.messages.append({"role": "assistant", "content": full_response})

    # ğŸ“Œ ìë™ ìŠ¤í¬ë¡¤ (Streamlitì€ ë‚´ì¥ ì§€ì› ì—†ìŒ â†’ ì•„ë˜ì— ë¹ˆ ê³µê°„ ë„£ëŠ” ë°©ì‹)
    st.write("")  # ì—¬ìœ  ê³µê°„
    st.markdown(
        """
        <script>
        var bottom = document.body.scrollHeight;
        window.scrollTo({top: bottom, behavior: 'smooth'});
        </script>
        """,
        unsafe_allow_html=True,
    )
